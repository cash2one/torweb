-- MySQL dump 10.13  Distrib 5.7.14, for osx10.11 (x86_64)
--
-- Host: localhost    Database: torweb
-- ------------------------------------------------------
-- Server version	5.7.14

/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;
/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */;
/*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */;
/*!40101 SET NAMES utf8 */;
/*!40103 SET @OLD_TIME_ZONE=@@TIME_ZONE */;
/*!40103 SET TIME_ZONE='+00:00' */;
/*!40014 SET @OLD_UNIQUE_CHECKS=@@UNIQUE_CHECKS, UNIQUE_CHECKS=0 */;
/*!40014 SET @OLD_FOREIGN_KEY_CHECKS=@@FOREIGN_KEY_CHECKS, FOREIGN_KEY_CHECKS=0 */;
/*!40101 SET @OLD_SQL_MODE=@@SQL_MODE, SQL_MODE='NO_AUTO_VALUE_ON_ZERO' */;
/*!40111 SET @OLD_SQL_NOTES=@@SQL_NOTES, SQL_NOTES=0 */;

--
-- Table structure for table `blogpost`
--

DROP TABLE IF EXISTS `blogpost`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `blogpost` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `title` varchar(71) NOT NULL,
  `slug` varchar(32) NOT NULL,
  `category_id` int(11) NOT NULL,
  `content` longtext NOT NULL,
  `create_time` datetime NOT NULL,
  `is_del` tinyint(1) NOT NULL,
  PRIMARY KEY (`id`),
  KEY `blogpost_category_id` (`category_id`),
  CONSTRAINT `blogpost_ibfk_1` FOREIGN KEY (`category_id`) REFERENCES `blogpostcategory` (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=266 DEFAULT CHARSET=utf8;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `blogpost`
--

LOCK TABLES `blogpost` WRITE;
/*!40000 ALTER TABLE `blogpost` DISABLE KEYS */;
INSERT INTO `blogpost` VALUES (213,'Django ORM笔记','django-orm',97,'### `__`神奇用法\n\n```\n多表联合查询,可用通过可以通过poc表访问vul外键对应的vul表中的字段\npoc.objects.values(\'id\',\'vul__name\').all()\n```\n\n### 外键关系反查\n\n```\n# 设置关系叫做`re_demand`\nclass Demand(models.Model):\n  submitter = models.ForeignKey(User, verbose_name=u\"需求提交者\",related_name=\'re_demand\')\nclass User(models.Model):\n  name=models.CharField()\n\n# 获取该user对应的所有demands\nuser.re_demand.all()\n```\n','2016-11-10 01:23:36',0),(214,'Django Rest framework笔记','django-restful',97,'## 最简洁使用\n\n```\n# 配置路由\nurl(r\'^api/v1/test_rest/\',test_rest.views.test_poc_list_view.as_view()),\n\nclass test_PocSerializer(serializers.Serializer):\n    id=serializers.IntegerField(read_only=True)\n    vul__name=serializers.CharField(read_only=True)\n\n    def create(self, validated_data):\n        pass\n\n    def update(self, instance, validated_data):\n        pass\n\n# 配置视图的两种方法\n#1.函数方法\n@api_view([\'POST\',\'GET\'])\ndef test_poc_list(request):\n    if request.method==\'GET\':\n        test_pocs=Poc.objects.values(\'id\',\'vul__name\').all()\n        serializer=test_PocSerializer(test_pocs,many=True)\n        return JSONResponse(serializer.data)\n    elif request.method == \'POST\':\n        pass\n\n#2.类视图\nclass Test_Poc_List(APIView):\n    # get方法\n    def get(self,request):\n        if request.method==\'GET\':\n            test_pocs=Poc.objects.values(\'id\',\'vul__name\').all()\n            serializer=test_PocSerializer(test_pocs,many=True)\n            return JSONResponse(serializer.data)\n        elif request.method == \'POST\':\n            pass\n#3.更加封装的view\nclass Test_Poc_List_(generics.ListAPIView):\n   queryset=Poc.objects.values(\'id\',\'vul__name\').all()\n   serializer_class = test_PocSerializer\n```\n\n##  技巧点\n\n```\n# 调用一个特殊的方法去返回该field\nrequired = serializers.SerializerMethodField(\'get_required\')\ndef get_required(self, obj):\n  # obj是正在序列化的instance\n  pass\n```\n','2016-11-10 01:23:36',0),(215,'django开发基本配置技巧','study-django',97,'## 入门配置篇\n\n```\n#模板\n\'DIRS\': [BASE_DIR+\"/templates\",]\n\n#新建数据库\npython manage.py migrate\npython manage.py makemigrations\n\n#数据库相关操作\nlist = Test.objects.all()\nTest.objects.filter(id=1)\nPublisher.objects.order_by(\"name\")\nPublisher.objects.order_by(\"state_province\", \"address\")\n#相当于limit10\nPublisher.objects.order_by(\'name\')[10]\n\n#批量update\nPublisher.objects.filter(id=52).update(name=\'Apress Publishing\')\n\n#批量删除   \nPublisher.objects.filter(country=\'USA\').delete()\n\n#从数据提取数据\ntry:\n    p = Publisher.objects.get(name=\'Apress\')\nexcept Publisher.DoesNotExist:\n\n#django admin管理,字符型可以仅仅使用blank，而一些以其他数据，需要加上null\npublication_date = models.DateField(**blank=True, null=True** )\n\n#model降序\nclass Article(models.Model):\n    class Meta:  #按时间下降排序\n        ordering = [\'-date_time\']\n\n\n#变量描述\nforloop.counter 索引从 1 开始算\nforloop.counter0 索引从 0 开始算\nforloop.revcounter 索引从最大长度到 1\nforloop.revcounter0 索引从最大长度到 0\nforloop.first 当遍历的元素为第一项时为真\nforloop.last 当遍历的元素为最后一项时为真\nforloop.parentloop 用在嵌套的 for 循环中，\n\n```\n\n## Admin基本配置\n\n```\n#每一个条目显示的字段\nlist_display = (\'first_name\', \'last_name\', \'email\')\n#每一个条目支持修改的字段\nfields = (\'title\', \'authors\', \'publisher\')\n```\n\n## Django下URLconf配置\n### 1.使用命名组参数\n\n```\nurlpatterns = patterns(\'\',\n    # 命名组参数year,month\n    (r\'^articles/(?P<year>\\d{4})/$\', views.year_archive),\n    (r\'^articles/(?P<year>\\d{4})/(?P<month>\\d{2})/$\', views.month_archive),\n)\n```\n\n### 2.传递额外参数\n\n增加了URL和Views的耦合度\n\n```\n# 不好！！！！ 增加了URL和Views的耦合度\nurlpatterns = patterns(\'\',\n    (r\'^(foo)/$\', views.foobar_view),\n    (r\'^(bar)/$\', views.foobar_view),\n)\n\ndef foobar_view(request, url):\n    m_list = MyModel.objects.filter(is_new=True)\n    if url == \'foo\':\n        template_name = \'template1.html\'\n    elif url == \'bar\':\n        template_name = \'template2.html\'\n    return render_to_response(template_name, {\'m_list\': m_list})\n```\n\n传递额外参数\n\n```\nurlpatterns = patterns(\'\',\n    # 传递了额外参数,template_name\n    (r\'^foo/$\', views.foobar_view, {\'template_name\': \'template1.html\'}),\n    (r\'^bar/$\', views.foobar_view, {\'template_name\': \'template2.html\'}),\n)\n\ndef foobar_view(request, template_name):\n    m_list = MyModel.objects.filter(is_new=True)\n    return render_to_response(template_name, {\'m_list\': m_list})\n```\n\n伪造URLconf参数\n\n```\nurlpatterns = patterns(\'\',\n    # 对于特例情况下，伪造urlconf\n    (r\'^mydata/birthday/$\', views.my_view, {\'month\': \'jan\', \'day\': \'06\'}),\n    (r\'^mydata/(?P<month>\\w{3})/(?P<day>\\d\\d)/$\', views.my_view),\n)\n```\n额外参数优先级要高对于捕获参数的优先级\n\nurl匹配存在短路逻辑\n\n从url提取的所有参数均为文本\n\n### post和get分给不同函数处理\n```\n# 这里的参数，*args列表类型,**kwargs字典类型\ndef method_splitter(request, *args, **kwargs):\n    get_view = kwargs.pop(\'GET\', None)\n    post_view = kwargs.pop(\'POST\', None)\n    if request.method == \'GET\' and get_view is not None:\n        return get_view(request, *args, **kwargs)\n    elif request.method == \'POST\' and post_view is not None:\n        return post_view(request, *args, **kwargs)\n    raise Http404\n```\n\n### 装饰器(访问很多页面要求已经登陆)\n```\n# 可以做成装饰器\ndef requires_login(view):\n    def new_view(request, *args, **kwargs):\n        if not request.user.is_authenticated():\n            return HttpResponseRedirect(\'/accounts/login/\')\n        return view(request, *args, **kwargs)\n    return new_view\n```\n\n## 渲染模板\nRequestContext可以包含req参数，同时可以将这个请求过程中一直存在的参数放到其中，相比Context而言。\n\n```\ndef custom_proc(request):\n    \"A context processor that provides \'app\', \'user\' and \'ip_address\'.\"\n    return {\n        \'app\': \'My app\',\n        \'user\': request.user,\n        \'ip_address\': request.META[\'REMOTE_ADDR\']\n    }\n\ndef view_1(request):\n    return render_to_response(\'template1.html\',\n        {\'message\': \'I am view 1.\'},\n        # 多个视图通用的参数\n        context_instance=RequestContext(request, processors=[custom_proc]))\n```\n\n### 关闭模板自转义\n```\n{% autoescape off %}\n    Hello {{ name }}\n{% endautoescape %}\n```\n### url规则名字，自动更改前缀\n```\nurl(r\'^add/(\\d+)/(\\d+)/$\', \'app.views.add\', name=\'add\'),\n{% url \'some-url-name\' arg arg2 as the_url %}\n```\n\n## Model高级\n\n### 1.增加数据库manager方法\n```\nclass BookManager(models.Manager):\n    def title_count(self, keyword):\n        return self.filter(title__icontains=keyword).count()\n    #修改初始Manager QuerySets\n    def get_query_set(self):\n        return super(DahlBookManager, self).get_query_set().filter(author=\'Roald Dahl\')\n\nclass Book(models.Model):\n    ...\n    objects = BookManager()\n    roald_objects=BookManager()\n```\n\n### 2.用户model自定义\n\nhttps://docs.djangoproject.com/en/dev/topics/auth/customizing/#substituting-a-custom-user-model\n\n`AbstractBaseUser` 是全部定制，需要重写覆盖`BaseUserManager`,`BaseUserAdmin`\n\n`AbstractUser` 如果只是扩展字段可以用这个\n','2016-11-10 01:23:36',0),(216,'Docker基础笔记','study-docker',98,'**文档地址 `https://docs.docker.com`**\n\n比较不错的入门实践 `https://www.gitbook.com/book/yeasy/docker_practice`\n\n个人Dockerfile集合 `https://github.com/jmpews/dockerfiles`\n\n必备命令 `docker --help`\n\n## 0. docker 架构\n\nDocker采取的C-S结构。Docker client同Docker daemon通讯，Docker daemon负责维护docker 容器的构建，运行和分发。\nClient和Daemon可以再同一台主机上面执行，也可以分开执行。本地的client可以连接远程的daemon。Client可以通过socker或者REST API同daemon通讯。\n![docker-architecture](https://docs.docker.com/engine/article-img/architecture.svg)\n\n## 1. images 和 container 的关系\n\ncontainer建立在images之上, images有多种获取方式，`daocloud.io` / `https://c.163.com/`, 建议首选`daocloud.io`;当通过images运行命令自动就生成一个container,例如: `docker run -ti jmpews/go1.6 /bin/bash`\n\n## 2. docker 基本配置信息\n\ndocker版本信息 `docker version`\n\ndocker配置信息 `docker info`\n\ndocker image(jmpews/go1.6)的配置信息 `docker inspect jmpews/go1.6`\n\ndocker存放images的位置(OSX) `~/Library/Containers/com.docker.docker/Data/com.docker.driver.amd64-linux/Docker.qcow2`\n\n## 3. Dockerfile实例\n\n使用daocloud.io/library/ubuntu:14.04作为基础image构建自己的image\n\n```\nFROM daocloud.io/library/ubuntu:16.04\n\nMAINTAINER jmpews \"jmpews@gmail.com\"\n\n# 修改源\nRUN cp /etc/apt/sources.list /etc/apt/sources.list.bak \\\n&& sed -i \'s/archive.ubuntu.com/mirrors.aliyun.com/g\' /etc/apt/sources.list \\\n&& apt-get update\n\nRUN DEBIAN_FRONTEND=noninteractive apt-get install -y --no-install-recommends \\\nbuild-essential \\\ngdb \\\npython \\\npython-pip \\\nvim \\\ncurl \\\nwget \\\ngit \\\ntmux\n\n# 修改时区\nRUN echo \"Asia/Shanghai\" > /etc/timezone && dpkg-reconfigure -f noninteractive tzdata\n# tmux配置文件\nRUN wget --no-check-certificate -qO $HOME/.tmux.conf https://raw.githubusercontent.com/jmpews/configs/master/tmux/.tmux.conf\nRUN tmux start-server\n# vim配置文件\nRUN wget --no-check-certificate -qO $HOME/.vimrc https://raw.githubusercontent.com/jmpews/configs/master/vim/.vimrc\n\n# # Python环境配置\n# RUN mkdir ~/.pip && echo \'[global]\\n\\\n# index-url = http://mirrors.aliyun.com/pypi/simple/\\n\\\n# [install]\\n\\\n# trusted-host = mirrors.aliyun.com\' > ~/.pip/pip.conf\n\n# # RUN wget https://www.python.org/ftp/python/3.5.2/Python-3.5.2.tgz\n# RUN cd /root/ \\\n# 	&& wget --no-check-certificate -qO ./Python-3.5.2.tgz https://www.python.org/ftp/python/3.5.2/Python-3.5.2.tgz \\\n#     && tar zxvf Python-3.5.2.tgz \\\n#     && cd /root/Python-3.5.2 \\\n#     && ./configure --prefix=/usr/local/python3.5.2 \\\n#     && make && make install\n\n# Peda 安装\nRUN GIT_SSL_NO_VERIFY=true git clone https://github.com/longld/peda.git ~/peda \\\n	&& echo \"source ~/peda/peda.py\" >> ~/.gdbinit \\\n	&& echo \"DONE! debug your program with gdb and enjoy\"\nWORKDIR /root\n```\n\n### `EXPOSE`和`-p`区别\n\n```\n# 默认不会进行映射，当使用`-P`会自动选择一个主机的端口映射好\nEXPOSE 1000\n# 指定docker和宿主机的特定端口映射\n-p 5000:5000\n```\n','2016-11-10 01:23:36',0),(217,'GCC内存栈对齐的坑','align-gcc-stack',99,'## 简介\n源于《深入理解计算机操作系统》的P153页的内存栈对齐.\n\n## 什么是内存对齐\n函数运行时需要的栈的大小是确定的, 比如经常会遇到如下的代码.\n\n```\npushl %ebp\nmovl %esp, %ebp\nsubl %24, %esp\n```\n其中 `subl %24, %esp` 就是用于分配函数运行栈, 需要对栈的大小进行对齐, 为什么需要对齐, 具体参考《SCPP》的3.9.3节.\n\n## 如何对齐\n\n参考 https://gcc.gnu.org/ml/gcc/2007-12/msg00503.html\n\n<pre>\nThere are two ways current GCC supports bigger than default stack\nalignment.  One is to make sure that stack is aligned at program entry\npoint, and then ensure that for each non-leaf function, its frame size\nis\naligned. This approach doesn\'t work when linking with libs or objects\ncompiled by other psABI confirming compilers. Some problems are logged\nas\nPR 33721. Another is to adjust stack alignment at the entry point of a\nfunction if it is marked with __attribute__ ((force_align_arg_pointer))\nor -mstackrealign option is provided. This method guarantees the\nalignment\nin most of the cases but with following problems and limitations:\n\n*  Only 16 bytes alignment is supported\n*  Adjusting stack alignment at each function prologue hurts performance\nunnecessarily, because not all functions need bigger alignment. In fact,\ncommonly only those functions which have SSE variables defined locally\n(either declared by the user or compiler generated internal temporary\nvariables) need corresponding alignment.\n*  Doesn\'t support x86_64 for the cases when required stack alignment\nis > 16 bytes\n*  Emits inefficient and complicated prologue/epilogue code to adjust\nstack alignment\n*  Doesn\'t work with nested functions\n*  Has a bug handling register parameters, which resulted in a cpu2006\nfailure. A patch is available as a workaround.\n</pre>\n\n这里通过一段代码来分析\n\n```\nint swap_add(int *xp, int *yp)\n{\n   int x = *xp;\n   int y = *yp;\n \n   *xp = y;\n   *yp = x;\n   return x + y;\n}\n \nint caller()\n{\n   int arg1 = 534;\n   int arg2 = 1057;\n   int sum = swap_add(&arg1, &arg2);\n   int diff = arg1 - arg2;\n \n   return sum * diff;\n}\n\nint main(int argc, char *argv[]) {\n    int result;\n    result = caller();\n}\n```\n\n使用 `gcc -S -m32 -march=i386 -fno-stack-protector p153.c`  进行反汇编, 也可以使用 `gcc -g -o p153 -m32 -march=i386 -fno-stack-protector p153.c` 然后丢到gdb调试.(-fno-stack-protector 关闭栈保护)\n\n```\n	.file	\"p153.c\"\n	.text\n	.globl	swap_add\n	.type	swap_add, @function\n// 暂时不管这个函数	\nswap_add:\n.LFB0:\n	.cfi_startproc\n	pushl	%ebp\n	.cfi_def_cfa_offset 8\n	.cfi_offset 5, -8\n	movl	%esp, %ebp\n	.cfi_def_cfa_register 5\n	subl	$16, %esp\n	movl	8(%ebp), %eax\n	movl	(%eax), %eax\n	movl	%eax, -4(%ebp)\n	movl	12(%ebp), %eax\n	movl	(%eax), %eax\n	movl	%eax, -8(%ebp)\n	movl	8(%ebp), %eax\n	movl	-8(%ebp), %edx\n	movl	%edx, (%eax)\n	movl	12(%ebp), %eax\n	movl	-4(%ebp), %edx\n	movl	%edx, (%eax)\n	movl	-4(%ebp), %edx\n	movl	-8(%ebp), %eax\n	addl	%edx, %eax\n	leave\n	.cfi_restore 5\n	.cfi_def_cfa 4, 4\n	ret\n	.cfi_endproc\n.LFE0:\n	.size	swap_add, .-swap_add\n	.globl	caller\n	.type	caller, @function\n// 主要分析这个函数栈对齐, 其实都差不多\ncaller:\n.LFB1:\n	.cfi_startproc\n	pushl	%ebp\n	.cfi_def_cfa_offset 8\n	.cfi_offset 5, -8\n	movl	%esp, %ebp\n	.cfi_def_cfa_register 5\n	// 分配函数栈\n	subl	$16, %esp\n	movl	$534, -12(%ebp)\n	movl	$1057, -16(%ebp)\n	leal	-16(%ebp), %eax\n	// 注意这里, 把swap_add需要的参数压入当前栈, $esp移动\n	pushl	%eax\n	leal	-12(%ebp), %eax\n  // 注意这里, 把swap_add需要的参数压入当前栈, $esp移动\n	pushl	%eax\n	call	swap_add\n	// swap_add调用完毕, 恢复之前栈的$esp\n	addl	$8, %esp\n	movl	%eax, -4(%ebp)\n	movl	-12(%ebp), %edx\n	movl	-16(%ebp), %eax\n	subl	%eax, %edx\n	movl	%edx, %eax\n	movl	%eax, -8(%ebp)\n	movl	-4(%ebp), %eax\n	imull	-8(%ebp), %eax\n	leave\n	.cfi_restore 5\n	.cfi_def_cfa 4, 4\n	ret\n	.cfi_endproc\n.LFE1:\n	.size	caller, .-caller\n	.globl	main\n	.type	main, @function\nmain:\n.LFB2:\n	.cfi_startproc\n	pushl	%ebp\n	.cfi_def_cfa_offset 8\n	.cfi_offset 5, -8\n	movl	%esp, %ebp\n	.cfi_def_cfa_register 5\n	subl	$16, %esp\n	call	caller\n	movl	%eax, -4(%ebp)\n	movl	$0, %eax\n	leave\n	.cfi_restore 5\n	.cfi_def_cfa 4, 4\n	ret\n	.cfi_endproc\n.LFE2:\n	.size	main, .-main\n	.ident	\"GCC: (Ubuntu 5.4.0-6ubuntu1~16.04.2) 5.4.0 20160609\"\n	.section	.note.GNU-stack,\"\",@progbits\n```\n\n在上述代码中, `subl	$16, %esp` 分配了16字节的栈空间给`local variable`, 我们需要保证这里的栈空间是栈对齐的, 但是在 `caller` 函数运行时调用了 `swap_add`, 需要把 `swap_add` 用到的参数给压到栈里( `pushl	%eax` ), 栈空间增加, 但属于临时使用并不考虑栈对齐, 因为在 `swap_add` 运行完毕后需要恢复栈( `addl	$8, %esp` ). \n\n这里在还有一段使用 `i686` 编译的, 对于函数调用参数采用另一种处理方式. \n\n```\ncaller:\n.LFB1:\n	.cfi_startproc\n	pushl	%ebp\n	.cfi_def_cfa_offset 8\n	.cfi_offset 5, -8\n	movl	%esp, %ebp\n	.cfi_def_cfa_register 5\n	# 分配栈空间(包含swap_add参数, 但不考虑其参数的栈对齐)\n	subl	$24, %esp\n	movl	$534, -12(%ebp)\n	movl	$1057, -16(%ebp)\n	# swap_add 参数\n	leal	-16(%ebp), %eax\n	movl	%eax, 4(%esp)\n	# swap_add 参数\n	leal	-12(%ebp), %eax\n	movl	%eax, (%esp)\n	call	swap_add\n	movl	%eax, -4(%ebp)\n	movl	-12(%ebp), %edx\n	movl	-16(%ebp), %eax\n	subl	%eax, %edx\n	movl	%edx, %eax\n	movl	%eax, -8(%ebp)\n	movl	-4(%ebp), %eax\n	imull	-8(%ebp), %eax\n	leave\n	.cfi_restore 5\n	.cfi_def_cfa 4, 4\n	ret\n	.cfi_endproc\n```\n\n在这段代码中 `subl	$24, %esp` 分配的栈空间包含 `local variable` 的空间和 `swap_add` 参数的空间, 但是不考虑 `swap_add` 参数所导致的栈不对齐. \n\n### 额外\n使用 `gcc -Q --help=target -march=i686 | grep mstackrealign` 查看是否开启了栈对齐\n\n可以使用`-mpreferred-stack-boundary=5` 设置特殊值的栈对齐值, \n\n\n### 参考资料:\n\nhttps://gcc.gnu.org/ml/gcc/2007-12/msg00503.html\n\n\n\n','2016-11-10 01:23:36',0),(218,'gdb调试笔记','gdb-note',100,'## 命令集锦\n\n### where/bt\n查看当前运行堆栈列表\n\n### info program\n来查看程序的是否在运行，进程号，被暂停的原因。\n\n### f N\n切换到特定栈帧\n\n### info args\n查看当前栈的参数\n\n### info locals\n查看当前栈的局部变量\n\n### gdb attach pid\n挂载特定pid进行调试\n\n### disassemble function_name\n对一段函数进行反汇编\n\n### x/16xw $eip\ndump出来对应地址内容\n','2016-11-10 01:23:36',0),(219,'go基础笔记','study-go',101,'## Function\n```\n//命名的返回值(初始化为相应类型的零值)\nfunc getX2(i int) (x2 int, x3 int) {\n    x2 = 2 * i\n    x3 = 3 * i\n    return\n}\n\n//defer(命名返回值)\nfunc test(s string) (n int, err error) {\n    defer func() {\n        log.Printf(\"func (%q) = %d, %v\", s, n, error)\n    }()\n    return 7, io.EOF\n}\n\n//defer ret = 2(defer 在return后执行)\nfunc f() (ret int) {\n    defer func() {\n        ret++\n    }()\n    return 1\n}\n\n//传递函数参数\nfunc Add(a, b int) {\n    fmt.Printf(\"%d %d\",a, b)\n}\n\nfunc callback(y int, f func(int, int)) {\n    f(y, 2)\n}\n\n// 用闭包进行调试\nwhere := func() {\n    _, file, line, _ := runtime.Caller(1)\n    log.Printf(\"%s:%d\", file, line)\n}\nwhere()\n\n```\n## Array\n切片在内存中的组织方式实际上是一个有 3 个域的结构体：**指向相关数组的指针，切片 长度以及切片容量**。\n\n**传递的都是值拷贝，或者是指针的值拷贝(联系切片,传递切片也包含相关数组的指针的拷贝),是值类型，但是表现出引用语义**\n\nnew(T) 为每个新的类型T分配一片内存，初始化为 0 并且返回类型为*T的内存地址：这种方法 返回一个指向类型为 T，值为 0 的地址的指针，它适用于值类型如数组和结构体（参见第 10 章）；它相当于 &T{}。\nmake(T) 返回一个类型为 T 的初始值，它只适用于3种内建的引用类型：切片、map 和 channel\n```\nfunc test(arr []int) {\n    arr[0] +=1 //引用语义,arr虽然是切片拷贝,但是传递的是相关数组指针的拷贝，可以仍然可以修改原切片\n    arr = []int{1,2,3,4}\n}\n\nvar arr = new([5]int)\nfunc test(arr *[5]int){ //传递数组指针,可以修改\n    arr[0] +=1\n}\n```\n\n## Map\n\n```\n//map初始化\nvar map1[keytype]valuetype = make(map[keytype]valuetype)\nmap1 := make(map[keytype]valuetype)\nmap1 := map[keytype]valuetype{}\n\n```\n## Struct\n\n结构体嵌套\n\n* 外层名字会覆盖内层名字（但是两者的内存空间都保留），这提供了一种重载字段或方法的方式；\n* 如果相同的名字在同一级别出现了两次，如果这个名字被程序使用了，将会引发一个错误（不使用没关系）。没有办法来解决这种问题引起的二义性，必须由程序员自己修正。\n\nGo 方法是作用在接收者（receiver）上的一个函数，接收者是某种类型的变量\n\n## Interface\n\n```\n//类型断言,如果转换合法，v 是 varI 转换到类型 T 的值，ok 会是 true；否则 v 是类型 T 的零值，ok 是 false，也没有运行时错误发生。\nv, ok := varI.(T)\n\n//空接口 其他类型，向空接口类型拷贝\nvar dataSlice []myType = FuncReturnSlice()\nvar interfaceSlice []interface{} = make([]interface{}, len(dataSlice))\nfor ix, d := range dataSlice {\n    interfaceSlice[ix] = d\n}\n```\n','2016-11-10 01:23:36',0),(220,'greenlet是否合适与tornado结合？','tornado-with-greenlet',102,'之前在tornado上实现一个线程和Future的结合(`tornado中ioloop-yield-Future与thread的配合.md`). 之后有个想法就是将greenlet和tornado结合, 今天抽时间具体看了下.\n\ngreenlet本质是模拟线程调度, 但线程的调度是由OS系统控制的. \n\n先说线程,比如sleep操作，超过时间片自动切换到另一个线程(时间片调度算法)。\n\n再说greenlet, 在greenlet中需要程序员自己去做调度, 切换堆栈上下文等。然而关键就在于**何时进行协程切换?**,这需要自己去判断, 比如gevent库，在进行socket的monkey_pach时, 会进行几个操作. 1. 把socket改为因为非阻塞 2. 建立一个后台事件循环机制, 在connect时, 将当前协程切换(switch)到主协程继续执行, 并注册事件响应回调函数为\'切换到该协程\', 这样就完成了协程间的切换, 这里事件循环机制的存在也正是为了**解决何时切换到被挂起的协程以继续执行**而存在.\n\n**gevent和go的实现不一样**\n\n那yield和greenlet在实现上有区别么, yield是根据`PyFrameObject`和字节码, 通过保存`PyFrameObject`和恢复来实现. 相当于封装了一层C的API, 而greenlet就是按照函数切换机制，在C和汇编的层面完成. 可以看下这篇[Greenlet切换源码分析].\n\n那greenlet是否更合适与Torando配合? 如果要配合怎么配合?\n\n首先我不觉得greenlet很适合与tornado配合, 因为本质还是需要用tornado的ioloop和future, 作为协程切换的关键. \n\n如果确实需要使用，关键就是, 将Future的`set_result`的回调函数改为greenlet的协程就可以了.\n','2016-11-10 01:23:36',0),(221,'Greenlet源码分析','read-greenlet',103,'## Summary:\n\n协程可以算是自定义控制切换的微线程。\n\n## 栈切换的本质\n#### 1.栈\n\n* 栈是从高地址向低地址\n* 栈大小固定不变\n* 栈帧(stack frame)，机器用栈来传递过程参数，存储返回信息，保存寄存器用于以后恢复，以及本地存储。为单个过程(函数调用)分配的那部分栈称为栈帧。栈帧其实是两个指针寄存器，寄存器%ebp为帧指针(栈底-高地址)，而寄存器%esp为栈指针(栈顶-低地址)\n\n#### 2.切换\n\n* 切换首先需要切换执行位置(`top_frame`)\n* 但是当切换执行位置，同时要切换到目的栈，同时要保证栈内数据没有丢失，且没有被无意修改。这就需要栈数据的保存与恢复(`slp_switch`)。\n\n## 如何进行切换？\n### 1. C栈切换\n\n其实协程的一个很特殊的例子，就是函数调用。下面这个例子在main中调用func\n\n```\n#include<stdio.h>\nint func(int arg)\n{\n    int d=4;\n    int e=5;\n    int f;\n    f=d+e+arg;\n    return f;\n}\n\nint main()\n{\n    int a=1;\n    int b=2;\n    int c=3;\n    func(c);\n    c=a+b;\n}\n```\n用gcc生成汇编code，建议在redhat或centos下\n\n```\n.file   \"stackpointer.c\"\n.text\n.globl func\n.type   func, @function\nfunc:\npushl   %ebp\nmovl    %esp, %ebp\nsubl    $16, %esp\nmovl    $4, -12(%ebp)\nmovl    $5, -8(%ebp)\nmovl    -8(%ebp), %eax\nmovl    -12(%ebp), %edx\nleal    (%edx,%eax), %eax\naddl    8(%ebp), %eax\nmovl    %eax, -4(%ebp)\nmovl    -4(%ebp), %eax\nleave\nret\n.size   func, .-func\n.globl main\n.type   main, @function\nmain:\npushl   %ebp\nmovl    %esp, %ebp\nsubl    $20, %esp\nmovl    $1, -12(%ebp)\nmovl    $2, -8(%ebp)\nmovl    $3, -4(%ebp)\nmovl    -4(%ebp), %eax\nmovl    %eax, (%esp)  \ncall    func\nmovl    -8(%ebp), %eax\nmovl    -12(%ebp), %edx\nleal    (%edx,%eax), %eax\nmovl    %eax, -4(%ebp)\nleave\nret\n.size   main, .-main\n.ident  \"GCC: (GNU) 4.4.7 20120313 (Red Hat 4.4.7-11)\"\n.section        .note.GNU-stack,\"\",@progbits\n```\n\n```\n函数调用\n从main函数进入func\n\n1. 首先将需要传入func的参数入栈。\n\n2. push『call func』=下一条地址(IP压栈),jmp 『func』的函数地址(设置IP)\n\n4. 进入func\n\n5. `push bp`\n\n6. `mov sp,bp`\n\n---至此为止的栈，属于上一个栈\n\n7. 开始为局部变量分配地址\n\n8. `leave = mov bp,sp,pop bp`\n\n9. `ret`\n```\n\n#### `call func`\n* `push ip`，保存下一条指令的地址\n* `jump func`，修改ip跳转到func执行函数\n\n####  func\n* push ebp,保存bp\n* mov esp,ebp，设置新的栈底。\n* 以新的bp进行偏移，保存临时、本地变量，完成函数功能\n* leave(等价与mov ebp，esp；pop ebp)恢复esp和ebp\n* ret 恢复ip，回到call的下一条指令继续执行。\n\n### 2. Python栈切换\n我们进行的切换方式与此类似，但是python的栈和c栈不同，python栈建立在虚拟机上。\n\n总体上说，就是先进行c栈切换，关于ip设置跳转到下条指令执行(即执行位置的切换,如何跳到函数位置开始执行，如何从函数返回原来位置执行)，需要在python上实现`top_frame`的设置。\n\n具体细节参考:\n\n* [python的Greenlet模块源码分析](http://rootk.com/post/python-greenlet.html)\n* [greenlet栈帧切换细节](http://114.215.135.238:8001/?p=108)\n\n## switch具体实现\n\n\n几个注意点：\n\n* 导入greenlet会初始化一个`main_greenlet`，并设置current为`main_greenlet`\n* greenlet运行结束，会返回到父greenlet执行\n\n```\nfrom greenlet import greenlet  \n\ndef func1(arg):  \n    print (arg)  \n    gr2.switch()  \n    print (\"func1 end\")  \n\ndef func2():  \n    print (\"fun2 come\")  \n\n#设置parent为main_greenlet\ngr1 = greenlet(func1)  \ngr2 = greenlet(func2)  \nvalue = gr1.switch(\"fun1 come\")  \nprint (value)  \n```\n首先：\n```\ngr1.switch(\"func1\")\n```\n会调用`g_switch函数`，其中`target=gr1,args=(\'func1\')`\n\n```\nstatic PyObject *\ng_switch(PyGreenlet* target, PyObject* args, PyObject* kwargs)\n{\n  ...\n  while (target) {\n  if (PyGreenlet_ACTIVE(target)) {\n    ts_target = target;\n    err = g_switchstack();\n    break;\n  }\n  if (!PyGreenlet_STARTED(target)) {\n    void* dummymarker;\n    ts_target = target;\n    err = g_initialstub(&dummymarker);\n    if (err == 1) {\n      continue; /* retry the switch */\n    }\n    break;\n  }\n  target = target->parent;\n  }\n  ...\n}\n```\n* `gr1(new_greenlet)`，默认`stack_start = NULL(没有运行)`,`stack_stop = NULL(没有启动)`，因而执行`g_initialstub()`\n* dummymarker设置为栈底\n* 为什么要将dummymarker栈底设置于此处？\n\n`g_initialstub`的栈中包含函数需要的参数等数据，然而`&dummymarker`的位置恰为`g_initialstub`栈的ebp。\n\n### `g_initialstub` 分析\n\n代码已简化\n\n```\nstatic int GREENLET_NOINLINE(g_initialstub)(void* mark))\n{\n  ...\n  /* 设置stack_stop，表明start该greenlet */\n  self->stack_start = NULL;\n  self->stack_stop = (char*) mark;\n\n  /* 设置target的上一个活动栈 */\n  /* Example:g1_greenlet.stack_prev=main_greenlet */\n  if (ts_current->stack_start == NULL) {\n    /* ts_current is dying */\n    self->stack_prev = ts_current->stack_prev;\n  }\n  else {\n    self->stack_prev = ts_current;\n  }\n  /* 核心代码，进行栈切换 */\n  err = g_switchstack();\n\n  /* 标志greenlet正在运行，将要运行PyEval_CallObjectWithKeywords */\n  self->stack_start = (char*) 1;  /* running\n\n  /* 设置当前运行参数为parent参数 */\n  self->run_info = green_statedict(self->parent);\n  /* 开始执行函数 */\n  /* 注意:可能在该函数运行过程中，存在switch其他的greenlet，否则运行到函数结束 */\n  result = PyEval_CallObjectWithKeywords(\n    run, args, kwargs);\n\n  /* 标志函数结束 */\n  self->stack_start = NULL;  /* dead */\n\n  /* 函数结束切换到parent运行 */\n  for (parent = self->parent; parent != NULL; parent = parent->parent) {\n    result = g_switch(parent, result, NULL);\n}\n\n```\n* 设置当前greenlet的`stack_prev`为`ts_current`，即上一个正在运行的栈\n* `PyEval_CallObjectWithKeywords`过程中可能会切换另一个greenlet，否则函数运行到结束\n\n### `g_switchstack` 分析\n```\nstatic int g_switchstack(void)\n{\n	int err;\n	{   /* save state */\n	    /* 保存线程状态或者说EIP */\n		PyGreenlet* current = ts_current;\n		PyThreadState* tstate = PyThreadState_GET();\n		current->recursion_depth = tstate->recursion_depth;\n		current->top_frame = tstate->frame;\n		current->exc_type = tstate->exc_type;\n		current->exc_value = tstate->exc_value;\n		current->exc_traceback = tstate->exc_traceback;\n	}\n	/* 汇编实现栈切换，分不同平台 */\n	err = slp_switch();\n	if (err < 0) {   /* error */\n		PyGreenlet* current = ts_current;\n		current->top_frame = NULL;\n		current->exc_type = NULL;\n		current->exc_value = NULL;\n		current->exc_traceback = NULL;\n\n		assert(ts_origin == NULL);\n		ts_target = NULL;\n	}\n	else {\n	    /* 恢复线程状态，或者说EIP，即跳转执行位置 */\n		PyGreenlet* target = ts_target;\n		PyGreenlet* origin = ts_current;\n		PyThreadState* tstate = PyThreadState_GET();\n		tstate->recursion_depth = target->recursion_depth;\n		tstate->frame = target->top_frame;\n		target->top_frame = NULL;\n		tstate->exc_type = target->exc_type;\n		target->exc_type = NULL;\n		tstate->exc_value = target->exc_value;\n		target->exc_value = NULL;\n		tstate->exc_traceback = target->exc_traceback;\n		target->exc_traceback = NULL;\n\n		assert(ts_origin == NULL);\n		Py_INCREF(target);\n		ts_current = target;\n		ts_origin = origin;\n		ts_target = NULL;\n	}\n	return err;\n}\n```\n* 保存线程状态，即EIP\n* 进行C栈切换，汇编实现\n* 恢复目标线程状态，即跳转执行位置\n\n### `slp_switch` (核心代码) 分析\n```\nstatic int\nslp_switch(void)\n{\n    /* 下面变量保存在栈(current)中 */\n    int err;\n    void* rbp;\n    void* rbx;\n    unsigned int csr;\n    unsigned short cw;\n    register long *stackref, stsizediff;\n    /* 这里save的是current线程的状态，变量保存在栈中 */\n    __asm__ volatile (\"\" : : : REGS_TO_SAVE);\n    __asm__ volatile (\"fstcw %0\" : \"=m\" (cw));\n    __asm__ volatile (\"stmxcsr %0\" : \"=m\" (csr));\n    __asm__ volatile (\"movq %%rbp, %0\" : \"=m\" (rbp));\n    __asm__ volatile (\"movq %%rbx, %0\" : \"=m\" (rbx));\n    __asm__ (\"movq %%rsp, %0\" : \"=g\" (stackref));\n    {\n        /* 保存当前线程的数据，包括上面的那些寄存器等等数据 */\n        /* 当为new_greenlet直接返回1，无栈可切换 */\n        SLP_SAVE_STATE(stackref, stsizediff);\n\n        /* 重要！current在此暂停，target从此处继续之前的状态之前 */\n        __asm__ volatile (\n            \"addq %0, %%rsp\\n\"\n            \"addq %0, %%rbp\\n\"\n            :\n            : \"r\" (stsizediff)\n            );\n        /* 恢复栈(target)中数据 */\n        SLP_RESTORE_STATE();\n        __asm__ volatile (\"xorq %%rax, %%rax\" : \"=a\" (err));\n    }\n    /* 恢复寄存器变量，这里恢复的是之前保存在target栈中的变量 */\n    /* 恢复了target的esp和ebp，因为变量的保存是以ebp进行偏移寻址中，所以当进行恢复时，进行相同偏移，但是因为ebp为已变为之前的target栈，因而恢复的寄存器也仍为之前的状态。 */\n    __asm__ volatile (\"movq %0, %%rbx\" : : \"m\" (rbx));\n    __asm__ volatile (\"movq %0, %%rbp\" : : \"m\" (rbp));\n    __asm__ volatile (\"ldmxcsr %0\" : : \"m\" (csr));\n    __asm__ volatile (\"fldcw %0\" : : \"m\" (cw));\n    __asm__ volatile (\"\" : : : REGS_TO_SAVE);\n    return err;\n}\n```\n\n很重要的一点，当从恢复ebp和esp开始，current暂停，target继续之前运行，恢复之前数据，恢复的寄存器也仍为之前保存的状态，因为他们是基于ebp的偏移寻址，寻址方式不变，只受ebp的控制。\n\n参考资料：\n---\n[python的Greenlet模块源码分析](http://rootk.com/post/python-greenlet.html)\n\n[greenlet栈帧切换细节](http://114.215.135.238:8001/?p=108)\n','2016-11-10 01:23:36',0),(222,'IPSec VPN搭建','setup-ipsec-vpn',104,'## 安装依赖\n```\nyum update\nyum install pam-devel openssl-devel make gcc\n```\n\n## 安装strongswan\n```\nyum -y install strongswan (strongswan-libipsec,openvz架构需要)\n```\n\n## 生成CA证书\n\n```\nstrongswan pki --gen --outform pem > caKey.pem\nstrongswan pki --self --in caKey.pem --dn \"C=CN, O=strongSwan, CN=strongSwan CA\" --ca --outform pem > caCert.pem\n```\n\n## 生成Server端证书\n\n```\nstrongswan pki --gen --outform pem > serverKey.pem\nstrongswan pki --pub --in serverKey.pem | strongswan pki --issue --cacert caCert.pem --cakey caKey.pem --dn \"C=CN, O=strongSwan, CN=45.32.47.162\" --san=\"45.32.47.162\" --flag serverAuth --flag ikeIntermediate --outform pem > serverCert.pem\n```\n\n## 生成Client端证书\n```\nstrongswan pki --gen --outform pem > clientKey.pem\nstrongswan pki --pub --in clientKey.pem | strongswan pki --issue --cacert caCert.pem --cakey caKey.pem --dn \"C=CN, O=strongSwan, CN=client\" --outform pem > clientCert.pem\n```\n\n## Client证书转换为.p12格式\n```\nopenssl pkcs12 -export -inkey clientKey.pem -in clientCert.pem -name \"client\" -certfile caCert.pem -caname \"strongSwan CA\" -out clientCert.p12\n```\n\n## 安装证书\n\n```\nmv -f caCert.pem /etc/strongswan/ipsec.d/cacerts/\nmv -f serverCert.pem /etc/strongswan/ipsec.d/certs/\nmv -f serverKey.pem /etc/strongswan/ipsec.d/private/\nmv -f clientCert.pem /etc/strongswan/ipsec.d/certs/\nmv -f clientKey.pem /etc/strongswan/ipsec.d/private/\n```\n\n## 配置Strongswan\n```\nbash -c \"cat > /etc/strongswan/ipsec.conf<<EOF\nconfig setup\n    uniqueids=never\nconn iOS_cert\n    keyexchange=ikev1\n    # strongswan version >= 5.0.2, compatible with iOS 6.0,6.0.1\n    fragmentation=yes\n    left=%defaultroute\n    leftauth=pubkey\n    leftsubnet=0.0.0.0/0\n    leftcert=server.cert.pem\n    right=%any\n    rightauth=pubkey\n    rightauth2=xauth\n    rightsourceip=10.31.2.0/24\n    rightcert=client.cert.pem\n    auto=add\nconn android_xauth_psk\n    keyexchange=ikev1\n    left=%defaultroute\n    leftauth=psk\n    leftsubnet=0.0.0.0/0\n    right=%any\n    rightauth=psk\n    rightauth2=xauth\n    rightsourceip=10.31.2.0/24\n    auto=add\nconn networkmanager-strongswan\n    keyexchange=ikev2\n    left=%defaultroute\n    leftauth=pubkey\n    leftsubnet=0.0.0.0/0\n    leftcert=server.cert.pem\n    right=%any\n    rightauth=pubkey\n    rightsourceip=10.31.2.0/24\n    rightcert=client.cert.pem\n    auto=add\nconn windows7\n    keyexchange=ikev2\n    ike=aes256-sha1-modp1024!\n    rekey=no\n    left=%defaultroute\n    leftauth=pubkey\n    leftsubnet=0.0.0.0/0\n    leftcert=server.cert.pem\n    right=%any\n    rightauth=eap-mschapv2\n    rightsourceip=10.31.2.0/24\n    rightsendcert=never\n    eap_identity=%any\n    auto=add\nEOF\"\n```\n\n## 配置Strongswan的配置文件\n\n```\nbash -c \"cat > /etc/strongswan/strongswan.conf<<EOF\n charon {\n         load_modular = yes\n         duplicheck.enable = no\n         compress = yes\n         plugins {\n                 include strongswan.d/charon/*.conf\n         }\n         dns1 = 8.8.8.8\n         dns2 = 8.8.4.4\n         nbns1 = 8.8.8.8\n         nbns2 = 8.8.4.4\n }\n include strongswan.d/*.conf\nEOF\"\n```\n\n## 设置认证方式\n\n```\nbash -c \"cat > /etc/strongswan/ipsec.secrets<<EOF\n: RSA server.pem\n: PSK \\\"seckey\\\"\n: XAUTH \\\"seckey\\\"\nnyt %any : EAP \\\"hello\\\"\njmpews %any : EAP \\\"hello\\\"\nEOF\"\n```\n\n## 调整IPTABLES\n\n```\niptables -A FORWARD -m state --state RELATED,ESTABLISHED -j ACCEPT\niptables -A FORWARD -s 10.31.0.0/24  -j ACCEPT\niptables -A FORWARD -s 10.31.1.0/24  -j ACCEPT\niptables -A FORWARD -s 10.31.2.0/24  -j ACCEPT\niptables -A INPUT -i eth0 -p esp -j ACCEPT\niptables -A INPUT -i eth0 -p udp --dport 500 -j ACCEPT\niptables -A INPUT -i eth0 -p tcp --dport 500 -j ACCEPT\niptables -A INPUT -i eth0 -p udp --dport 4500 -j ACCEPT\niptables -A INPUT -i eth0 -p udp --dport 1701 -j ACCEPT\niptables -A INPUT -i eth0 -p tcp --dport 1723 -j ACCEPT\niptables -A FORWARD -j REJECT\niptables -t nat -A POSTROUTING -s 10.31.0.0/24 -o eth0 -j MASQUERADE\niptables -t nat -A POSTROUTING -s 10.31.1.0/24 -o eth0 -j MASQUERADE\niptables -t nat -A POSTROUTING -s 10.31.2.0/24 -o eth0 -j MASQUERADE\n```\n','2016-11-10 01:23:36',0),(223,'Linux上Juniper的VPN搭建','config-juniper-vpn',104,'最近需要在自己的centos上搭建连接学校juniper-vpn跑一些内网服务。osx和win都可以使用Pulse Connect Secure。\n\n需要使用`OpenConnect`搭建VPN。 http://www.infradead.org/openconnect\n\n\n### Linux下搭建`OpenConnect`\n\n```\n# 安装依赖\nyum install vpnc-script openssl-devel libxml2-devel\napt-get install vpnc-scripts libssl-dev libxml2-dev\n\n# 安装openconnect\nwget http://www.infradead.org/openconnect/download.html\ntar xzvf openconnect-7.06.tar.gz\ncd openconnect\n./configure --with-vpnc-script=/etc/vpnc/vpnc-script --without-gnutls --without-openssl-version-check\nmake\nmake install\n\n# 添加/usr/local/lib到环境变量到.bash_profile 或者 .bashrc\nexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/lib\n\n# 修改策略路由以允许其他服务正常被访问，否则会导致ssh等timeout\n# x.x.x.x is your public IP, y.y.y.y/y is the subnet(IP:101.201.111.225 netmask:255.255.252.0 subnet:101.201.108.0/22), ethX is your public Ethernet interface, and z.z.z. is the default gateway(cat /etc/sysconfig/network)\nip rule add from x.x.x.x table 128\nip route add table 128 to y.y.y.y/y dev ethX #测试发现这一句即使没有也没事，因为ip route就没有关于to的option\nip route add table 128 default via z.z.z.z\n\n# 开启VPN\nopenconnect --juniper --user=xxxx --no-cert-check https://sslvpn.xxx.edu.cn\nopenconnect --juniper --background --pid-file=/var/run/openconnect.pid --quiet --passwd-on-stdin --reconnect-timeout=30 --user=2012241004 --no-cert-check https://sslvpn.sxu.edu.cn\n```\n','2016-11-10 01:23:36',0),(224,'Linux命令笔记','linux-cmd-note',104,'## lsof\n\n```\n#查看所有已经建立的TCP连接(不解析port和host)\nlsof -i -sTCP:ESTABLISHED -P -n\n\n#查看某个进程打开文件\nlsof -p pid\n\n#查看TCP链接状态\nlsof -iTCP -sTCP:ESTABLISHED\n\n#查看某个端口的的连接\nlsof -i :22\n```\n\n## find\n\n```\n查找文件夹下包含某字符串的所有文件\nfind ./ |xargs grep -ri \"str\"\n```\n## ps\n\n```\n查看运行参数\nps -ef |grep mysql\n```\n\n## sudo\n\n```\n以某一个用户权限执行命令\nsudo -u apache ls\n```\n\n## /etc/group & /etc/passwd\n\n```\n# /etc/group 文件详解\n\n#第一字段:用户组名称\n#第二字段:用户组密码\n#第三字段:GID\n#第四字段:用户列表,每个用户之间用,号分割;本字段可以为空,如果字段为空表示用户组为GID的用户名\n\n# 用户组root,没有口令,包含用户root,me以及GID为0的用户(可以通过/etc/passwd查看)\nroot:x:0:root,me\n```\n## grep\n```\n# 查找包含指定字符串的文件\ngrep -n ` find -name \"*.go\"` -e \"ErrTooLong\"\n```\n\n## wc\n```\n# 返回文件行数\nwc -l filename\n```\n## nc\n```\n# 监听本地8001端口，打印请求\nnc -l 8001\n\n# 发送字符串\necho 4wcYUJFw0k0XLShlDzztnTBHiqxU3b3e | nc -vvn 127.0.0.1 30000\n```\n\n## tcp\n```\n# https://en.wikipedia.org/wiki/Transmission_Control_Protocol\n# https://zh.wikipedia.org/wiki/IPv4\n# 根据\'Data offset\'得到TCP-Length, 判断此后四个字节是否为\'GET \'\n# IPython\n# In [0]: [ hex(ord(x)) for x in \'GET \']\n# Out[0]: [\'0x47\', \'0x45\', \'0x54\', \'0x20\']\nsudo tcpdump -X -s 0 -i en0 \'tcp[(tcp[12]>>2):4] = 0x47455420\'\n```\n\n## tree\n```\n# L:显示层数 I:忽略文件\ntree -I \'*.pyc|__*__|node_modules|bower_components\' -L 3\n```\n\n## ssh\n\n```\nservice ssh restart\n```\n\n## find\n\n```\n# 找出文件大小为1033文件\nfind . -name \"*\" -size +1033c\n\n# 找到用户和群组归属的特定文件\nfind / -group bandit6 -user bandit7 -size 33c\n```\n\n## apt-cache\n\n```\n# 查看依赖\napt-cache depends \"build-essential\"\n```\n\n## echo\n\n```\n# 16 2 dec\necho $((16#7f))\n```\n\n## od\n\n```\n# 查看二进制文件\n# -w8 每行显示8个字节\n# -t x 2以16进制显示，每一列包含2个字节\n# -A n 不显示偏移地址\n# -v 显示重复\'0\'行，否则以\'*\'替代\ncat main.o | od -w8 -t x2 -A n -v\n```\n\n## xxd\n\n```\n# 二进制查看文件\n# -c 12每一行包含12个字节\n# -g 4 每一列包含4个字节\nxxd -g 4  -c 12 main.o\n```\n\n## printf\n\n```\n# 进制转换\nprintf \'%d\\n\' 0xd\nprintf \'%x\\n\' 11\n\n# 16进制运算\nprintf \'%x\\n\' $((0xdd-0x7f))\n```\n\n## hexdump\n\n```\n# -C 显示16进制和ASCII\nhexdump -C test.o\n```\n\n## git\n\n```\n# 显示某一个版本的文件\ngit show HEAD^:db/tests/test_mysql.py\n```\n\n## apt-get install\n\n```\n# 安装指定版本\nsudo apt-get install postgresql-common=151.pgdg12.4+1\n\n```\n','2016-11-10 01:23:36',0),(225,'nginx基础笔记','nginx-note',105,'### nginx设置日志格式\n\n```\n# log_format 日志名字 日志格式\nlog_format  torweb  \'$host $remote_addr - $remote_user [$time_local] \"$request\" \'\n					\'$status $body_bytes_sent \"$http_referer\" \'\n					\'\"$http_user_agent\" \"$http_x_forwarded_for\"\';\n\n# 使用特定日志格式\naccess_log  /usr/local/var/log/nginx/torweb.access.log torweb;\n```\n\n### nginx正则重定向\n\n需要实现一个需求: 对于特定的域名访问, 自动跳转到指定的路由, 访问其他路由自动跳到该路由\n\n比如: 访问 `jmpews.com` 自动跳转到 `jmpews.com/blog`, 然而对于 `jmpews.com/blog` 不再进行正则处理. \n\n这里用到几个知识.\n\n1. 正则的零宽断言(`(?=blog)`) \n\n2. 德摩根定: `¬(p∧q)≡¬p∨¬q	¬(p∨q)≡¬p∧¬q` (`((v2)|(assets)|(blog))`)\n\n```\nif ($host ~* \'(www\\.)?jmpews\\.me\') {\n	rewrite \'^(?!/((v2)|(assets)|(blog))/).*\' /blog break;\n}\n```\n\n参考:\n\nhttp://www.isnowfy.com/regular-expression-negative/\n\nhttp://ued.fanxing.com/2016/09/30/nginx_location_rewrite/\n','2016-11-10 01:23:36',0),(226,'Open VPN搭建','install-open-vpn',104,'## 安装依赖\n```\nsudo yum update\nsudo yum install openssl lzo pam pam-devel openssl-devel lzo-devel\nsudo yum install easy-rsa\n```\n\n## 制作证书\n```\ncd /usr/share/easy-rsa/2.0/\n\nvim ./vars\n# 设置EY_COUNTRY, KEY_PROVINCE, KEY_CITY, KEY_ORG, and KEY_EMAIL几个参数\n# These are the default values for fields\n# which will be placed in the certificate.\n# Don\'t leave any of these fields blank.\nexport KEY_COUNTRY=\"CN\"\nexport KEY_PROVINCE=\"BJ\"\nexport KEY_CITY=\"beijing\"\nexport KEY_ORG=\"jmpews\"\nexport KEY_EMAIL=\"jmpews@gmail.com\"\nexport KEY_OU=\"jmpews\"\n# X509 Subject Field\nexport KEY_NAME=\"jmpewsvpn\"\n\n# 使vars生效, 生成证书\n. ./vars\n./clean-all\n./build-ca\n\n```\n\n## 制作服务端证书\n```\n./build-key-server jmpewsvpn\n```\n\n## 制作客户端证书\n```\n./build-key client1\n./build-key client2\n./build-key client3\n```\n\n## 生成Hellman\n```\n./build-dh\n```\n## 剩下按照docs做即可\n\n## 参考资料\n---\nhttps://openvpn.net/index.php/open-source/documentation/howto.html#install\n','2016-11-10 01:23:36',0),(227,'php基础笔记','study-php',106,'如果向八进制数传递了一个非法数字（即 8 或 9），则后面其余数字会被忽略。\n\n# string\n\n```\n// 如果在数组定义中多个单元都使用了同一个键名，则只使用了最后一个，之前的都被覆盖了。\n// 如果对给出的值没有指定键名，则取当前最大的整数索引值，而新的键名将是该值加一。如果指定的键名已经有了值，则该值会被覆盖。\n<?php\n$array = array(\n    1    => \"a\",\n    \"1\"  => \"b\",\n    1.5  => \"c\",\n    true => \"d\",\n);\nvar_dump($array);\n?>\n\n// Output:\narray(1) {\n  [1]=>\n  string(1) \"d\"\n}\n```\n\n```\n$a = array();\n$a[\'color\'] = \'red\';\n$a[\'taste\'] = \'sweet\';\n$a[\'shape\'] = \'round\';\n$a[\'name\']  = \'apple\';\n$a[]        = 4;        // key will be 0\n```\n\n```\n<?php\n// 创建一个简单的数组\n$array = array(1, 2, 3, 4, 5);\nprint_r($array);\n\n// 现在删除其中的所有元素，但保持数组本身不变:\nforeach ($array as $i => $value) {\n    unset($array[$i]);\n}\nprint_r($array);\n\n// 添加一个单元（注意新的键名是 5，而不是你可能以为的 0）\n$array[] = 6;\nprint_r($array);\n\n// 重新索引：\n$array = array_values($array);\n$array[] = 7;\nprint_r($array);\n?>\n```\n\n因为 PHP 自动将裸字符串（没有引号的字符串且不对应于任何已知符号）转换成一个其值为该裸字符串的正常字符串。例如，如果没有常量定义为 bar，PHP 将把它替代为 \'bar\' 并使用之。\n\n使用引用运算符(&)通过引用来拷贝数组。\n','2016-11-10 01:23:36',0),(228,'python中的元类','python-metaclass',107,'### 什么是元类?\n\n```\nclass Test():\n    fool = 1\n\nt = Test()\n\nprint(type(t))\nprint(type(Test))\nprint(type(type))\n```\n\n** t 是 Test 类的实例, 那么 Test 又是谁的实例? **\n\n** t 的类型是 Test, 那么 Test 的类型是什么? **\n\n**Test 是 type 的实例.**\n\n**type 就是元类.**\n\n### 动态生成类\n```\ntype(name of the class,\n    tuple of the parent class (for inheritance, can be empty),\n    dictionary containing attributes names and values)\n\n# Example\ntype(\'Test\', (), {\'fool\': 1})\n```\n\n### 自定义元类\n\n```\nclass Test(type):\n    def __new__(cls, clsname, bases, dct):\n        attrs = {}\n        for name, val in dct.items():\n            if name == \'fool\':\n                attrs[name] = 1\n        return type.__new__(cls, clsname, bases, attrs)\n```\n\n### 使用元类实现ORM\n\n> Foo中有metaclass这个属性吗？如果是，Python会在内存中通过metaclass创建一个名字为Foo的类对象（我说的是类对象，请紧跟我的思路）。如果Python没有找到metaclass，它会继续在Bar（父类）中寻找metaclass属性，并尝试做和前面同样的操作。如果Python在任何父类中都找不到metaclass，它就会在模块层次中去寻找metaclass，并尝试做同样的操作。\n> 如果还是找不到metaclass,Python就会用内置的type来创建这个类对象。\n\n实现如下功能的ORM\n\n```\nclass User(Model):\n    # 定义类的属性到列的映射：\n    id = IntegerField(\'id\')\n    name = StringField(\'username\')\n    email = StringField(\'email\')\n    password = StringField(\'password\')\n\n# 创建一个实例：\nu = User(id=12345, name=\'Michael\', email=\'test@orm.org\', password=\'my-pwd\')\n\n# 保存到数据库：\n# metaclass的发挥作用\nu.save()\n```\n\n具体实现\n\n```\nclass StringField(Field):\n\n    def __init__(self, name):\n        super(StringField, self).__init__(name, \'varchar(100)\')\n\nclass IntegerField(Field):\n\n    def __init__(self, name):\n        super(IntegerField, self).__init__(name, \'bigint\')\n\nclass ModelMetaclass(type):\n\n    def __new__(cls, name, bases, attrs):\n        if name==\'Model\':\n            return type.__new__(cls, name, bases, attrs)\n        print(\'Found model: %s\' % name)\n        mappings = dict()\n        for k, v in attrs.items():\n            if isinstance(v, Field):\n                print(\'Found mapping: %s ==> %s\' % (k, v))\n                mappings[k] = v\n        for k in mappings.keys():\n            attrs.pop(k)\n        attrs[\'__mappings__\'] = mappings # 保存属性和列的映射关系\n        attrs[\'__table__\'] = name # 假设表名和类名一致\n        return type.__new__(cls, name, bases, attrs)\n\nclass Model(dict, metaclass=ModelMetaclass):\n\n    def __init__(self, **kw):\n        super(Model, self).__init__(**kw)\n\n    def __getattr__(self, key):\n        try:\n            return self[key]\n        except KeyError:\n            raise AttributeError(r\"\'Model\' object has no attribute \'%s\'\" % key)\n\n    def __setattr__(self, key, value):\n        self[key] = value\n\n    def save(self):\n        fields = []\n        params = []\n        args = []\n        for k, v in self.__mappings__.items():\n            fields.append(v.name)\n            params.append(\'?\')\n            args.append(getattr(self, k, None))\n        sql = \'insert into %s (%s) values (%s)\' % (self.__table__, \',\'.join(fields), \',\'.join(params))\n        print(\'SQL: %s\' % sql)\n        print(\'ARGS: %s\' % str(args))\n```\n\n### 参考\n\n参考链接:\n\nhttps://github.com/xiyoulaoyuanjia/blog/blob/master/%E7%90%86%E8%A7%A3python%E4%B8%AD%E7%9A%84%E5%85%83%E7%B1%BB.md\n\nhttp://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000/0014319106919344c4ef8b1e04c48778bb45796e0335839000\n','2016-11-10 01:23:36',0),(229,'Python单元测试以及Mock','python-unittest-mock',107,'## Summary(基本单元测试):\n\n* 测试可以保证你的代码在一系列给定条件下正常工作(**e:保证基本功能正确**)\n* 测试允许人们确保对代码的改动不会破坏现有的功能(**e:保证在修改的过程中,功能不变**)\n* 测试迫使人们在不寻常条件的情况下思考代码，这可能会揭示出逻辑错误(**e:传入不同参数或边界参数**)\n* 良好的测试要求模块化，解耦代码，这是一个良好的系统设计的标志(**e:模块化设计**)\n\n通过一段代码来对比上面\n\n```\nimport unittest\n\n\ndef double_div(a, b):\n    return a / b / b\n\n\nclass TestBase(unittest.TestCase):\n    def setUp(self):\n        \'\'\'\n        Test之前的初始化\n        \'\'\'\n        self.a = 4\n        self.b = 2\n\n    def test_double_div_default(self):\n        self.assertEqual(1, double_div(self.a, self.b), \'Not 1\')\n\n    def test_double_div_1_2(self):\n        self.assertEqual(0.04, double_div(1, 5), \'Not 0.04\')\n\n    def test_double_div_1_2_double(self):\n        self.assertEqual(0.04, double_div(1.0, 5), \'Not 0.04\')\n\n    def test_double_div_1_0(self):\n        self.assertEqual(0, double_div(1, 0), \'Not 0\')\n\n\nif __name__ == \'__main__\':\n        unittest.main()\n\n```\n\n结果:\n\n```\n$ python python_unittest.py\nEF..\n======================================================================\nERROR: test_double_div_1_0 (__main__.TestBase)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"python_unittest.py\", line 28, in test_double_div_1_0\n    self.assertEqual(0, double_div(1, 0), \'Not 0\')\n  File \"python_unittest.py\", line 7, in double_div\n    return a / b / b\nZeroDivisionError: integer division or modulo by zero\n\n======================================================================\nFAIL: test_double_div_1_2 (__main__.TestBase)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"python_unittest.py\", line 22, in test_double_div_1_2\n    self.assertEqual(0.04, double_div(1, 5), \'Not 0.04\')\nAssertionError: Not 0.04\n\n----------------------------------------------------------------------\nRan 4 tests in 0.000s\n```\n\n## Mock测试\n\n基本用法说就是\'模拟伪造\'对象，模仿这个对象的返回值、属性等。这样可以避免一些副作用和耗时操作，比如:删除文件(remove)等\n\n```\nimport unittest\nimport mock\nimport requests\nimport json\n\n\ndef get_name(uuid):\n    r = requests.get(\'http://example.com\')\n    user_name = json.loads(r.text)\n    return user_name\n\n\ndef check_user_info(uuid):\n    print(uuid)\n    username = get_name(uuid)\n    print(username)\n    if username == \'admin\':\n        return True\n    else:\n        return False\n\n\nclass TestUserInfo(unittest.TestCase):\n    def setUp(self):\n        self.uuid = \'1234\'\n\n    @mock.patch(\'__main__.get_name\')\n    def test_check_user_info(self, mock_get_name):\n        mock_get_name.return_value = \'jmpews\'\n        result = check_user_info(self.uuid)\n        mock_get_name.assert_called_once_with(self.uuid)\n        self.assertTrue(result, msg=\'> Check False!\')\n\n\nif __name__ == \'__main__\':\n    unittest.main()\n```\n### 参考文章:\n---\n[Python3.4的unittest.mock官方文档](https://docs.python.org/3.4/library/unittest.mock-examples.html)\n\n[Python Mock的入门(很详细,推荐)](https://segmentfault.com/a/1190000002965620)\n\n[Python中如何创建mock?](http://code.oneapm.com/python/2015/06/11/python-mock-introduction/)\n','2016-11-10 01:23:36',0),(230,'Python引用计数理解','reference-count',107,'# Summary\n引用计数记录指向对象引用的个数，当变为0，则被释放。总结了引用计数的注意点和如何使用。更新：weakref(弱引用)、用弱引用解决引用环问题\n\n# 简介\n> It counts how many different places there are that have a reference to an object.When an object’s reference count becomes zero, the object is deallocated\n\n> 记录指向对象引用的个数，当变为0，则被释放\n\n# 使用引用计数的实质\n> The only real reason to use the reference count is to prevent the object from being deallocated as long as our variable is pointing to it\n\n> 使用引用计数的唯一理由就是只要还有变量指向就应当阻止对象被释放\n\n# 引用计数的实现\n* PyObject* 是什么?\n* 引用计数变量 **ob_refcnt**\n* 如何操作ob_refcnt (Py_INCREF and Py_DECREF)\n\n## 0x00. PyObject* 是什么?\n> This type is a pointer to an opaque data type representing an **arbitrary Python object**. Since all Python object types are treated **the same way** by the Python language in most situations (e.g., assignments, scope rules, and argument passing), it is only fitting that they should be represented by a single C type. Almost all **Python objects live on the heap**: you never declare an automatic or static variable of type PyObject, only pointer variables of type **PyObject* **can be declared.\n\n> 这种数据类型是可以表示任意Python对象的封装数据类型，因此Python对象类型在大多数情况下以相同方式处理。几乎全部的Python的对象存储在**heap堆(由程序员分配malloc)**，因此不可以声明一个PyObject的类型对象(局部变量值保存在stack)，只能是**PyObject* **\n\n## 0x01. 引用计数变量 `**ob_refcnt**`\n```\ntypedef struct _object {\n    _PyObject_HEAD_EXTRA\n    Py_ssize_t ob_refcnt;\n    struct _typeobject *ob_type;\n} PyObject;\n```\n\n## 0x02. 如何操作`ob_refcnt (Py_INCREF and Py_DECREF)`\n```\n#define Py_INCREF(op) (                         \\\n    _Py_INC_REFTOTAL  _Py_REF_DEBUG_COMMA       \\\n    ((PyObject *)(op))->ob_refcnt++)\n\n#define Py_DECREF(op)                                   \\\n    do {                                                \\\n        PyObject *_py_decref_tmp = (PyObject *)(op);    \\\n        if (_Py_DEC_REFTOTAL  _Py_REF_DEBUG_COMMA       \\\n        --(_py_decref_tmp)->ob_refcnt != 0)             \\\n            _Py_CHECK_REFCNT(_py_decref_tmp)            \\\n        else                                            \\\n        _Py_Dealloc(_py_decref_tmp);                    \\\n    } while (0)\n```\n# 什么时候操作引用计数\n**仅有当你需要保护这个变量不被释放时才使用INCREF**\n\n具体：\n* 创建一个Object* 对象\n* 处理函数返回的对象\n* 借用引用(borrow)\n* 偷取引用(Steal)\n\n注: 不需要对每个**本地变量(stack变量)**的引用+1，因为当一个变量创建并且有一个指针指向时，默认INC，然而当变量失去作用范围(stack栈)又会DEC，两者抵消。\n\n## 0x00. 创建一个Object* 对象\n### Example1: 源码分析\n#### 0x0000.针对long类型变量分析\n```\nPyObject *l, *x;\nx = PyLong_FromLong(1L);\n```\n#### 0x0001. PyLong_FromLong() [longobject.c]\n调用_PyLong_New()创建新long对象\n```\nPyObject *\nPyLong_FromLong(long ival)\n{\n    PyLongObject *v;\n    ...\n    //something done\n        v = _PyLong_New(1);\n    ...\n    //something done\n    return (PyObject *)v;\n}\n```\n#### 0x0002. _PyLong_New() [longobject.c]\n调用**PyObject_MALLOC()**分配内存，调用**PyObject_INIT_VAR()**初始化为PyLongOject\\*类型，完成PyObject*相关项的初始化，比如类型项等等。\n\n**注：**关于**PyObject_MALLOC()[obmalloc.c]**，采用**内存池**进行内存管理，此处不详细介绍\n[Python内存管理](http://blog.csdn.net/dbzhang800/article/details/6685269)\n\n```\nPyLongObject *\n_PyLong_New(Py_ssize_t size)\n{\n    PyLongObject *result;\n    if (size > (Py_ssize_t)MAX_LONG_DIGITS) {\n        PyErr_SetString(PyExc_OverflowError,\n                        \"too many digits in integer\");\n        return NULL;\n    }\n    result = PyObject_MALLOC(offsetof(PyLongObject, ob_digit) +\n                             size*sizeof(digit));\n    if (!result) {\n        PyErr_NoMemory();\n        return NULL;\n    }\n    return (PyLongObject*)PyObject_INIT_VAR(result, &PyLong_Type, size);\n}\n```\n#### 0x0003. PyObject_INIT_VAR() [objimp.h]\n\n```\n#define PyObject_INIT(op, typeobj) \\\n    ( Py_TYPE(op) = (typeobj), _Py_NewReference((PyObject *)(op)), (op) )\n#define PyObject_INIT_VAR(op, typeobj, size) \\\n    ( Py_SIZE(op) = (size), PyObject_INIT((op), (typeobj)) )\n```\n#### 0x0004. 宏展开(Macro Expansion) Py_TYPE() _Py_NewReference() [object.h]\n最终发现调用创建PyObject\\*变量时 **初始化op_refcnt为1**\n\n```\n#define Py_TYPE(ob)             (((PyObject*)(ob))->ob_type)\n#define Py_REFCNT(ob)           (((PyObject*)(ob))->ob_refcnt)\n#define _Py_NewReference(op) (                          \\\n    _Py_INC_TPALLOCS(op) _Py_COUNT_ALLOCS_COMMA         \\\n    _Py_INC_REFTOTAL  _Py_REF_DEBUG_COMMA               \\\n    Py_REFCNT(op) = 1)\n```\n\n## 0x01. 处理函数返回的对象\n很多函数在返回之前会调用Py_INCREF()，因此该函数的caller需要调用Py_DECREF(),以防内存泄露(memory leak)\n### Example1: MyCode必须处理pyo，调用Py_DECREF\n\n```\nvoid MyCode(arguments)\n{\n    PyObject* pyo;\n    ...\n    pyo = Py_Something(args);\n    //Py_DECREF(pyo);\n}\n```\n###  Example2: 如果MyCode传递pyo的所有权，则不能调用Py_DECREF\n\n```\nPyObject* MyCode(arguments) {\n    PyObject* pyo;\n    ...\n    pyo = Py_Something(args);\n    ...\n    return pyo;\n}\n```\n#### 注: 函数返回None则返回之前需要Py_INCREF(Py_None)\n[Py_INCREF(Py_None) from stackoverflow](http://stackoverflow.com/questions/15287590/why-should-py-increfpy-none-be-required-before-returning-py-none-in-c)\n\n```\nPy_INCREF(Py_None);\nreturn Py_None;\n```\n\n## 0x02. 借用引用(borrow)\n**仅获得拷贝，引用计数不增加**\n\n产生借用:\n\n* 返回借用引用对象的函数[borrow]\n* 传递给函数的对象[borrow]\n\n### 0x000. 返回借用引用对象的函数[borrow]\n* PyTuple_GetItem()\n* PyList_GetItem()\n* PyList_GET_ITEM()\n* PyList_SET_ITEM()\n* PyDict_GetItem()\n* PyDict_GetItemString()\n* PyErr_Occurred()\n* PyFile_Name()\n* PyImport_GetModuleDict()\n* PyModule_GetDict()\n* PyImport_AddModule()\n* PyObject_Init()\n* Py_InitModule()\n* Py_InitModule3()\n* Py_InitModule4()\n* PySequence_Fast_GET_ITEM()\n\n#### Example1: PyList_GetItem仅获得对应项目拷贝，不增加引用计数\n\n```\nlong sum_list(PyObject *list)\n{\n int i, n;\n long total = 0;\n PyObject *item;\n\n n = PyList_Size(list);\n if (n < 0)\n     return -1; /* Not a list */\n     /* Caller should use PyErr_Occurred() if a -1 is returned. */\n for (i = 0; i < n; i++) {\n     /* PyList_GetItem does not INCREF \"item\".\n        \"item\" is unprotected and borrowed. IMPORTANT!!! */\n     item = PyList_GetItem(list, i); /* Can\'t fail */\n     if (PyInt_Check(item))\n         total += PyInt_AsLong(item);\n }\n return total;\n}\n```\n#### Example2: PySequence_GetItem获得对象所有权，其返回对象+1，因而每次循环后需要-1.\n\n```\nlong sum_sequence(PyObject *sequence)\n{\n int i, n;\n long total = 0;\n PyObject *item;\n n = PySequence_Length(sequence);\n if (n < 0)\n     return -1; /* Has no length. */\n     /* Caller should use PyErr_Occurred() if a -1 is returned. */\n for (i = 0; i < n; i++) {\n     /* PySequence_GetItem INCREFs item.  IMPORTANT!!!*/\n     item = PySequence_GetItem(sequence, i);\n     if (item == NULL)\n         return -1; /* Not a sequence, or other failure */\n     if (PyInt_Check(item))\n         total += PyInt_AsLong(item);\n     Py_DECREF(item);\n }\n return total;\n}\n```\n\n### 0x001. 传递给函数的对象[borrow]\n> Most functions assume that the arguments passed to them are already protected.Therefore Py_INCREF() is not called inside Function unless Function wants the argument to continue to exist after Caller exits. In the documentation, Function is said to borrow a reference:\n> **大多数函数假定传入函数的参数都是受保护的不需要INCREF，除非希望参数在函数exit后仍然存在。官方文档说法是函数借用引用**\n\n> When you pass an object reference into another function, in general, the function borrows the reference from you   if it needs to store it, it will use Py_INCREF() to become an independent owner.\n> **你传递对象给一个函数，一般情况来说是函数借用引用，如果你希望保存那么请INCREF，将其变为独立拥有者。**\n\n**PyTuple_SetItem()和PyList_SetItem()**除外，它们**接管传入对象所有权(take over responsibility) or 偷取引用(steal a reference)**\n详细见下\n\n## 0x03. 偷取引用(Steal)\n**PyTuple_SetItem(tuple,i,item)和PyList_SetItem()接管所有权(take over responsibility) or 偷取引用(steal a reference) item引用**，but not to the tuple or list into which the item is put，即仅仅偷取item引用.\n\n* PyDict_SetItem()非借用，既然是store变量到dict，因此PyDict_SetItem() INCREF它的kye和value\n* 但是PyTuple_SetItem()和PyList_SetItem()比较特殊，接管所有权(take over responsibility) or 偷取引用(steal a reference)\n* PyTuple_SetItem(tuple,i,item)实现：如果tuple[i]存在PyObject则DECREF，然后tuple[i]设置为item。并且Item并没有INCREF\n* PyTuple_SetItem(tuple,i,item)既然是steal，那么**Item之前必须有所有权**\n* 如果PyTuple_SetItem()插入item失败，则DECREF item引用计数\n* PyTuple_SetItem()是设置Tuple中item的唯一方法\n\n### Example1:\n你不需要调用DECREF(x)，PyTuple_SetItem()已经自动调用了,当Tuple被DECREF时，它的item也会被DECREF\n\n```\nPyObjetc *t;\nPyObject *x;\nx=PyIntFromLong(1L);\nPyTuple_SetItem(t,0,x);\n```\n# 总结\n* 许多从**其他对象上提取子对象**的函数，通过引用传递所有权，但有一些例外，**PyTuple_GetItem(),PyList_GetItem(),PyDict_GetItem()，和PyDict_GetItemString()**，这些返回的引用是从tuple，list或dict中**借用**的.(借用仅获得拷贝，引用计数并不增加)\n* 当你传递一个对象引用给其他函数，这个函数会从借用这个引用，如果需要保存它应该使用Py_INCREF()转换为独立拥有者。但是有例外，**PyTuple_SetItem()和PyList_SetItem()**，直接传递对象所有权\n* Python调用一个C函数的返回对象必须拥有引用所有权传递给它的调用者    \n\n# 常见问题\n## 0x00. INCREF不可马虎\n常见的情况是从list中提取对象，一些操作符可以能会替换或者移除list中某个对象，并且假如这个向对象是用户自定义的calss，包含__del__，然而这个__del__可以执行任意的code，但是这些操作可能会无意的DEC 该list[0]的引用计数，导致free。\n\n```\nbug(PyObject *list) {\n/*item利用PyList_GetItem借用list引用*/\n PyObject *item = PyList_GetItem(list, 0);\n //修改措施Py_INCREF(item); /* Protect item. */\n /* This function “steals” a reference to item and discards a reference to an item already in the list at the affected position.\n 可能引起list中原list[1]中__del__，导致DEClist[0]*/\n PyList_SetItem(list, 1, PyInt_FromLong(0L));\n PyObject_Print(item, stdout, 0); /* BUG! */\n //修改措施:Py_DECREF(item);\n}\n```\n## 0x01. 偷取和借用对比在build list or tuple方面\n### Example1: steal a referfence(take over responsibilty)\n\n```\nPyObjetc *t;\nPyObject *x;\nx=PyIntFromLong(1L);\nPyTuple_SetItem(t,0,x);\n//Dont\'t Need Py_DECREF()\n```\n### Example2 borrow a reference\n\n```\n/*Better way*/\n\nPyObject *l, *x;\nl = PyList_New(3);\nx = PyInt_FromLong(1L);\nPySequence_SetItem(l, 0, x); Py_DECREF(x);\nx = PyInt_FromLong(2L);\nPySequence_SetItem(l, 1, x); Py_DECREF(x);\nx = PyString_FromString(\"three\");\nPySequence_SetItem(l, 2, x); Py_DECREF(x);\n```\n### 注: 更常见的创建list和tuple的方法\nMore Common Way to Populate a tuple or list\n\n```\nPyObject *t, *l;\nt = Py_BuildValue(\"(iis)\", 1, 2, \"three\");\nl = Py_BuildValue(\"[iis]\", 1, 2, \"three\");\n```\n# Refer:\n[Reference Counting in Python](http://edcjones.tripod.com/refcount.html)\n\n[Extending Python with C or C++](http://www.incoding.org/admin/archives/808.html)\n\n## Two Examples\n\n### Example 1\n\nThis is a pretty standard example of C code using the Python API.\n\n```\nPyObject*\n    MyFunction(void)\n    {\n        PyObject* temporary_list=NULL;\n        PyObject* return_this=NULL;\n\n        temporary_list = PyList_New(1);          /* Note 1 */\n        if (temporary_list == NULL)\n            return NULL;\n\n        return_this = PyList_New(1);             /* Note 1 */\n        if (return_this == NULL)\n            Py_DECREF(temporary_list);           /* Note 2 */\n            return NULL;\n        }\n\n        Py_DECREF(temporary_list);               /* Note 2 */\n        return return_this;\n    }\n```\n* Note 1: The object returned by PyList_New has a reference count of 1.\n* Note 2: Since temporary_list should disappear when MyFunction exits, it must be DECREFed before any return from the function. If a return can be reached both before or after temporary_list is created, then initialize temporary_list to NULL and use Py_XDECREF().\n\n### Example 2\n\n```\nThis is the same as Example 1 except PyTuple_GetItem() is used.\n    PyObject*\n    MyFunction(void)\n    {\n        PyObject* temporary=NULL;\n        PyObject* return_this=NULL;\n        PyObject* tup;\n        PyObject* num;\n        int err;\n        tup = PyTuple_New(2);\n        if (tup == NULL)\n            return NULL;\n        err = PyTuple_SetItem(tup, 0, PyInt_FromLong(222L));\n        /* Note 1 */\n        if (err) {\n            Py_DECREF(tup);\n            return NULL;\n        }\n        err = PyTuple_SetItem(tup, 1, PyInt_FromLong(333L));\n        /* Note 1 */\n        if (err) {\n            Py_DECREF(tup);\n            return NULL;\n        }\n        temporary = PyTuple_Getitem(tup, 0);\n        /* Note 2 */\n        if (temporary == NULL) {\n            Py_DECREF(tup);\n            return NULL;\n        }\n        return_this = PyTuple_Getitem(tup, 1);\n        /* Note 3 */\n        if (return_this == NULL) {\n            Py_DECREF(tup);\n            /* Note 3 */\n            return NULL;\n        }\n        /* Note 3 */\n        Py_DECREF(tup);\n        return return_this;\n    }\n```\n\n* Note 1: If PyTuple_SetItem fails or if the tuple it created is DECREFed to 0, then the object returned by **PyInt_FromLong is DECREFed**.\n* Note 2: PyTuple_Getitem does not increment the reference count for the object it returns.\n* Note 3: You have no responsibility for DECFREFing temporary.\n\n\n# 更新\n### 1. 弱引用\n> 弱引用与强引用相对，指不能确保其引用对象不会被垃圾回收器回收，一个对象若只被弱引用所引用，则被认为是不可访问的。 --wiki\n\n#### 弱引用解决引用环问题\n```\n# python2.x会出现，python3.x做了改进\nclass LeakTest(object):\n   def __init__(self):\n     print \'Object with id %d born here.\' % id(self)\n   def __del__(self):\n     print \'Object with id %d dead here.\' % id(self)\n\ndef foo():\n   A = LeakTest()\n   B = LeakTest()\n   A.b = B\n   B.a = A\nif __name__ = =\"__main__\":\n  foo()\n\nRESULT:\nObject with id 10462448 born here.\nObject with id 10462832 born here.\n```\n相互引用导致形成环，当对象只有被弱引用时，同样会被回收,因此可做如下修改\n\n```\nimport weakref\nclass LeakTest(object):\n   def __init__(self):\n     print \'Object with id %d born here.\' % id(self)\n   def __del__(self):\n     print \'Object with id %d dead here.\' % id(self)\n\ndef foo():\n   A = LeakTest()\n   B = LeakTest()\n   A.b = weakref.proxy(B)\n   B.a = weakref.proxy(A)\nif __name__ = =\"__main__\":\n  foo()\n```\n#### 弱引用对象使用\n弱引用和代理对象都可以设置callback，在没有强引用时，python要进行销毁时调用。\n\n```\n>>> from socket import *\n>>> import weakref\n>>> s=socket(AF_INET,SOCK_STREAM)\n>>> ref=weakref.ref(s) # 通过调用弱引用来获取被弱引用的对象\n>>> pref=weakref.proxy(s) #代理对象就是弱引用对象\n>>> s\n<socket.socket fd=8, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=(\'0.0.0.0\', 0)>\n>>> ref\n<weakref at 0x103275598; to \'socket\' at 0x10325aee8>\n>>> ref()\n<socket.socket fd=8, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=(\'0.0.0.0\', 0)>\n>>> pref\n<weakproxy at 0x103275548 to socket at 0x10325aee8>\n```\n','2016-11-10 01:23:36',0),(231,'抓取英雄联盟的妹纸信息','crawler-lol-girls',107,'首先我觉得做爬虫很容易，难点在于如果把爬虫做的有意义，抓取到有价值的信息。两方面，一方面对自己可以数据分析，提炼价值，然而对个人而言好像没卵用，另一方面，可以整合信息，数据二次整理展现，面向用户。\n\n---\n\n### 8.30:\n完成了基本的线程池、任务队列、任务产生py、任务消耗py。更新github\n\n[爬取LoL中girls](https://github.com/jmpews/lolgirl)\n\n### 8.31:\n在编写程序发现几个注意点。\n\n1. 重视模块化，一个函数仅仅实现一个功能就ok\n2. 如果某个地方可能出现异常需要打上标记 TODO等\n3. `time.mktime(time.strptime(timestr,\'%Y-%m-%d %H:%M:%S\'))`字符串转化为时间戳\n\n\n## redis任务队列的设计\n```\n__author__ = \'jmpews\'\nimport redis\n\nclass RedisQueue(object):\n    def __init__(self,name,namespace=\'queue\',**redis_kwargs):\n        self.__db=redis.StrictRedis(host=\'linevery.com\', port=6379, db=0)\n        self.key = \'%s:%s\' % (name,namespace)\n\n    def qsize(self):\n        return self.__db.llen(self.key)\n\n    def empty(self):\n        return self.qsize()==0\n\n    def put(self,item):\n        self.__db.rpush(self.key,item)\n    # 阻塞至超时\n    def get(self,block=True,timeout=None):\n        if block:\n            item=self.__db.blpop(self.key,timeout=timeout)\n            item=item[1]\n        else:\n            item=self.__db.lpop(self.key)\n\n        # item=item[1]\n        return item\n        \n    # 无阻塞的get	 \n    def get_notwait(self):\n        return self.get(block=False)\n\n```\n\n# threadpool线程池的设计\n```\n__author__ = \'jmpews\'\nimport threading\nfrom logger import initLogging\n\n# log file\nloggg=initLogging(\'threadpool.log\')\n\n# 初始化工作函数和线程数\nclass ThreadPool(object):\n    def __init__(self,func=None,thread_num=5):\n        self.threads=[]\n        if func==None:\n            self.func=None\n            print(\'Error : func is None...\')\n            return\n        self.func=func\n        self.__init_threads(thread_num)\n\n    def __init_threads(self,thread_num=5):\n        for i in range(thread_num):\n            self.threads.append(Worker(self.func))\n\n    def start(self):\n        if self.func==None:\n            print(\'func is None...\')\n            return\n        for one in self.threads:\n            one.start()\n\n# 线程实例\nclass Worker(threading.Thread):\n    def __init__(self,func=None):\n        self.func=func\n        threading.Thread.__init__(self)\n\n    def run(self):\n        while True:\n            try:\n                self.func()\n            except Exception as e:\n                loggg.error(e)\n                import traceback\n                traceback.print_exc()\n            print(\'=======\'+self.name+\'Done!=======\')\n\n# 测试函数\ndef test():\n    def func():\n        print(\'oh,yes!\')\n    threadpool=ThreadPool(func=func)\n    threadpool.start()\n\n#test()\n```\n\n## logging日志记录设计\n```\n__author__ = \'jmpews\'\nimport logging\ndef initLogging(logFilename=\'run.log\'):\n    \"\"\"Init for logging\"\"\"\n\n    # logging.basicConfig(\n    #     level = logging.NOTSET,\n    #     format = \'LINE %(lineno)-4d  %(levelname)-8s %(message)s\',\n    #     datefmt = \'%m-%d %H:%M\',\n    #     filename = logFilename,\n    #     filemode = \'w\')\n\n    logger=logging.getLogger()\n    # 格式\n    formatter = logging.Formatter(\'LINE %(lineno)-4d : %(levelname)-8s %(message)s\')\n    # 输出到文件里\n    logfile=logging.FileHandler(logFilename)\n    logfile.setLevel(logging.NOTSET)\n    logfile.setFormatter(formatter)\n\n    console = logging.StreamHandler()\n    console.setLevel(logging.NOTSET)\n    console.setFormatter(formatter)\n\n    logger.addHandler(console)\n    logger.addHandler(logfile)\n    return logger\n```\n','2016-11-10 01:23:36',0),(232,'Python进阶笔记','python-note',107,'### 1. class是type的instance\n类也是对象\n代码解释，解释器会在类创建末尾添加下面一句话啊。type创建一个type实例(即:calss className)，type也存在`__new__`(实例化type)，`__int__`(初始化类)。\n\n`class = type(className, superClasses, attributeDict)`\n\n### 2. `__new__()`实例化\n* object是所有类的基类`\n* 依次向上调用`__new__实例化类，若父没有定义，则继续直至object基类\n* 不能调用自身的`__new__`来实例化对象。`cls.__new__(cls, *args, **kwargs)`这样不可行\n\n```\n# cls当前正在实例化的类\ndef __new__(cls, *args, **kwargs):\n    ...  \n```\n\n### 3. super继承\n对于单继承，当父类修改名字可以避免多次修改\n\n```\nclass Base(object):\n    def __init__(self):\n        print \"Base created\"\n\nclass ChildA(Base):\n    def __init__(self):\n        Base.__init__(self)\n\nclass ChildB(Base):\n    def __init__(self):\n        # Python3 可以直接使用super().__init__()\n        super(ChildB, self).__init__()\n\nChildA() \nChildB()\n```\n对于多继承,采用mro顺序调用，相同父类只调用一次\n\n```\nclass D(A,B,C):\n    def __init__(self):\n        super(D，self).__init__()\n```\n### 4. dict的遍历方式\n\n#### 1.采用for遍历dict\n不可以在遍历的过程中进行修改\n\n```\ndict={1:\'a\',2:\'b\',3:\'c\'}\n\ndef add_handler():\n    dict[4]=\'d\'\n		\nfor k,v in dict.items():\n    if k==3:\n        add_handler()\n    print(k,v)\n```\n结果\n\n```\nTraceback (most recent call last):\n1 a\n  File \"/Users/jmpews/PycharmProjects/asyncnet/test.py\", line 15, in <module>\n    for k,v in dict.items():\n2 b\nRuntimeError: dictionary changed size during iteration\n3 c\n\nProcess finished with exit code 1\n```\n#### 2.采用popitem遍历\n可以在遍历过程中对dict进行修改，但是遍历后，dict为空\n\n```\ndict={1:\'a\',2:\'b\',3:\'c\'}\n\ndef add_handler():\n    dict[4]=\'d\'\n\nwhile dict:\n    k,v=dict.popitem()\n    if k==3:\n        add_handler()\n    print(k,v)\n\nprint(dict)\n```\n结果\n\n```\n1 a\n2 b\n3 c\n4 d\n{}\n```\n### 5. 装饰器高级特性\n用装饰器我们可以很好的做一些预处理，但仍然有一些小问题需要我们处理，比如装饰器修饰后函数的`__name__`和`__doc__`属性，我们可以手动`return functools.update_wrapper(_wrapper,func)`，也可以采用`@functools.wraps(_wrapper)`。\n\n```\ndef hello(func):\n    def _wrapper(*args,**kwargs):\n        import inspect\n        # 将参数转化为字典类型\n        func_args=inspect.getcallargs(func,*args,**kwargs)\n        if func_args:\n            for k,v in func_args.items():\n                print(\'key=\',k,\'value=\',v)\n        print(\'hello call \',func.__name__)\n        return func(*args,**kwargs)\n    import functools\n    # 更新装饰器的__name__等属性\n    return functools.update_wrapper(_wrapper,func)\n\n@hello\ndef function(name):\n    print(\'my name is\',name)\n\nfunction(\'Amy\')\n\nprint(function.__name__)\n```\n结果\n\n```\nkey= name value= Amy\nhello call  function\nmy name is Amy\nfunction\n\n```\n### 6. classmethod与工厂方法\n工厂方法把选择具体实现的功能延迟到子类去实现。\n\n```\nclass Pizza(object):\n	def __init__(self,ing):\n		self.ing=ing;\n	@classmethod\n	def from_fridge(cls,fridge):\n		return cls(fridge.get_a()+fridge.get_b())\n		\nclass A_Pizza(Pizza):\n	pass\n	\nA_Pizza.from_fridge(fridge)\n```\n\n### 7. 简单工厂模式和抽象工厂模式\n[抽象工厂模式](http://www.cnblogs.com/jerryxing/archive/2013/01/23/2873408.html)\n\n### 8. with的使用\n```\nclass LockContext(object):\n    def __init__(self, lock):\n        self.lock = lock\n\n    def __enter__(self):\n        self.Lock()\n\n    def __exit__(self, type, value, traceback):\n        if type != None:\n            pass\n        self.Unlock()\n        return False\n```\n\n也可以使用`contextmanager`，使用yield返回值\n\n```\n@contextmanager\n    def locked(lock):\n        lock.acquire()\n        try:\n            yield values\n        finally:\n            lock.release()\n```\n\n### 11. `locals()`返回局部变量字典，包含所有键值对\n\n### 12. `time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())`\n\n### 13. python进制相关\n\'\\x2d\' 主要是用来表是一个不能直接显示的单字节字符的编码 \n\n\'0x2d\' 应该算是一个标准的16进制表示的字符串，可以通过int(\'0x2d\', 16) 转换为int 类型的值\n\n```\n65=ord(\'A\')\n```\n\n### 14.生成器\n```\ndef mygenerator():\n    yield 1\n\ngen=mygenerator()\nimport inspect\ninspect.getgeneratorstate(gen)\n```\n### 15.参数传入\n```\ndef foo(*args, **kwargs):\n    print \"Positional arguments are:\"\n    print args\n    print \"Keyword arguments are:\"\n    print kwargs\n\n#可以看出args为元组，**kwargs为字典    \n>>> foo(1, 2, 3)\nPositional arguments are:\n(1, 2, 3)\nKeyword arguments are:\n{}\n>>> foo(1, 2, name=\'Adrian\', framework=\'Django\')\nPositional arguments are:\n(1, 2)\nKeyword arguments are:\n{\'framework\': \'Django\', \'name\': \'Adrian\'}\n```\n\n### 16. 系统路径\n```\nglob 查找路径\n```\n### 17. 对**理解,表示列表参数\n\n```\na,*b,c=[1,2,3,4]\n# 巧妙的递归\nitems=[1,2,3,4,5,6,7,8]\ndef sum(items):\n    head,*rest=items\n    return head+sum(rest) if rest else head\n\n```\n','2016-11-10 01:23:36',0),(233,'React基础笔记','react-note',108,'使用react必须要正确的**抽象组件**\n### `props`\n父组件向子组件传递数据.\n\n### `input`默认值的设置\n`defaultValue`仅在load的时候执行一次，不会根据state进行更新。这里可以使用refs来获取到真实dam，然后`this.ref.username.value=\'test\'`\n','2016-11-10 01:23:36',0),(234,'Redis基础笔记','redis-python',109,'## 1.Pipelines\n> Pipelines are a subclass of the base Redis class that provide support for buffering multiple commands to the server in a single request.\n\n```\npipe=r.pipeline()\npipe.set(\'a\',1)\npipe.set(\'b\',2)\npipe.get(\'a\')\npipe.get(\'b\')\npipe.execute()\n#[True, True, b\'1\', b\'2\']\n```\n\n## 2.事务\n\n**Important:事务中每个命令的执行结果都是最后一起返回的，无法讲前一条命令的结果作为下一条命令的参数。**\n\n事务实现`incr()`，不能在事务中实现+1的操作。`watch`监视一个变量直到`execute()`,如果在此期间变量值被修改则异常。\n\n```\nwith r.pipeline() as pipe:\n    while 1:\n        try:\n            # put a WATCH on the key that holds our sequence value\n            pipe.watch(\'OUR-SEQUENCE-KEY\')\n            # after WATCHing, the pipeline is put into immediate execution\n            # mode until we tell it to start buffering commands again.\n            # this allows us to get the current value of our sequence\n            current_value = pipe.get(\'OUR-SEQUENCE-KEY\')\n            next_value = int(current_value) + 1\n            # now we can put the pipeline back into buffered mode with MULTI\n            pipe.multi()\n            pipe.set(\'OUR-SEQUENCE-KEY\', next_value)\n            # and finally, execute the pipeline (the set command)\n            pipe.execute()\n            # if a WatchError wasn\'t raised during execution, everything\n            # we just did happened atomically.\n            break\n       except WatchError:\n            # another client must have changed \'OUR-SEQUENCE-KEY\' between\n            # the time we started WATCHing it and the pipeline\'s execution.\n            # our best bet is to just retry.\n            continue\n```\n\ntransaction,更简便的实现方式\n\n> A convenience method named “transaction” exists for handling all the boilerplate of handling and retrying watch errors. It takes a callable that should expect a single parameter, a pipeline object, and any number of keys to be WATCHed. Our client-side INCR command above can be written like this, which is much easier to read:\n\n`transaction(func,\'key\')`，该函数参数为可调函数`func(pipe)`(自动传入一个pipe参数)和需要监视的key\n\n```\ndef client_side_incr(pipe):\n    current_value = pipe.get(\'OUR-SEQUENCE-KEY\')\n    next_value = int(current_value) + 1\n    pipe.multi()\n    pipe.set(\'OUR-SEQUENCE-KEY\', next_value)\n\nr.transaction(client_side_incr, \'OUR-SEQUENCE-KEY\')\n#[True]\n```\n\n## 3.发布订阅\n\n基本code\n\n```\nimport redis\ndb=redis.StrictRedis(host=\'linevery.com\', port=6379, db=0)\np = db.pubsub()\n# 忽略订阅消息\np = r.pubsub(ignore_subscribe_messages=True)\n# 订阅channel\np.subscribe(\'channel1\', \'channel2\')\n# 通配符订阅\np.psubscribe(\'channel*\')\n# 发送消息，返回有几个channel接收到message\nr.publish(\'channel1\', \'some data\')\n# 获取消息 {\'channel\': \'my-first-channel\', \'data\': \'some data\', \'pattern\': None, \'type\': \'message\'}\np.get_message()\n# 退订channel\np.unsubscribe()\np.punsubscribe(\'my-*\')\n```\n\n`get_message()`的回调函数\n\n```\ndef my_handler(message):\n	print(\'MY HANDLER: \', message[\'data\'])\np.subscribe(**{\'my-channel\': my_handler})\n# 直接调用回调函数，不再返回值。\np.get_message()\n```\n\n`get_message()`的几种方式\n\n```\n# 循环读取\nwhile True:\n    message = p.get_message()\n    if message:\n        # do something with the message\n    time.sleep(0.001)  # be nice to the system :)\n\n# 阻塞读取\nfor message in p.listen():\n    # do something with the message\n```\n\n线程loop,必须要存在回调函数的channel，因为thread不能自动的处理message。\n\n```\n# 必须存在回调\np.subscribe(**{\'my-channel\': my_handler})\nthread = p.run_in_thread(sleep_time=0.001)\n# the event loop is now running in the background processing messages\n# when it\'s time to shut it down...\nthread.stop()\n```\n\n##\n 记住`close()`\n','2016-11-10 01:23:36',0),(235,'ScanProxy代理扫描(旧)','scan-proxy',107,'## 简介\n分析协议构造验证数据，采用异步非阻塞socket发送数据，不采用request的方式。后记来到公司，发现用Zmap来说进行一遍预扫，然后再精确扫，这样会更快,而且使用go的协程来做.\n\n## 更新!!!!!!!!：\n---\n先用Zmap进行全网扫一段，因为Zmap扫描是半连接，组成SYN包发送，组成包的发送不经过内核管理，发送SYN包，目标主机返回ACK包，但host收到ACK包，但是host不明确(因为之前就没有进过内核)，所以对外发送RST包，通过Zmap的原理可以查看，这样经过几个小时的全局扫描，对开放的端口进行具体的connect发送代理验证字符串\n\n---\n\n采用非阻塞的connect,每个IP测试4个端口。\n\n之前没分清国内和国外的IP段，导致去扫国外的，一片超时。所以才有下文的超时处理，但是国内一般不会涉及到超时。但这里还是要说下自己的想法。\n\n首先采用非阻塞的connect，会立即返回，如果返回`EINPROGRESS`,表明正在连接属于正常，在此期间使用`getsockopt(socket.SOL_SOCKET, socket.SO_ERROR)`获取socket的错误，无论对于*正在连接*还是*连接完成*都返回0,直到出现超时异常或其他错误，才返回其他错误码。\n\n##### 如果我们提前做超时异常处理，如何做？\n假如三次握手包，要在网络中存在N秒多，那这几秒内，没有函数去判断是否连接完成，因为处在正在连接的过程中，`getsockopt(socket.SOL_SOCKET, socket.SO_ERROR)`对于*正在连接*和*连接完成*的socket都返回0。但是我们可以通过`read()`或者`send()`或者`getpeername()`报异常，来判断。\n\n几个注意点:\n\n* 1.IP的区段 http://ips.chacuo.net/\n* 2.非阻塞connect的返回码\'EINPROGRESS\',表示正在连接\n* 3.http代理的验证方式,send一段http报文,验证返回.\n\n## Http代理\n当你发送`CONNECT %s:%s HTTP/1.1\\r\\nHost: %s:%s\\r\\nProxy-Connection: keep-alive\\r\\n\\r\\n`,接收到的response包含`b\'Connection established\'`表明，可以作为代理\n\n## Socks5代理\n当你发送`b\'\\x05\\x02\\x00\\x02\'`，接收到的data包含`b\'\\x05\\x00\'`,可以作为代理，这里仅仅是简单说明，但其中还涉及到验证等等复杂问题。\n\n##### proxys.py\n```\n__author__ = \'jmpews\'\nimport socket\nfrom redisq import RedisQueue\nimport errno\nimport select\nimport time\nimport utils\n\n# 采用非阻塞的connect,每个IP测试4个端口,手动做好每个socket的connect的超时处理\n# 几个注意点:\n# 1.IP的区段 http://ips.chacuo.net/\n# 2.非阻塞connect的返回码\'EINPROGRESS\',表示正在连接\n# 3.http代理的验证方式,send一段http报文,验证返回.\n\n\nrq=RedisQueue(\'proxy\')\n\nipfile=open(\'ip_shanghai.txt\',\'r\',encoding=\'utf-8\')\niplist=[]\nfor line in ipfile:\n    tmp=line.split(\'\\t\')\n    iplist.append((tmp[0],tmp[1]))\n\nips=utils.genips(iplist)\n# ips=utils.genips([(\'40.3.125.51\',\'70.0.0.128\')])\ninputs=[]\noutputs=[]\noutputimeouts=[]\n\n#test\n# outputimeouts+=utils.addips(\'118.144.108.254\')\n\nwhile True:\n\n    # 清除超时connect\n    # 由于非阻塞的connect,所以要手动排除超时的connect\n    outputimeouts=list(filter(utils.checktimeout,outputimeouts))\n\n    # 维持数据数量\n    if len(outputimeouts)<400:\n        for i in range(100-int(len(outputimeouts)/4)):\n            try:\n                ip=ips.__next__()\n            except StopIteration:\n                # 循环到ip列表最后\n                break\n            outputimeouts+=utils.addips(ip)\n\n    #补充数据\n    outputs=[x[0] for x in outputimeouts]\n\n    readable,writeable,exceptional=select.select(inputs,outputs,[],4)\n    for x in readable:\n        try:\n            data=x.recv(1024)\n            print(data)\n        except Exception as e:\n            x.close()\n            print(e)\n        if utils.checkhttp(data):\n            detial=x.getpeername()\n            print(detial)\n            rq.put(detial[0]+\':\'+str(detial[1]))\n        inputs.remove(x)\n        x.close()\n\n    for x in writeable:\n        erro=x.getsockopt(socket.SOL_SOCKET, socket.SO_ERROR)\n        # connect拒绝\n        if erro==errno.ECONNREFUSED:\n            # print(\'conn refuse.\')\n            outputimeouts=list(filter(lambda tm:tm[1]!=x.fileno(),outputimeouts))\n            # outputs.remove(x)\n            x.close()\n            continue\n\n        # 超时\n        elif erro==errno.ETIMEDOUT:\n            # print(\'conn timeout.\')\n            outputimeouts=list(filter(lambda tm:tm[1]!=x.fileno(),outputimeouts))\n            # outputs.remove(x)\n            x.close()\n            continue\n\n        # 不可到达\n        elif erro==errno.EHOSTUNREACH:\n            # print(\'host unreach.\')\n            outputimeouts=list(filter(lambda tm:tm[1]!=x.fileno(),outputimeouts))\n            # outputs.remove(x)\n            x.close()\n            continue\n\n        # 正常connect\n        # 发送http代理验证数据\n        elif erro==0:\n            print(\'connect success\')\n            utils.sendhttp(x)\n            outputimeouts=list(filter(lambda tm:tm[1]!=x.fileno(),outputimeouts))\n            # outputs.remove(x)\n            inputs.append(x)\n\n    for x in exceptional:\n        print(\'====EXCEP====\')\n\n    # ip=ips.__next__()\n    # print(ip)\n    # print(\'loop...\')\n```\n\n##### utils.py\n```\n__author__ = \'jmpews\'\nimport socket\nimport time\n\n#发送验证字符串\ndef sendhttp(x):\n    t=x.getpeername()\n    connstr=\"CONNECT %s:%s HTTP/1.1\\r\\nHost: %s:%s\\r\\nProxy-Connection: keep-alive\\r\\n\\r\\n\" % (t[0],t[1],t[0],t[1])\n    x.send(connstr.encode())\n\n#检查response是否存在字符串\ndef checkhttp(data):\n    if data.find(b\'Connection established\')==-1:\n        return False\n    return True\n\n# 发送socks验证数据\ndef sendsocks(x):\n    x.send(b\'\\x05\\x02\\x00\\x02\')\n\n#检查response是否存在字符串.\ndef checksocks(data):\n    if data.find(b\'\\x05\\x00\') == -1:\n        return False\n    return True\n\n# 采用生成器方式,防止超长list爆内存\ndef genips(ipl):\n    def s2n(str):\n        i=[int(x) for x in str.split(\'.\')]\n        return i[0]<<24|i[1]<<16|i[2]<<8|i[3]\n    def n2ip(num):\n        return \'%s.%s.%s.%s\' % (\n            (num&0xFF000000)>>24,\n            (num&0x00FF0000)>>16,\n            (num&0x0000FF00)>>8,\n            (num&0x000000FF)\n        )\n    for s,e in ipl:\n        for t in range(s2n(s),s2n(e)):\n            yield n2ip(t)\n\n\n# 对于每个IP生成4个socket,表示检查4个常见端口\ndef addips(ip):\n    httports=[80,3128,8080,8888]\n    socks=[]\n    tm=int(time.time())\n    for port in httports:\n        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        # 非阻塞connect\n        sock.setblocking(0)\n        err=sock.connect_ex((ip, port))\n        socks.append((sock,sock.fileno(),tm))\n    return socks\n\n# 检查sock是否超时\ndef checktimeout(x):\n    t=time.time()\n    if x[2]+3<t:\n        try:\n            x[0].getpeername()\n        except:\n            # print(\'Exp:Host.\')\n            x[0].close()\n            return False\n    return True\n```\n','2016-11-10 01:23:36',0),(236,'sicp换零钱-递归转尾递归','sicp-make-change',110,'递归和迭代的转化，关键需要明确哪些是递归的冗余数据，也就说哪些是迭代可以重复利用数据。下面具体分析。\n\n给不同的coin分配索引\n\n```\n(define (first-denomination kinds-of-coins)\n    (cond ((= kinds-of-coins 1) 1)\n        ((= kinds-of-coins 2) 5)\n        ((= kinds-of-coins 3) 10)\n        ((= kinds-of-coins 4) 25)\n        ((= kinds-of-coins 5) 50)))\n\n```\n\n### 递归的思路\n\n将总数为a的现金换成n种硬币的不同方式的数目等于\n\n1. 将现金a换成除第一种硬币以外的其他硬币的不同方式，加上2\n2. 将现金a－d换成所有种类硬币的不同方式。其中d为第一种硬币的面值。\n\n可以写递归公式\n\n`Ct(N) = Ct(N-first-denomination(t)) + Ct-1(N)`\n\nt(下标)为几种硬币，N为现金数。例如：t为5，N为100美分，所以总数目=(将100美分换成1,5,10,25这四种硬币组成方法数)+(将100-50美分换成1,5,10,25,50这五种硬币组成的方法数)\n\n通过公式进行初步运算，渐渐会发现冗余数据(重复利用的数据)\n\n```\nC5(100)=C4(100)+C5(50)\n    C4(100)==C3(100)+C4(75)\n        C3(100)=C2(100)+C3(90)\n            C2(100)=C1(100)+C2(95)\n                C2(95)=C1(95)+C2(90)\n                    C2(90)=C1(90)+C2(85)\n                        C2(85)=C1(85)+C2(80)\n                            C2(80)=C1(80)+C2(75)\n                                C2(75)=C1(75)+C2(70)\n                                    ...\n            # C2(90) 重复\n            C3(90)=C2(90)+C3(80)\n                # C2(80) 重复\n                C3(80)=C2(80)+C3(70)\n                    # C2(70) 重复\n                    C3(70)=C2(70)+C3(60)\n                        ...\n        C4(75)=C3(75)+C4(50)\n            C3(75)=C2(75)+C3(65)\n                ...\n            C4(50)=C3(50)+C4(25)\n                ...\n    C5(50)=C4(50)+C5(0)\n        C5(50)=C4(50)+C5(0)\n            ...\n```\n\n上面可能不太直观\n\n```\nC2(4) = C1(4) + C2(-1)\nC2(5) = C1(5) + C2(0)\nC2(6) = C1(6) + C2(1)\nC2(7) = C1(7) + C2(2)\nC2(8) = C1(8) + C2(3)\nC2(9) = C1(9) + C2(4) //出现重复利用值C2(4) 间隔为5\nC2(10) = C1(10) + C2(5) //出现重复利用值C2(5) 间隔为5\nC2(11) = C1(11) + C2(6)\nC2(12) = C1(12) + C2(7)\nC2(13) = C1(13) + C2(8)\nC2(14) = C1(14) + C2(9)\nC2(15) = C1(15) + C2(10)\nC2(16) = C1(16) + C2(11)\n\n\nC3(4) = C2(4) + C3(-6)\nC3(5) = C2(5) + C3(-5)\nC3(6) = C2(6) + C3(-4)\nC3(7) = C2(7) + C3(-3)\nC3(8) = C2(8) + C3(-2)\nC3(9) = C2(9) + C3(-1)\nC3(10) = C2(10) + C3(0)\nC3(11) = C2(11) + C3(1)\nC3(12) = C2(12) + C3(2)\nC3(13) = C2(13) + C3(3)\nC3(14) = C2(14) + C3(4) //出现重复利用值C3(4) 间隔为10\nC3(15) = C2(15) + C3(5) //出现重复利用值C3(5) 间隔为10\nC3(16) = C2(16) + C3(6)\n```\n\n**所以对于C2来说，始终需要缓存5个可以重复利用值(长度为5的缓存队列);对于C3，始终需要缓存10个可以重复利用值(长度为10的缓存队列);对于C4，使用需要缓存25个(...);对于C5来说，使用需要缓存50个可以重复利用值(...)**\n\n### 迭代思路\n\n1. 迭代是线性O(n)时间+常量空间消耗(不会随n改变)\n2. 迭代需要**重复利用**递归产生的冗余数据.\n3. 迭代的状态能由这些变量完全刻画\n\n假设有5种硬币，现金100美分\n\nC 源码\n\n```\n/*\n * =====================================================================================\n *\n *  Filename:  p26.c\n *\n *  Description: change money\n *\n *  Version:  1.0\n *  Created:  2016/08/02 14时58分22秒\n *  Revision:  none\n *  Compiler:  gcc\n *\n *  Author:  jmpews (jmpews.github.io), jmpews@gmail.com\n *\n * =====================================================================================\n */\n\n\n#include <stdlib.h>\n#include <stdio.h>\n#include <string.h>\nint count_change(int amount);\nint cc(int amount, int kinds_of_coins);\nvoid count_iter(int *tmp, int t, int amount);\nint get_coin(int index_of_coin);\nint get_index_tmp(int index_of_coin);\nint *get_tmp_array(int kinds_of_coins);\nint get_recycle_value(int index_of_coin, int current_amount, int *tmp_array);\nvoid update_recycle_value(int index_of_coin, int *tmp_array, int value);\n\nint main ( int argc, char *argv[] )\n{\n    int t;\n    t = count_change(100);\n    printf(\"%d\", t);\n    return EXIT_SUCCESS;\n}				/* ----------  end of function main  ---------- */\n\nint count_change(int amount) {\n    cc(amount, 5);\n    return 0;\n}\n\nint cc(int amount, int kinds_of_coins) {\n    int *tmp = get_tmp_array(kinds_of_coins);\n    int t = 0;\n    tmp[0] = 0;\n    count_iter(tmp, t, amount);\n    return 0;\n}\n\n// 这里这里也是关键点，这个尾递归的结束由t(当前需要兑换的金钱)和amount(需要兑换的目标金钱)控制，为线性，也就是说时间复杂度为O(n)\nvoid count_iter(int *tmp, int t, int amount) {\n    int r;\n    r = get_recycle_value(1, t, tmp);\n    update_recycle_value(1, tmp, r);\n\n    //C2(t) = C2(t-get_coin(2)) + C1(t)\n    r = get_recycle_value(2, t, tmp) + r;\n    update_recycle_value(2, tmp, r);\n\n    //C3(t) = C3(t-get_coin(3)) + C2(t)\n    r = get_recycle_value(3, t, tmp) + r;\n    update_recycle_value(3, tmp, r);\n\n    //C4(t) = C4(t-get_coin(4)) + C3(t)\n    r= get_recycle_value(4, t, tmp) + r;\n    update_recycle_value(4, tmp, r);\n\n    //C5(t) = C5(t-get_coin(5)) + C4(t)\n    r = get_recycle_value(5, t, tmp) + r;\n    if(t == amount) {\n        printf(\"final-value: %d\\n\", r);\n        exit(1);\n    }\n    update_recycle_value(5, tmp, r);\n\n    count_iter(tmp, t+1, amount);\n}\n\nint get_coin(int index_of_coin) {\n    switch(index_of_coin) {\n        case 1: return 1;\n        case 2: return 5;\n        case 3: return 10;\n        case 4: return 25;\n        case 5: return 50;\n        default: exit(1);\n    }\n}\n\n// 对于C1、C2、C3、C4、C5缓存队列开始的位置\nint get_index_tmp(int index_of_coin) {\n    switch(index_of_coin) {\n        case 1: return 0;\n        case 2: return 1;\n        case 3: return 6;\n        case 4: return 16;\n        case 5: return 41;\n        default: exit(1);\n    }\n}\n\n// 分配固定的缓存, 无论需要兑换多少金钱，只要金币种类不变，缓存的大小就是固定的。 空间复杂度为常量。\n// \"因为它的状态能由其中的三个状态变量完全刻画，解释器在执行 这一计算过程时，只需要保存这三个变量的轨迹就足够了\" 这句话在这里就有体现了\nint *get_tmp_array(int kinds_of_coins) {\n    int *tmp;\n    int i;\n    int sum = 0;\n    for(i=1 ; i<kinds_of_coins ; i++) {\n        sum += get_coin(i);\n    }\n    tmp = (int *)malloc(sizeof(int) * sum);\n    memset(tmp, 0 ,sizeof(int) * sum);\n    return tmp;\n}\n\n// 获取重复利用值, 每次缓存队列头的位置\n// 比如: 此时缓存队列为[C2(0), C2(1), C2(2), C2(3), C2(4)]\n// C2(5) = C1(5) + C2(0) 此时我们需要取缓存队列头的值C2(0)\n// 计算完得到C2(5)，需要执行update_recycle_value将得到C2(5)进队列，除去旧的C2(0)，此时队列头尾C2(1)，即为计算C2(6)需要的缓存值\nint get_recycle_value(int index_of_coin, int current_amount, int *tmp_array) {\n    int t = get_index_tmp(index_of_coin);\n    if(current_amount < get_coin(index_of_coin)){\n        return 0;\n    }\n    else if(current_amount == get_coin(index_of_coin)){\n        return 1;\n    }\n    else {\n        return tmp_array[t];\n    }\n}\n\n// 更新重复利用值(队列的概念), 计算出最新的值，需要替换旧的利用值\n// 比如: C2(5) = C1(5) + C2(0)\n// 现在C2缓存队列中有[C2(0), C2(1), C2(2), C2(3), C2(4)]，我们需要将C2(5)进队列，[C2(1), C2(2), C2(3), C2(4), C2(5)]\nvoid update_recycle_value(int index_of_coin, int *tmp_array, int value) {\n    int i;\n    int t = get_index_tmp(index_of_coin);\n    for(i = 0; i< (get_coin(index_of_coin)-1); i++) {\n        tmp_array[t+i] = tmp_array[t+i+1];\n    }\n    tmp_array[t+get_coin(index_of_coin)-1] = value;\n}\n```\n\n### 参考\nhttp://stackoverflow.com/questions/1485022/sicp-making-change/\n','2016-11-10 01:23:36',0),(237,'socketpool连接池','read-socketpool',111,'项目链接地址: https://github.com/benoitc/socketpool\n\n## 如何设计一个socket连接池\n1. 首先连接池,必须具有一个queue来保存{连接}\n2. 从连接池中get一个(ip,port)的连接，如果存在直接返回socket，如果不存在创建socket(创建socket可以对外提供一个接口factory,用户只需要继承接口并实现具体的方法)\n3. 如果连接池满了直接关闭该socket\n\n## pool.py 分析\n```\n# -*- coding: utf-8 -\n#\n# This file is part of socketpool.\n# See the NOTICE for more information.\n\nimport contextlib\nimport sys\nimport time\n\nfrom socketpool.util import load_backend\n\nclass MaxTriesError(Exception):\n    pass\n\nclass MaxConnectionsError(Exception):\n    pass\n\nclass ConnectionPool(object):\n    \"\"\"Pool of connections\n\n    This is the main object to maintain connection. Connections are\n    created using the factory instance passed as an option.\n\n    Options:\n    --------\n\n    :attr factory: Instance of socketpool.Connector. See\n        socketpool.conn.TcpConnector for an example\n    :attr retry_max: int, default 3. Numbr of times to retry a\n        connection before raising the MaxTriesError exception.\n    :attr max_lifetime: int, default 600. time in ms we keep a\n        connection in the pool\n    :attr max_size: int, default 10. Maximum number of connections we\n        keep in the pool.\n    :attr options: Options to pass to the factory\n    :attr reap_connection: boolean, default is true. If true a process\n        will be launched in background to kill idle connections.\n    :attr backend: string, default is thread. The socket pool can use\n        different backend to handle process and connections. For now\n        the backends \"thread\", \"gevent\" and \"eventlet\" are supported. But\n        you can add your own backend if you want. For an example of backend,\n        look at the module socketpool.gevent_backend.\n    \"\"\"\n\n    def __init__(self, factory,\n                 retry_max=3, retry_delay=.1,\n                 timeout=-1, max_lifetime=600.,\n                 max_size=10, options=None,\n                 reap_connections=True, reap_delay=1,\n                 backend=\"thread\"):\n\n        if isinstance(backend, str):\n            self.backend_mod = load_backend(backend)\n            self.backend = backend\n        else:\n            self.backend_mod = backend\n            self.backend = str(getattr(backend, \'__name__\', backend))\n        self.max_size = max_size\n        self.pool = getattr(self.backend_mod, \'PriorityQueue\')()\n        self._free_conns = 0\n        self.factory = factory\n        self.retry_max = retry_max\n        self.retry_delay = retry_delay\n        self.timeout = timeout\n        self.max_lifetime = max_lifetime\n        if options is None:\n            self.options = {\"backend_mod\": self.backend_mod,\n                            \"pool\": self}\n        else:\n            self.options = options\n            self.options[\"backend_mod\"] = self.backend_mod\n            self.options[\"pool\"] = self\n\n        # bounded semaphore to make self._alive \'safe\'\n        self._sem = self.backend_mod.Semaphore(1)\n\n        self._reaper = None\n        # 循环定时调用murder_connections(),清除无效连接\n        if reap_connections:\n            self.reap_delay = reap_delay\n            self.start_reaper()\n\n    def too_old(self, conn):\n        return time.time() - conn.get_lifetime() > self.max_lifetime\n    # 遍历清除无效连接\n    def murder_connections(self):\n        current_pool_size = self.pool.qsize()\n        if current_pool_size > 0:\n            for priority, candidate in self.pool:\n                current_pool_size -= 1\n                if not self.too_old(candidate):\n                    self.pool.put((priority, candidate))\n                else:\n                    self._reap_connection(candidate)\n                if current_pool_size <= 0:\n                    break\n    # 设置这个循环检测是线程(thread)、协程(gevent)还是其他\n    def start_reaper(self):\n        self._reaper = self.backend_mod.ConnectionReaper(self,\n                delay=self.reap_delay)\n        self._reaper.ensure_started()\n\n    def _reap_connection(self, conn):\n        if conn.is_connected():\n            conn.invalidate()\n\n    @property\n    def size(self):\n        return self.pool.qsize()\n\n    # 关闭连接池所有连接\n    def release_all(self):\n        if self.pool.qsize():\n            for priority, conn in self.pool:\n                self._reap_connection(conn)\n\n    # 释放无效连接或加入连接池，在socket使用完毕后调用\n    def release_connection(self, conn):\n        if self._reaper is not None:\n            self._reaper.ensure_started()\n\n        with self._sem:\n            if self.pool.qsize() < self.max_size:\n                connected = conn.is_connected()\n                if connected and not self.too_old(conn):\n                    self.pool.put((conn.get_lifetime(), conn))\n                else:\n                    self._reap_connection(conn)\n            else:\n                self._reap_connection(conn)\n    # 核心函数，从连接池子获取符合条件的连接，如果不存在，那么根据backend(thread,gevent等)生成一个连接\n    def get(self, **options):\n        options.update(self.options)\n\n        found = None\n        i = self.pool.qsize()\n        tries = 0\n        last_error = None\n\n        unmatched = []\n\n        # 遍历连接查找符合条件的连接\n        while tries < self.retry_max:\n            # first let\'s try to find a matching one from pool\n\n            if self.pool.qsize():\n                for priority, candidate in self.pool:\n                    i -= 1\n                    if self.too_old(candidate):\n                        # let\'s drop it\n                        self._reap_connection(candidate)\n                        continue\n\n                    matches = candidate.matches(**options)\n                    if not matches:\n                        # let\'s put it back\n                        unmatched.append((priority, candidate))\n                    else:\n                        if candidate.is_connected():\n                            found = candidate\n                            break\n                        else:\n                            # conn is dead for some reason.\n                            # reap it.\n                            self._reap_connection(candidate)\n\n                    if i <= 0:\n                        break\n\n            if unmatched:\n                for candidate in unmatched:\n                    self.pool.put(candidate)\n\n            # we got one.. we use it\n            if found is not None:\n                return found\n\n            # 不存在则创建连接\n            try:\n                new_item = self.factory(**options)\n            except Exception as e:\n                last_error = e\n            else:\n                # we should be connected now\n                if new_item.is_connected():\n                    with self._sem:\n                        return new_item\n\n            tries += 1\n            self.backend_mod.sleep(self.retry_delay)\n\n        if last_error is None:\n            raise MaxTriesError()\n        else:\n            raise last_error\n\n    # 奇淫技巧 方便with使用\n    @contextlib.contextmanager\n    def connection(self, **options):\n        conn = self.get(**options)\n        try:\n            yield conn\n            # what to do in case of success\n        except Exception as e:\n            conn.handle_exception(e)\n        finally:\n            # 检查该连接是否关闭，如果没有关闭假如连接池\n            self.release_connection(conn)\n```\n\n## conn.py 分析\n```\n# -*- coding: utf-8 -\n#\n# This file is part of socketpool.\n# See the NOTICE for more information.\n\nimport select\nimport socket\nimport time\nimport random\n\nfrom socketpool import util\n\nclass Connector(object):\n    def matches(self, **match_options):\n        raise NotImplementedError()\n\n    def is_connected(self):\n        raise NotImplementedError()\n\n    def handle_exception(self, exception):\n        raise NotImplementedError()\n\n    def get_lifetime(self):\n        raise NotImplementedError()\n\n    def invalidate(self):\n        raise NotImplementedError()\n\n# Connect类，连接不存在时，创建该类的实例\nclass TcpConnector(Connector):\n\n    def __init__(self, host, port, backend_mod, pool=None):\n        self._s = backend_mod.Socket(socket.AF_INET, socket.SOCK_STREAM)\n        self._s.connect((host, port))\n        self.host = host\n        self.port = port\n        self.backend_mod = backend_mod\n        self._connected = True\n        # use a \'jiggle\' value to make sure there is some\n        # randomization to expiry, to avoid many conns expiring very\n        # closely together.\n        self._life = time.time() - random.randint(0, 10)\n        self._pool = pool\n\n    def __del__(self):\n        self.release()\n\n    # 在连接池中查找\n    def matches(self, **match_options):\n        target_host = match_options.get(\'host\')\n        target_port = match_options.get(\'port\')\n        return target_host == self.host and target_port == self.port\n\n    def is_connected(self):\n        if self._connected:\n            return util.is_connected(self._s)\n        return False\n\n    def handle_exception(self, exception):\n        print(\'got an exception\')\n        print(str(exception))\n\n    def get_lifetime(self):\n        return self._life\n\n    # 关闭连接，需要接着release()\n    def invalidate(self):\n        self._s.close()\n        self._connected = False\n        self._life = -1\n\n    def release(self):\n        if self._pool is not None:\n            if self._connected:\n                self._pool.release_connection(self)\n            else:\n                self._pool = None\n\n    def send(self, data):\n        return self._s.send(data)\n\n    def recv(self, size=1024):\n        return self._s.recv(size)\n```\n\n## backend_gevent.py gevent模式分析\n```\n# -*- coding: utf-8 -\n#\n# This file is part of socketpool.\n# See the NOTICE for more information.\n\nimport gevent\nfrom gevent import select\nfrom gevent import socket\nfrom gevent import queue\n\nfrom socketpool.pool import ConnectionPool\n\ntry:\n    from gevent import lock\nexcept ImportError:\n    #gevent < 1.0b2\n    from gevent import coros as lock\n\n\nsleep = gevent.sleep\nSemaphore = lock.BoundedSemaphore\nSocket = socket.socket\nSelect = select.select\n\n# 连接池：采用queue实现\nclass PriorityQueue(queue.PriorityQueue):\n\n    def __next__(self):\n        try:\n            result = self.get(block=False)\n        except queue.Empty:\n            raise StopIteration\n        return result\n    next = __next__\n\n# 循环清理连接池中的无效连接\nclass ConnectionReaper(gevent.Greenlet):\n\n    running = False\n\n    def __init__(self, pool, delay=150):\n        self.pool = pool\n        self.delay = delay\n        gevent.Greenlet.__init__(self)\n\n    def _run(self):\n        self.running = True\n        while True:\n            gevent.sleep(self.delay)\n            self.pool.murder_connections()\n\n    def ensure_started(self):\n        if not self.running or self.ready():\n            self.start()\n\n```\n','2016-11-10 01:23:36',0),(238,'SSH笔记','use-ssh',112,'## SSH本地端口转发。\n\n`ssh -L 2121:host2:21 host3`ssh建立一个socket绑定本地2121端口，通过host3这个桥，转发本地2121端口请求到host2:21\n\n## SSH远程端口转发\n\nhost3在内网，可以访问外网host1\n\n`ssh -R 2121:host2:21 host1`建立socket连接host1:2121，让host1监听2121端口，让所有数据转发到host2:21\n\n前提，host1和host3两台主机都有sshD和ssh客户端。\n\n## 额外参数\n\n-N参数，表示只连接远程主机，不打开远程shell；T参数，表示不为这个连接分配TTY。这个两个参数可以放在一起用，代表这个SSH连接只用来传数据，不执行远程操作。f参数，表示SSH连接成功后，转入后台运行。\n\n\n### http隧道\n分为不使用connect的隧道和使用connect的隧道，不用connect的隧道为重新组装请求，而https必须通过connect建立隧道通信\n\n### 端口映射\n将来自指定外网IP的某一端口的请求转发到内网某一IP的某一个端口\n\n#### iptables的端口转发\n```\n# 使用iptables实现端口转发\necho 1 > /proc/sys/net/ipv4/ip_forward\niptables -t nat -I PREROUTING -p tcp –dport 80 -j DNAT –to xx.xx.xx.xx\niptables -t nat -I POSTROUTING -p tcp –dport 8080 -j MASQUERADE\nservice iptables save\n```\n#### ssh的本地端口转发和远程端口转发\n[ssh隧道、端口转发、内网穿透](http://blog.creke.net/722.html)\n','2016-11-10 01:23:36',0),(239,'summary-12-27','summary-12-27',113,'Watch and Learn,Learn and Think.\n\n最近一直在做两个东西:mini-httpdserver 和代理扫描自动代理的工具\n\n先说说mini-httpdserver:\n\n用pure c写的一个Httpserver，提供简单的web访问，对request和response进行分模块处理，并且提供了简单的路由。而且把我把很多资料放到该目录下，只要`git clone`就可以提供服务。\n\n重点下代理扫描和自动代理:\n\n在这个过程中走了很多弯路，原本以为通过select和epoll进行非阻塞的connect，并且手动做好timeout设置，每秒并发会上万已经是很快了。但是最近了解到Zmap，只要一听到它是通过**发送SYN半连接**来判断就明白了好多，只进行三次握手的第一步，整个过程不建立连接,因为自己写过一个用python发送原生TCP、IP、以太网包的程序，同时也可以监听本地数据包。Zmap就是不断发送SYN包，通过接受目标主机的ACK包，进行判断端口有没有开放，先缩小结果，然后进行connect发送验证数据包.\n\n上面是扫描代理遇到坑，关于自动代理，之前想做的是，扫描代理形成一个自己的代理IP库，然后打算实现自动代理。\n\n先说下客户端的自动代理：\n\n在python上给socket打上patch，一开始是把patch打到connect上，重新实现connect，然后的做法是用装饰器去包装connect，第二种更简单一些。但是发现自己用用还可以，但是很难写成接口。connect之前get一个proxy，connect连接到proxy，然后发送请求，get这个从哪里获取。其实和人家request又有什么区别呢？从列表中get一个proxy，设置到request上，开一个线程，反正，鸡肋。\n\n另一种做法就建立一个本地代理，程序中只需要设置好本地代理就ok，本地代理负责挑选代理进行转发。\n\n','2016-11-10 01:23:36',0),(240,'SYNcookie原理','syncookie',114,'在研究syncookie的时候首先需要明确需要搞清的问题.\n\n1. syncookie是为了解决什么问题? \n\n2. syncookie是怎么解决的? \n\n### syncookie解决了什么问题?\n\nSYN flood(SYN洪水攻击, 不断发送伪造的SYN给服务器), 导致服务器上**半连接队列满**, 丢弃之后正常请求的SYN.\n\n### syncookie 是怎么解决的?\n\n#### 正常的过程, 半连接队列未满\n1. 服务前端接收到 SYN(seq_a), 判断队列有没有如果没有满, 按照正常的处理过程, 将 SYN 放到半连接队列中, 回应SYN(seq_b)+ACK(seq_a+1)\n2. 客户端回应ACK(seq_b+1), 服务端接受到客户端 ACK, 去检查半连接队列里是否有对应的 SYN, 如果有建立连接, 放到连接完成队列\n\n#### SYN foold攻击, 半连接队列满\n1. 接收到 SYN, 判断半连接队列是否满, 是否开启了syncookie, 按照syncookie进行接下来处理\n\n2. 将接收到的 SYN 进行算法hash, 将关键的字段加密成 **服务端回应的SYN的seq** , 发送给客户端ACK+SYN(此时seq=hash后的而关键数值), 并丢弃SYN. (可以类比seq为base64-encode过程)\n\n3. 如果客户端是正常的客户端会对服务器端的SYN(seq)回应ACK(seq+1)\n\n4. 服务端接收到 ACK(seq+1), 先检查半连接队列是否存在该ACK对应的SYN, 如果不存在, 继续检查是否开启了syncookie, 如果开启了, 就检查seq是否为合法cookie, 如果是则对其进行逆运算, 恢复之前SYN, 继续操作.(可以类比base64-decode)\n\n### 参考资料\n\nhttp://blog.csdn.net/justlinux2010/article/details/12619761\n\n[Syncookie源码解析（linux-2.6.30.10](http://m.blog.chinaunix.net/uid-23207633-id-267571.html)\n','2016-11-10 01:23:36',0),(241,'TCP/IP源码阅读','read-tcp-ip',113,'## 数据链路层\n### 以太网\n* 默认采用RFC894定义\n* IP数据部分长度46~1500\n\n### SLIP串行线路IP\n* 每一方都必须知道对方IP地址\n* 如果一条串行线路用于SLIP，则不用于其他协议\n* 没有校验，上层协议提供\n\n### PPP协议\n\n`0x7d`作为转义字符，当它它出现在PPP数据帧中时，那么紧接着的字符的第6个比特位要取其补码。(就像`\\`作为转义字符，需要打印`\\`字符，则需要转义为`\\\\`)\n\n`0x7e` 转为 `0x7d 0x5e`\n\n`0x7d` 转为 `0x7d 0x5d`\n\n### 路径MTU\n主机通信路径最小MTU\n\n### 串行线路吞吐量计算\n平均等待时间为最大数据帧所需时间的一半。\n','2016-11-10 01:23:36',0),(242,'Torando的IOLoop和Applicaion过程分析','tornado-read',102,'## Application和IOLoop初始化\n\n![初始化](../images/tornado初始化流程.jpg)\n\n\n`IOLoop.current()`返回当前的loop，若无，则进行单例初始化。\n\n`IOLoop.instance()`进行单例初始化\n\n`IOLoop()`进行初始化\n\n`Configurable.__new__()` 父类初始化\n\n`IOLoop.configure_default()`根据不同平台实现子类\n','2016-11-10 01:23:36',0),(243,'tornado中ioloop-yield-Future与thread的配合','ioloop-yield-future-thread',102,'在写项目[torweb](https://github.com/jmpews/torweb), 需要有一个分离一个线程去完成耗时操作.\n\n把tornado的Future、Python里的Yield和线程结合起来，处理阻塞函数。可以查看[tests/test_thread_future.py](https://github.com/jmpews/torweb/blob/master/tests/test_thread_future.py) ，具体分析可以查看 http://jmpews.github.io/posts/tornado-future-ioloop-yield.html\n\n```\nfrom threading import Thread\nclass ThreadWorker(Thread):\n    \'\'\'\n    线程Future\n    \'\'\'\n    def __init__(self, future, func, *args, **kwargs):\n        Thread.__init__(self)\n        self.future =future\n        self.func =func\n        self.args = args\n        self.kwargs = kwargs\n        print(\'worker init...\')\n\n    def run(self):\n        result = self.func(*self.args, **self.kwargs)\n        self.future.set_result(result)\n\ndef run_with_thread_future(*args, **kwargs):\n    \'\'\'\n    如何利用yield, future和线程的配合\n    http://jmpews.github.io/posts/tornado-future-ioloop-yield.html\n    :param args:\n    :param kwargs:\n    :return:\n    \'\'\'\n    def wraps_func(func):\n        @functools.wraps(func)\n        def wraps_args(*args, **kwargs):\n            future = Future()\n            work = ThreadWorker(future, func, *args, **kwargs)\n            work.start()\n            return future\n        return wraps_args\n    return wraps_func\n```\n\n','2016-11-10 01:23:36',0),(244,'Tornado中的Future,ioloop,yield三者如何完成以\'同步协程,异步执行\'','tornado-future-ioloop-yield',102,'## Summary:\n\n首先需要明确的，tornado中异步是建立在事件循环机制之上，也就是IOLoop。\n\nFuture IOLoop yield 本质仅仅完成了, 协程的切换, 也就是实现了以同步的方式去写异步\n\n本质上非阻塞与异步的实现是在`SimpleAsyncHTTPClient.fetch_impl(simple_httpclient.py) -> self._process_queue(simple_httpclient.py) self._handle_request(simple_httpclient.py) -> self._connection_class(_HTTPConnection)(simple_httpclient.py) -> self.tcp_client.connect()(simple_httpclient.py) -> self._create_stream(tcpclient.py) -> stream.connect(tcpclient.py) -> self._add_io_state(iostream.py)`, 注册事件到ioloop, 等待实现响应触发`self._handle_events(iostream.py)`\n\n## 异步请求例子\n\n```\nfrom tornado.httpclient import AsyncHTTPClient\nfrom tornado import gen\nimport tornado.ioloop\n\n@gen.coroutine\ndef fetch_coroutine(url):\n    http_client = AsyncHTTPClient()\n    response = yield http_client.fetch(url)\n    print(response)\nfetch_coroutine(\'http://jmpews.com\')\ntornado.ioloop.IOLoop.instance().start()\n```\n\n伪代码例子\n\n```\ndef work():\n  future = Future()\n  ioloop.add_result_callback(future.set_result(\'result)) // 触发ioloop响应结果时，设置future状态为完成\n  return future\n\ndef coroutine():\n  def wrap_func(func):\n    d = func()\n    result = next(d) //future\n    future.add_done_callback(d.send(result)) // 设置当future状态为完成时，触发send来恢复协程，继续执行func。\n    \n@coroutine\ndef func():\n  print(\'step in\')\n  result = yield work()\n  print(\'step out\')\n```\n\n## yield : 异步协程同步写法，配合@tornado.gen.coroutine\n\nyield，有两个作用，一个是用于挂起当前函数(yield)，第二个可以相当于封装后的callback(yield send)，只不过它的callback是`generator.send(\'result\')`，用于恢复挂起函数继续执行。这里需要注意的是，我们需要在挂起当前函数时注册事件循环机制的响应callback为`generator.send(\'result\')`。\n\n所以，使用yield的第一个问题就是，在哪里设置的`generator.send(\'result\')`。这里以`AsyncHTTPClient`为例。\n\n## Future : 连接ioloop和yield\n提供`set_result`和`set_done`方法，来触发Future上的callback，其中的callback包含`Runner.run()` ，实质为 `generator.send(\'result\')`，也就是在yield中必须要明确的在哪里设置`generator.send(\'result\')`。\n\n## IOLoop : 调度center\n注册响应事件的callback为Future的`set_restult()`，等待事件触发\n\n## `AsyncHTTPClient`分析执行流程\n\n```\n# 文件信息: tornado.httpclient\n# 涉及到类名: AsyncHTTPClient\n# 涉及到函数名: fetch\n\ncode ignore...\n\n从这段代码得到函数执行流程: \n\n0-0 .fetch\n ↓\n0-1 .fetch_impl(request, handle_response)\n\n回调函数:\nhandle_response(response)\n# 如果设置了callback\nfuture.add_done_callback(handle_future)\n```\n\n\n`handle_response(response)` 设置 future 的 `set_result` 继续查看 `set_result` 的实现\n---\n\n```\n# 文件信息: tornado.concurrent\n# 涉及到类名: Future\n# 涉及到函数名: add_done_callback, set_result, _set_done\n\ncode ignore...\n\n从这段代码得到函数执行流程: \n\nset_result(self, result)\n ↓\n_set_done(self)\n ↓\nfor cb in self._callbacks: cb(self)\n\n额外信息执行流程为:\n\nadd_done_callback(self, fn)\n ↓\nself._callbacks.append(fn)\n```\n\n发现 set_result 后, 会调用 `_set_done` 方法，以及各种callback\n\n接下来看下 `tornado.gen.coroutine` 添加了什么 trick 的 callback\n\n---\n\n```\n# 文件信息: tornado.gen\n# 涉及到函数名: coroutine, _make_coroutine_wrapper\n\ncode ignore...\n\n#从这段代码可以得到函数执行流程:\n\n_make_coroutine_wrapper(func, replace_callback=True)\n ↓\nresult = func(*args, **kwargs)\n ↓\nyielded = next(result)\n ↓\nRunner(result, future, yielded)\n```\n\n上面没有设置什么 callback, 只是启动了这个 generator, 接下来看 Runner, 有没有做什么工作\n---\n\n```\n# 文件信息: tornado.gen\n# 涉及到类名: Runner\n# 涉及到函数名: __init__, handle_yield, run\n\ncode ignore...\n\n从这段代码可以得到函数执行流程:\n\n__init__(self, gen, result_future, first_yielded)\n ↓\nself.handle_yield(first_yielded)\n ↓\nself.io_loop.add_future(self.future, lambda f: self.run())\n```\n\n最后可以发现在 run 方法中, 设置了 generator 的 send 方法\n\n\n\n','2016-11-10 01:23:36',0),(245,'Tornado中的异步与模块设计(yield&yield from)','tornado-yield-module-design',102,'## Tornado异步实质\n使用Tornado的yield进行异步`reponse=yield Async.fetch(\'http://example.com\')`,在这个过程，用一句话说就是注册IO可读事件的handler(回调函数)到IOLoop(事件循环机制)。其中yield本质是回调，相当于回调`send(result)`，那么最后也就是`response=result`.\n\n举一个Tornado典型的异步例子\n\n```\nclass AsyncHandler(RequestHandler):\n    @asynchronous\n    @coroutine\n    def post(self, *args, **kwargs):\n      httpclient=AsyncHTTPClient()\n      resp=yield httpclient.fetch(\'http://www.abc.com\')\n      self.write(resp.body)\n```\n## 如何进行tornado异步的模块化设计\n现在遇到的情况就是，假如进行模块化设计。比如：写个util模块函数，函数内进行异步调用(重复使用,并且不能直接展开到post函数内,减少耦合)\n\n```\ndef get_info(username):\n    do something...\n    httpclient = AsyncHTTPClient()\n    # 仅为生成器\n    resp1 = yield httpclient.fetch(\'http://www.abc.com\')\n    resp2 = yield httpclient.fetch(\'http://www.abc.com\')\n\n    do something...\n\n    return resp1 + resp2\n\nclass WebHandler(RequestHandler):\n    @asynchronous\n    @coroutine\n    def post(self, *args, **kwargs):\n        other func()...\n        # 错误!!!，后面仅仅是个生成器，需要的是Future才能和coroutine配合\n        result=yield get_info(username)\n        other func()...\n        return result_final\n```\n## 装饰器实现解决\n\n```\n@wrap_yield\ndef get_info(username):\n    do something...\n    httpclient = AsyncHTTPClient()\n    #仅为生成器\n    resp1 = yield httpclient.fetch(\'http://www.abc.com\')\n    resp2 = yield httpclient.fetch(\'http://www.abc.com\')\n\n    do something...\n\n    return resp1 + resp2\n\ndef wrap_yield(func):\n    @functools.wraps\n    def wrapper(*args, **kwargs):\n        _g = func(*args, **kwargs)\n\n		# return future\n		_f = _g.send(None)\n		while True:\n			try:\n				# return future\n				_s =  yield(_f)\n				_f = _g.send(_s)\n			except StopIteration:\n				break\n			excpet Exception as e:\n				try:\n					_f = _g.send(e)\n				except StopIteration:\n					break\n\nclass WebHandler(RequestHandler):\n    @asynchronous\n    @coroutine\n    def post(self, *args, **kwargs):\n\n        other func()...\n\n        resp = yield get_info(username)\n        return result_final\n```\n\n## `yield from` Trick (PEP-380)\n\n```\n# http://stackoverflow.com/questions/9708902/in-practice-what-are-the-main-uses-for-the-new-yield-from-syntax-in-python-3\n# 关于yield from的例子\ndef reader():\n    \"\"\"A generator that fakes a read from a file, socket, etc.\"\"\"\n    for i in range(4):\n        yield \'<< %s\' % i\n\n# 不使用yield from\ndef reader_wrapper(g):\n    # Manually iterate over data produced by reader\n    for v in g:\n        yield v\nwrap = reader_wrapper(reader())\nfor i in wrap:\n    print(i)\n\n# 使用yield from\ndef reader_wrapper(g):\n    yield from g\n\n# Result\n<< 0\n<< 1\n<< 2\n<< 3\n```\n\n可以看官方对于`yield from`给出的等价py实现\n\n```\n# https://www.python.org/dev/peps/pep-0380/\nPython 3 syntax is used in this section.\n\n1. The statement\n\n::\n\n    RESULT = yield from EXPR\n\nis semantically equivalent to\n\n::\n\n    _i = iter(EXPR)\n    try:\n        _y = next(_i)\n    except StopIteration as _e:\n        _r = _e.value\n    else:\n        while 1:\n            try:\n                _s = yield _y\n            except GeneratorExit as _e:\n                try:\n                    _m = _i.close\n                except AttributeError:\n                    pass\n                else:\n                    _m()\n                raise _e\n            except BaseException as _e:\n                _x = sys.exc_info()\n                try:\n                    _m = _i.throw\n                except AttributeError:\n                    raise _e\n                else:\n                    try:\n                        _y = _m(*_x)\n                    except StopIteration as _e:\n                        _r = _e.value\n                        break\n            else:\n                try:\n                    if _s is None:\n                        _y = next(_i)\n                    else:\n                        _y = _i.send(_s)\n                except StopIteration as _e:\n                    _r = _e.value\n                    break\n    RESULT = _r\n```\n\n具体如何解决tornado中异步模块设计问题\n\n```\ndef get_info(username):\n    do something...\n    httpclient = AsyncHTTPClient()\n    #仅为生成器\n    resp1 = yield httpclient.fetch(\'http://www.abc.com\')\n    resp2 = yield httpclient.fetch(\'http://www.abc.com\')\n\n    do something...\n\n    return resp1 + resp2\n\n\nclass WebHandler(RequestHandler):\n    @asynchronous\n    @coroutine\n    def post(self, *args, **kwargs):\n\n        other func()...\n\n        resp = yield from get_info(username)\n        return result_final\n```\n\n## 参考链接:\n\n---\n\nhttps://www.python.org/dev/peps/pep-0380/\n\nhttp://stackoverflow.com/questions/9708902/in-practice-what-are-the-main-uses-for-the-new-yield-from-syntax-in-python-3\n','2016-11-10 01:23:36',0),(246,'Tornado和Websocket建立实时通讯','tornado-websocket-real-time-chat',102,'## Summary:\n\n需要在web上建立实时通讯的一个Widget, 找了一些Tornado和Websocket结合的方案, 发现都很简单, 然后就结合具体实现了一个方案.\n\n## Feature:\n\n1. 支持通讯记录\n2. 支持多人的通讯\n3. 支持sessionStorage缓存\n4. 界面上显示聊天列表(待)\n\n## Tornado & Websocket 简介\n\n略...\n\n## JS的解决方案\n\n```\n// 启动聊天的websocket\nfunction start_chat_websocket(url) {\n     var  wsServer = \'ws://\' + url + \'/user/chatwebsocket\';\n     chat_websocket = new WebSocket(wsServer);\n     chat_websocket.onopen = function (evt) { onOpen(evt) };\n     chat_websocket.onclose = function (evt) { onClose(evt) };\n     chat_websocket.onmessage = function (evt) { onMessage(evt) };\n     chat_websocket.onerror = function (evt) { onError(evt) };\n\n     function onOpen(evt) {\n        console.log(\"Connected to WebSocket server.\");\n        window.sessionStorage.setItem(\'current_other\', \'\');\n     }\n\n     function onClose(evt) {\n        console.log(\"Disconnected\");\n     }\n\n     function onMessage(evt) {\n         var result = JSON.parse(evt.data);\n         console.log(result);\n         // 接受发送过来信息\n         if(result.errorcode == 0) {\n             // data = {\'user_id\': 2, \'data\': [\'>\', \'test, \'2015/09/26\']}\n             var data = JSON.parse(evt.data).data;\n             // 发送者user_id\n             var user_id = data.user_id;\n\n            //cache_user_data = {me_avatar: \"admin.png\", me_name: \"admin\", other_avatar: \"default_doubi.png\", other_name: \"test\", logs: Array[6]}\n             // 需要缓存这个数据\n            var cache_user_data = window.sessionStorage.getItem(data.user_id);\n            if(cache_user_data) {\n                // 如果有缓存数据直接从从缓存数据中取\n                cache_chat_log(data, chat_init);\n            }\n            else {\n                // 如果不存在缓存数据，重新从服务端拉取\n                get_chat_log(user_id, chat_init);\n            }\n         }\n         // 返回发送成功的信息\n         else if(result.errorcode == 1) {\n             // data = {\'me_id\': 2, \'data\': [\'>\', \'test, \'2015/09/26\']}\n             var data = JSON.parse(evt.data).data;\n             // 发送者user_id\n             var user_id = data.user_id;\n             // 需要缓存这个数据\n             var cache_user_data = window.sessionStorage.getItem(data.user_id);\n             if(cache_user_data) {\n                // 如果有缓存数据直接从从缓存数据中取\n                cache_chat_log(data, chat_init);\n             }\n             else {\n                // 如果不存在缓存数据，重新从服务端拉取\n                 get_chat_log(user_id, chat_init);\n             }\n         }\n         else if(result.errorcode == 2){\n             $.notify(\'未在线,等待上线回复.\')\n         }\n         else if(result.errorcode == 3){\n         }\n         else if(result.errorcode != 0)\n            alert(result.txt);\n\n     }\n     function onError(evt) {\n        console.log(\'Error occured: \' + evt.data);\n     }\n}\n\n// 缓存聊天记录\nfunction cache_chat_log(data, callback) {\n    // cache_user_data = {me_avatar: \"admin.png\", me_name: \"admin\", other_avatar: \"default_doubi.png\", other_name: \"test\", logs: Array[6]}\n    // 字符串缓存 -> 格式化为json -> 把新的聊天记录push到data.logs -> 重新格式化字符串保存到缓存中\n    // 然后把数据json格式化成字符串保存到sessionStorage\n     var cache_user_data = window.sessionStorage.getItem(data.user_id);\n     cache_user_data = JSON.parse(cache_user_data);\n     cache_user_data.logs.push(data.data)\n     window.sessionStorage.setItem(data.user_id, JSON.stringify(cache_user_data));\n     callback(cache_user_data);\n}\n\n// 获取聊天记录\n// 如果没有缓存或者没有启用localStorage，那么需要重新从服务器获取聊天记录\nfunction get_chat_log(other_id, callback) {\n    $.ajax({\n        type: \'post\',\n        dataType: \'json\',\n        url: \'/useropt\',\n        data: JSON.stringify({\n            \'opt\': \'realtime-chat\',\n            \'data\': {\'other\': other_id}\n        }),\n        success: function(result, status) {\n            if(result.errorcode == 0) {\n                var data = result[\'data\'];\n                // data = {me_avatar: \"admin.png\", me: \"admin\", other_avatar: \"default_doubi.png\", other: \"test\", logs: Array[6]}]\n                // 设置最初始的缓存\n                window.sessionStorage.setItem(other_id, JSON.stringify(data));\n                callback(data);\n            }\n            else if(result.errorcode == -3) {\n                $.notify(result.txt);\n                return false;\n                }\n            else if(result.errorcode != 0) {\n                $.notify(result.txt);\n                return false;\n            }\n        }\n    });\n}\n\n// 把聊天记录格式到组件\nfunction chat_init(data) {\n    console.log(data);\n    if(!data)\n        return;\n    $(\'.chat .chat-header\').html(\'chat 2 \' + data[\'me\']);\n    $(\'.chat .chat-header\').attr(\'other_avatar\', data[\'other_avatar\']);\n    $(\'.chat .chat-header\').attr(\'me_avatar\', data[\'me_avatar\']);\n    var chatlog = data[\'logs\'];\n    var chatcontent = $(\'.chat .chat-content ul\');\n    $(chatcontent).html(\'\');\n    for(var i = 0; i < chatlog.length; i++) {\n        if (chatlog[i][0] == \"<\")\n            var s = \"<li class=\'chat-other cl\'><img class=\'avatar\' src=\'/assets/images/avatar/\"+data[\'other_avatar\']+\"\'><div class=\'chat-text\'>\"+chatlog[i][1]+\"</div></li>\";\n        else\n            var s = \"<li class=\'chat-self cl\'><img class=\'avatar\' src=\'/assets/images/avatar/\"+data[\'me_avatar\']+\"\'><div class=\'chat-text\'>\"+chatlog[i][1]+\"</div></li>\";\n        $(chatcontent).append(s)\n    }\n    $(\'.chat-container\').show();\n}\n```\n\n## Tornado的解决方案\n\nDB用的mysql, driver用的是peewee.\n\n### 数据模型\n\n```\nclass ChatLog(BaseModel):\n    me = ForeignKeyField(User, related_name=\'who-send\')\n    other = ForeignKeyField(User, related_name=\'send-who\')\n    content = TextField(verbose_name=\'chat-content\')\n    time = DateTimeField(default=datetime.datetime.now)\n\n    @staticmethod\n    def get_chat_log(me, other):\n        \'\'\'\n        获取双方对话的聊天记录\n        :param self:\n        :param other:\n        :return:\n        \'\'\'\n        result = {\'me\': \'\', \'other\': \'\', \'logs\': []}\n        result[\'me\'] = me.username\n        result[\'other\'] = other.username\n        result[\'me_avatar\'] = me.avatar\n        result[\'other_avatar\'] = other.avatar\n        # import pdb;pdb.set_trace()\n\n        # () 注意需要全包\n        chatlogs = (ChatLog.select().where(((ChatLog.me == me) & (ChatLog.other == other)) | ((ChatLog.me == other) & (ChatLog.other == me))).order_by(ChatLog.time).limit(10))\n        for cl in chatlogs:\n            d = \'>\' if cl.me == me else \'<\'\n            result[\'logs\'].append([d, cl.content, TimeUtil.datetime_delta(cl.time)])\n        return result\n```\n\n### Websocket处理Handler\n\n处理handler的地方加了一个peewee的hook，在sql处理前建立连接，处理完成后释放连接\n\n```\nclass WebsocketChatHandler(BaseWebsocketHandler):\n    \"\"\"\n    使用websocket的实时聊天\n\n    websocket real-time-chat\n    \"\"\"\n\n    # redis ?\n    clients = {}\n\n    def check_origin(self, origin):\n        return True\n\n    @ppeewwee\n    def open(self, *args, **kwargs):\n\n        user = self.current_user\n        if user.username not in WebsocketChatHandler.clients.keys():\n            WebsocketChatHandler.clients[user.username] = self\n\n    @ppeewwee\n    def on_close(self):\n        user = self.current_user\n\n        if user.username in WebsocketChatHandler.clients.keys():\n            WebsocketChatHandler.clients.pop(user.username)\n        else:\n            logger.debug(\"[{0}] not in Websocket.clients, but close.\".format(user.username))\n\n    @staticmethod\n    def is_online(username):\n        w = WebsocketChatHandler.clients.get(username, False)\n        return w\n\n    @ppeewwee\n    def on_message(self, message):\n        json_data = get_cleaned_json_data_websocket(message, [\'opt\', \'data\'])\n        data = json_data[\'data\']\n        opt = json_data[\'opt\']\n        if opt == \'chat-to\':\n            user = self.current_user\n            # 目标用户\n            other_id = data[\'other\']\n            other = User.get(User.id == other_id)\n            content = data[\'content\']\n            cl = ChatLog.create(me=user, other=other, content=content)\n\n            #push to [other]\n            other_websocket = WebsocketChatHandler.is_online(other.username)\n            if other_websocket:\n                # <\n                other_websocket.write_message(json_result(0, {\'user_id\': user.id, \'data\': [\'<\', cl.content, TimeUtil.datetime_delta(cl.time)]}))\n                # >\n                self.write_message(json_result(1, {\'user_id\': other.id, \'data\': [\'>\', cl.content, TimeUtil.datetime_delta(cl.time)]}))\n            else:\n                self.write_message(json_result(2, \'success.\'))\n\n        else:\n            self.write_message(json_result(-1, \'not support opt.\'))\n```\n','2016-11-10 01:23:36',0),(247,'Tornado源码阅读总结','tornado-summary',102,'## application\n1. 基本配置初始化，关键是对路由规则的配置\n2. Httpserver的初始化，继承于Configurable，工厂方法设计模式，，基本参数初始化，初始化父类tcpserver(同样也是进行基本参数初始化)\n3. Httpserver监听(是指是穿透到tcp进行监听),建立监听socket\n\n## ioloop\n事件循环，类似libev，在不同platform实现不同的事件循环机制(epoll,select)\n\n1. IOLoop初始化，继承于Configurable，工厂设计模式\n\n## Tornado值得学习\n### Tornado工厂方法\n重写`__new__`函数，根据`configurable_base`和`configurable_default`返回子类，然后`initialize(instead of __init__)`进行初始化。IOLoop的初始化过程 `IOLoop() -> Configurable.__new__() -> KQueueIOLoop.initialize() -> PollIOLoop.initialize() -> IOLoop.initialize()`，同时初始化Waker()，用于在timeout之前返回，通过发送一个字符x唤醒\n\n```\nclass Configurable(object):\n    __impl_class = None\n    __impl_kwargs = None\n\n    def __new__(cls, *args, **kwargs):\n        base = cls.configurable_base()\n        init_kwargs = {}\n        if cls is base:\n            impl = cls.configured_class()\n            if base.__impl_kwargs:\n                init_kwargs.update(base.__impl_kwargs)\n        else:\n            impl = cls\n        init_kwargs.update(kwargs)\n        instance = super(Configurable, cls).__new__(impl)\n        # initialize vs __init__ chosen for compatibility with AsyncHTTPClient\n        # singleton magic.  If we get rid of that we can switch to __init__\n        # here too.\n        instance.initialize(*args, **init_kwargs)\n        return instance\n\n    @classmethod\n    def configurable_base(cls):\n        \"\"\"Returns the base class of a configurable hierarchy.\n\n        This will normally return the class in which it is defined.\n        (which is *not* necessarily the same as the cls classmethod parameter).\n        \"\"\"\n        raise NotImplementedError()\n\n    @classmethod\n    def configurable_default(cls):\n        \"\"\"Returns the implementation class to be used if none is configured.\"\"\"\n        raise NotImplementedError()\n\n    def initialize(self):\n        \"\"\"Initialize a `Configurable` subclass instance.\n\n        Configurable classes should use `initialize` instead of ``__init__``.\n\n        .. versionchanged:: 4.2\n           Now accepts positional arguments in addition to keyword arguments.\n        \"\"\"\n\n    @classmethod\n    def configure(cls, impl, **kwargs):\n        \"\"\"Sets the class to use when the base class is instantiated.\n\n        Keyword arguments will be saved and added to the arguments passed\n        to the constructor.  This can be used to set global defaults for\n        some parameters.\n        \"\"\"\n        base = cls.configurable_base()\n        if isinstance(impl, (unicode_type, bytes)):\n            impl = import_object(impl)\n        if impl is not None and not issubclass(impl, cls):\n            raise ValueError(\"Invalid subclass of %s\" % cls)\n        base.__impl_class = impl\n        base.__impl_kwargs = kwargs\n\n    @classmethod\n    def configured_class(cls):\n        \"\"\"Returns the currently configured class.\"\"\"\n        base = cls.configurable_base()\n        if cls.__impl_class is None:\n            base.__impl_class = cls.configurable_default()\n        return base.__impl_class\n\n    @classmethod\n    def _save_configuration(cls):\n        base = cls.configurable_base()\n        return (base.__impl_class, base.__impl_kwargs)\n\n    @classmethod\n    def _restore_configuration(cls, saved):\n        base = cls.configurable_base()\n        base.__impl_class = saved[0]\n        base.__impl_kwargs = saved[1]\n```\n','2016-11-10 01:23:36',0),(248,'Tornado项目模板','tornado-project-generator',102,'最近写了一个tornado的项目模板生成器。可以快速生成tornado项目，从后端DB、日志记录、session控制、参数清理等都做了比较好的封装。github:[tornado-project-generator](https://github.com/jmpews/tornado-project-generator)。\n\n首先这个框架是基于Py3的，但其实Py2稍微改下就能用。\n\n### 1.DB相关处理\n\nMongo做session存储、服务器stats(例如url访问统计)\n\nReis做访问频率限制以及cache缓存(访问速率其实可以在nginx进行控制,见附)\n\nMySQL做DB存储\n\n(可能并不需要这么多)\n\n#### MySQL\n##### peewee\n\n使用peewee做为driver,虽然使用了connectionpool但是没有添加RequestHook(在请求来时创建连接，请求结束释放),如果使用可能需要调节这里。\n\n**创建数据库需要设置好编码**\n\n#### Redis\n##### 用户访问频率限制\n封装了几个处理的handler\n\n`\'ratelimit:ip\':count`\n\nExample: `\'ratelimit:127.0.0.1\':5` & `expire(5)`\n\n#### Mongo\n#### 用户Session\n`{ \"_id\" : \"encrypt_id\", \"data\" : { \"key\" : \"value\" } }`\n\nExample: `{ \"_id\" : \"Km9hAb58ePjV9NdJtBR0lxNMmSPfe6e3Kmi43n6gsDMp1GTWet8wHS3mYjcX6g\", \"data\" : { \"openid\" : \"test\" } }`\n\n### 2.utils相关封装\n\n#### 参数安全获取\n\n```\ndef get_cleaned_post_data(handler,args,blank=False):\n    \'\'\'\n    这个是自定义异常的，然后到get/post去catch然后异常处理，亦可以raise HTTPError来的通用。\n    \'\'\'\n    data={}\n    for k in args:\n        try:\n            data[k]=clean_data(handler.get_body_argument(k))\n        except MissingArgumentError:\n            if blank:\n                data[k]=None\n            else:\n                raise RequestArgumentError(k+\' arg not found\')\n    return data\n```\n可以post方法里这样获取参数`post_data=get_cleaned_post_data(self,[\'username\',\'password\'])`\n\n对于异常有两种处理:\n\n(1).`try:catch`自定义处理异常\n\n```\ntry:\n    post_data=get_cleaned_post_data(self,[\'username\',\'password\'])\nexcept RequestArgumentError as e:\n    self.write(json_result(e.code,e.msg))\n    return\n```\n\n(2).不做自定义处理,错误被抛到`BaseRequestHandler`的`write_error`，在那里做统一处理\n\n```\nclass BaseRequestHandler(RequestHandler):\n    \'\'\'\n    重写了异常处理\n    \'\'\'\n    def write_error(self, status_code, **kwargs):\n        if \'exc_info\' in kwargs:\n            # 参数缺失异常\n            if isinstance(kwargs[\'exc_info\'][1],RequestArgumentError):\n                self.write(json_result(kwargs[\'exc_info\'][1].code,kwargs[\'exc_info\'][1].msg))\n                return\n\n        if status_code==400:\n            self.write(json_result(400,\'缺少参数\'))\n            return\n        if not config.DEBUG:\n            self.redirect(\"/static/500.html\")\n```\n\n#### 登陆(loginrequired)\n```\ndef login_required(method):\n    from tornado.httpclient import HTTPError\n    \'\'\'\n    取自\"tornado.web.authenticated\"\n    `self.current_user`是一个@property\n    \'\'\'\n    @functools.wraps(method)\n    def wrapper(self, *args, **kwargs):\n        if not self.current_user:\n            if self.request.method in (\"GET\", \"HEAD\"):\n                url = self.get_login_url()\n                if \"?\" not in url:\n                    if urlparse.urlsplit(url).scheme:\n                        # if login url is absolute, make next absolute too\n                        next_url = self.request.full_url()\n                    else:\n                        next_url = self.request.uri\n                    url += \"?\" + urlencode(dict(next=next_url))\n                self.redirect(url)\n                return\n            raise HTTPError(403)\n        return method(self, *args, **kwargs)\n    return wrapper\n```\n\n### 使用&测试\n\n安装requirements.txt\n```\npip install -r requirements.txt\n```\n\nmysql配置\n```\n# create database\nCREATE DATABASE tornado\n  DEFAULT CHARACTER SET utf8\n  DEFAULT COLLATE utf8_general_ci;\n\n# 创建基本数据库\npython tests/test_mysql.py\n```\n\nredis安全配置\n```\nbind 127.0.0.1\n```\n\nmongo安全配置\n```\nnet:\n  port: 27017\n  bindIp: 127.0.0.1\n```\n\n`python app.py -port=8001`\n\n默认用户(`test_mysql.py`) `{username: admin,password: root}`\n\n### 附录\n\n#### Nginx配置文件\n```\nuser nginx;\nworker_processes auto;\nerror_log /var/log/nginx/error.log;\npid /run/nginx.pid;\n\nevents {\n    worker_connections 1024;\n}\n\nhttp {\n    upstream frontends {\n        server 127.0.0.1:8001;\n        server 127.0.0.1:8002;\n    }\n\n    include /etc/nginx/mime.types;\n    default_type application/octet-stream;\n\n    access_log /var/log/nginx/access.log;\n\n    keepalive_timeout 65;\n    proxy_read_timeout 200;\n    sendfile on;\n    tcp_nopush on;\n    tcp_nodelay on;\n    gzip on;\n    gzip_min_length 1000;\n    gzip_proxied any;\n    gzip_types text/plain text/css text/xml\n               application/x-javascript application/xml\n               application/atom+xml text/javascript;\n\n\n    log_format  main  \'$remote_addr - $remote_user [$time_local] \"$request\" \'\n                      \'$status $body_bytes_sent \"$http_referer\" \'\n                      \'\"$http_user_agent\" \"$http_x_forwarded_for\"\';\n\n    # rate limit:分配10m的zone,每秒5次上限\n    limit_req_zone $binary_remote_addr zone=allips:10m rate=5r/s;\n    # Load modular configuration files from the /etc/nginx/conf.d directory.\n    # See http://nginx.org/en/docs/ngx_core_module.html#include\n    # for more information.\n    include /etc/nginx/conf.d/*.conf;\n\n    server {\n        listen 80;\n        server_name  weixin.linevery.com;\n\n        # 桶控制\n        limit_req zone=allips burst=2 nodelay;\n\n        client_max_body_size 50M;\n\n        location ^~ /static/ {\n            # 根目录文件\n            root /home/jmpews/sxuhelp;\n            if ($query_string) {\n                expires max;\n            }\n        }\n        location = /favicon.ico {\n            rewrite (.*) /static/favicon.ico;\n        }\n        location = /robots.txt {\n            rewrite (.*) /static/robots.txt;\n        }\n\n        location / {\n            proxy_pass_header Server;\n            proxy_set_header Host $http_host;\n            proxy_redirect off;\n            proxy_set_header X-Real-IP $remote_addr;\n            proxy_set_header X-Scheme $scheme;\n            proxy_pass http://frontends;\n        }\n    }\n}\n```\n','2016-11-10 01:23:36',0),(249,'Zmap笔记','zmap-tool',115,'## Zmap编译安装\n```\ncmake -DWITH_REDIS=OFF -DENABLE_DEVELOPMENT=ON .\n```\n\n## 扫描IP段\n```\nsudo zmap -p 80 -o results.csv 114.215.105.0/24\n```\n\n## 使用配置文件进行扫描\n```\nprobe-module tcp_synscan\ntarget-port 80\n\noutput-module csv\noutput-file zmap-output-80.csv\noutput-filter \"success = 1 && repeat = 0\"\noutput-fields \"saddr,daddr,sport,seqnum,acknum,cooldown,repeat,timestamp-str\"\n\n#Gateway MAC address to send packets to (in case auto-detection does not work)\n#gateway-mac addr\n\n# see the packets that would be sent over the network\n# dryrun\n\n# Level of log detail\nverbosity 3\n\n# finish summary\nmetadata-file zmap-80-metadata.json\n\n# zmap log\nlog-file zmap-80.log\n\n# zmap status\nstatus-updates-file zmap-status.txt\n```\n\n## 参考资料\n---\n\n[Github-Issue] https://github.com/zmap/zmap/issues (比如:summary选项已经移除、使用metadata-file代替)\n\n[不错的资料] https://linux.cn/article-5860-1.html#probemodule\n\n[官方Doc] https://zmap.io/documentation.html\n\n[Man] `man zmap`\n','2016-11-10 01:23:36',0),(250,'为Python添加DES_CFB_64加密解密模块','python-des-cfb-64',107,'看过一个搞二进制的哥们把99宿舍的搞定了加密解密方式。用的是`des_cfb64`加密的方式，但是用了几个python加密库都不对，就尝试自己给python写了一个模块，用的是openssl的lib\n\n### 核心的加密解密模块\n\n```\n#pycet.c\n#include \"Python.h\"\n#include <stdio.h>\n#include <string.h>\n#include <stdlib.h>\n#include <openssl/des.h>\n\nchar * Encrypt( char *Key, char *Msg, int size);\nchar * Decrypt( char *Key, char *Msg, int size);\nstatic PyObject *SpamError;\n\nstatic PyObject *\ncet_des_cfb64(PyObject *self,PyObject *args)\n{\n    unsigned char * txt;\n    unsigned int length;\n    unsigned char * key;\n    unsigned int C;\n    char * r;\n    int i=0;\n    PyObject *result;\n\n    //接受python参数\n    if(!PyArg_ParseTuple(args,\"s#sI\",&txt,&length,&key,&C))\n    {\n        return NULL;\n    }\n\n    //分配result_buffer\n    r = malloc(length);\n\n    //加密和解密\n    if(C)\n        memcpy(r, Encrypt(key, txt, length), length);\n    else\n        memcpy(r, Decrypt(key, txt, length), length);\n\n\n    //保存成python结果\n    result = PyBytes_FromStringAndSize(r,length);\n\n    //释放malloc\n    free(r);\n    return result;\n}\n\n// 安装约定部分\n//\nstatic PyMethodDef SpamMethods[]={\n    {\"cetdes\",cet_des_cfb64,METH_VARARGS,\"cet_des_cfb64\"},\n    {NULL,NULL,0,NULL}\n};\n\nstatic struct PyModuleDef spammodule = {\n    PyModuleDef_HEAD_INIT,\n    \"cetdes\",\n    NULL,\n    -1,\n    SpamMethods\n};\nPyMODINIT_FUNC\nPyInit_cetdes(void)\n{\n    PyObject *m;\n    m = PyModule_Create(&spammodule);\n    if(m==NULL)\n        return NULL;\n    SpamError = PyErr_NewException(\"cetdes.error\",NULL,NULL);\n    Py_INCREF(SpamError);\n    PyModule_AddObject(m,\"error\",SpamError);\n    return m;\n}\n\n//des_cfb64_encrypt\nchar *\nEncrypt( char *Key, char *Msg, int size)\n{\n\n	static char*    Res;\n	int             n=0;\n	DES_cblock      Key2;\n	DES_key_schedule schedule;\n\n	Res = ( char * ) malloc( size );\n\n	/* Prepare the key for use with DES_cfb64_encrypt */\n	memcpy( Key2, Key,8);\n	DES_set_odd_parity( &Key2 );\n	DES_set_key_checked( &Key2, &schedule );\n\n	/* Encryption occurs here */\n	DES_cfb64_encrypt( ( unsigned char * ) Msg, ( unsigned char * ) Res,\n			   size, &schedule, &Key2, &n, DES_ENCRYPT );\n\n	 return (Res);\n}\n\n//des_cfb64_decrypt\nchar *\nDecrypt( char *Key, char *Msg, int size)\n{\n\n	static char*    Res;\n	int             n=0;\n\n	DES_cblock      Key2;\n	DES_key_schedule schedule;\n\n	Res = ( char * ) malloc( size );\n\n	/* Prepare the key for use with DES_cfb64_encrypt */\n	memcpy( Key2, Key,8);\n	DES_set_odd_parity( &Key2 );\n	DES_set_key_checked( &Key2, &schedule );\n\n	/* Decryption occurs here */\n	DES_cfb64_encrypt( ( unsigned char * ) Msg, ( unsigned char * ) Res,\n			   size, &schedule, &Key2, &n, DES_DECRYPT );\n\n	return (Res);\n\n}\n```\n\n### 安装模块\n```\n#setup.py\nfrom distutils.core import setup,Extension\nmoduleone=Extension(\'cetdes\',\n        sources=[\'pycet.c\'],\n        include_dirs=[\'/usr/local/opt/openssl/include\'],\n        library_dirs=[\'/usr/local/opt/openssl/lib\'],\n        libraries = [\'crypto\']\n        )\nsetup(name=\'cetdes\',\n    version=\'1.0\',\n    description=\'This is cetdes\',\n    ext_modules=[moduleone]\n)\n```\n\n链接`-lcrypto`库,LIB: `-L/usr/local/opt/openssl/lib`,INCLUDE: `-I/usr/local/opt/openssl/include`\n\n### 参考链接\n[Extending Python with C or C++(官方)] https://docs.python.org/3.5/extending/extending.html\n','2016-11-10 01:23:36',0),(251,'前端笔记','frontend-note',116,'## 0. 前端开发环境部署\n采用gulp作为构建工具\n\n```\nvar gulp = require(\'gulp\'),\n    less = require(\'gulp-less\'),\n    sass = require(\'gulp-ruby-sass\'),\n    autoprefixer = require(\'gulp-autoprefixer\'),\n    minifycss = require(\'gulp-minify-css\'),\n    eslint = require(\'gulp-eslint\');\n    uglify = require(\'gulp-uglify\'),\n    imagemin = require(\'gulp-imagemin\'),\n    rename = require(\'gulp-rename\'),\n    concat = require(\'gulp-concat\'),\n    notify = require(\'gulp-notify\'),\n    cache = require(\'gulp-cache\'),\n    del = require(\'del\');\n\ngulp.task(\'scripts\', function() {\n  return gulp.src(\'src/scripts/*.js\')\n    .pipe(eslint.formatEach(\'compact\', process.stderr))\n    .pipe(concat(\'main.js\'))\n    .pipe(gulp.dest(\'src/assets/js\'))\n    .pipe(rename({suffix: \'.min\'}))\n    .pipe(uglify())\n    .pipe(gulp.dest(\'src/assets/js\'))\n    .pipe(notify({ message: \'Scripts task complete\' }));\n});\n\ngulp.task(\'styles\', function(){\n    return sass([\'./src/bootstrap/scss/bootstrap.scss\',\'./src/styles/index.scss\'])\n    .pipe(autoprefixer(\'last 2 version\', \'Safari 5\', \'IE 8\', \'IE 9\', \'Opera 12.1\', \'IOS 6\', \'android 4\'))\n    .pipe(gulp.dest(\'src/assets/css\'))\n    .pipe(rename({suffix: \'.min\'}))\n    .pipe(minifycss())\n    .pipe(gulp.dest(\'src/assets/css\'))\n    .pipe(notify({ message: \'Styles task complete\' }));\n})\n\n\ngulp.task(\'images\', function() {\n  return gulp.src(\'src/images/**/*\')\n    .pipe(imagemin({ optimizationLevel: 3, progressive: true, interlaced: true }))\n    .pipe(gulp.dest(\'src/assets/img\'))\n    .pipe(notify({ message: \'Images task complete\' }));\n});\n\ngulp.task(\'clean\', function() {\n    // del([\'src/assets/css\', \'src/assets/img\'])\n});\n\ngulp.task(\'watch\', function() {\n  // Watch .scss files\n  gulp.watch(\'src/bootstrap/scss/*.scss\', [\'styles\']);\n  gulp.watch(\'src/styles/*.scss\', [\'styles\']);\n  // Watch .js files\n  gulp.watch(\'src/scripts/*.js\', [\'scripts\']);\n  // Watch image files\n  gulp.watch(\'src/images/**/*\', [\'images\']);\n});\n\n// Default task\ngulp.task(\'default\', [\'clean\'], function() {\n    gulp.start(\'styles\', \'scripts\', \'images\');\n    gulp.start(\'watch\');\n});\n```\n\n## 1.`click`事件穿透\n`stopPropagation`阻止事件的传播，阻止时间传递给其他的dom节点\n\n## 2.多个div同行几种实现\n#### 1).`float`\n但是需要`clearfix`,并且最好该div的`with`为固定,否则会导致长度超一行而转到下一行\n\n#### 2).`display:inline-block`\n\n#### 3).`position: absolute`\n\n## 3.表单submit提交前数据修改\n假如我在表单的form使用了summernote这个富文本编辑器，在获取内容的时候需要使用`$(\'#summernote\').summernote(\'code\')`，如果不使用ajax进行数据提交，可以采用这种解决方案。\n\n在form添加一个隐藏的input`<input name=\"content\" style=\"display:none;\"/>`，然后对form添加一段js\n```\n$(\'form\').on(\'submit\', function (e) {\n    $(e.target).find(\'[name=content]\').val($(\'#summernote\').summernote(\'code\'));\n    return 1;\n});\n```\n','2016-11-10 01:23:36',0),(252,'如何使多Container协同发挥Docker的优势','mutiple-docker',98,'这里用Docker部署一个torweb(Tornado, MySQL)服务作为例子。将整个服务拆分为Web(Python)和MySQL放在不同的容器运行。\n\n这里的torweb是我自己写的服务，https://github.com/jmpews/torweb ，Dockerfile配置文件， https://github.com/jmpews/dockerfiles\n\n\n###Web层部署(搭建Tornado运行环境)\n几个注意点\n1. 最好把需要完成一个任务的所有命令放在一行(`&&`)，因为docker使用行作为每一步的分割，每执行一步就会做cache，当出现错误，下次执行会使用之前cache。\n2. 注意基础依赖包的安装，比如:`ssl`, `sqlite3`等\n3. 需要将Dockerfile需要COPY的文件放到和Dockerfile同目录下。\n\n```\nFROM daocloud.io/library/ubuntu:14.04\n\nMAINTAINER jmpews \"jmpews@gmail.com\"\n\n# 将修改源所有命令放在一行用&&连接\nRUN cp /etc/apt/sources.list /etc/apt/sources.list.bak \\\n&& echo \'deb http://mirrors.aliyun.com/ubuntu/ trusty main restricted universe multiverse\\n\\\ndeb http://mirrors.aliyun.com/ubuntu/ trusty-security main restricted universe multiverse\\n\\\ndeb http://mirrors.aliyun.com/ubuntu/ trusty-updates main restricted universe multiverse\\n\\\ndeb http://mirrors.aliyun.com/ubuntu/ trusty-proposed main restricted universe multiverse\\n\\\ndeb http://mirrors.aliyun.com/ubuntu/ trusty-backports main restricted universe multiverse\\n\\\ndeb-src http://mirrors.aliyun.com/ubuntu/ trusty main restricted universe multiverse\\n\\\ndeb-src http://mirrors.aliyun.com/ubuntu/ trusty-security main restricted universe multiverse\\n\\\ndeb-src http://mirrors.aliyun.com/ubuntu/ trusty-updates main restricted universe multiverse\\n\\\ndeb-src http://mirrors.aliyun.com/ubuntu/ trusty-proposed main restricted universe multiverse\\n\\\ndeb-src http://mirrors.aliyun.com/ubuntu/ trusty-backports main restricted universe multiverse\' > /etc/apt/sources.list \\\n&& apt-get update\n\n# DEBIAN_FRONTEND=noninteractive 不进行交互\n# 先检查有没有安装 sqlite3 ssl\nRUN DEBIAN_FRONTEND=noninteractive apt-get install -y --no-install-recommends \\\n                                    build-essential \\\n                                    g++ \\\n                                    gcc \\\n                                    libc6-dev \\\n                                    make \\\n                                    python-pip \\\n                                    libssl-dev \\\n                                    openssl \\\n                                    sqlite3 \\\n                                    libsqlite3-dev \\\n    && apt-get install -y wget curl git\n# 删除apt-get的缓存\n# RUN rm -rf /var/lib/apt/lists/*\n\n# 修改时区\nRUN echo \"Asia/Shanghai\" > /etc/timezone && dpkg-reconfigure -f noninteractive tzdata\n\n# COPY 目录下所有文件到指定目录下，注意最后`/`保留\n# 配置应用目录\nRUN mkdir -p /app/torweb\nCOPY torweb /app/torweb/ #目标文件是目录拷贝目录下所有文件到指定目录下\nCOPY Python-3.5.2.tgz /root/ #拷贝指定文件到目录下\n\n# Python环境配置，修改为阿里源\nRUN mkdir ~/.pip && echo \'[global]\\n\\\nindex-url = http://mirrors.aliyun.com/pypi/simple/\\n\\\n[install]\\n\\\ntrusted-host = mirrors.aliyun.com\' > ~/.pip/pip.conf\n\n# 配置Python3的环境\n# RUN wget https://www.python.org/ftp/python/3.5.2/Python-3.5.2.tgz\nRUN cd /root/ \\\n    && tar zxvf Python-3.5.2.tgz \\\n    && cd /root/Python-3.5.2 \\\n    && ./configure --prefix=/usr/local/python3.5.2 \\\n    && make && make install\n\n# 使用virtualenv来做部署环境，发现好像没啥用\n# RUN pip install virtualenv \\\n#     && mkdir /virtualenv \\\n#     && cd /virtualenv \\\n#     && virtualenv -p /usr/local/python3.5.2/bin/python3 python3.5.2\n# RUN . /virtualenv/python3.5.2/bin/activate \\\n#     && pip install -r requirements.txt\n\n# 安装依赖torweb项目依赖\nRUN cd /app/torweb \\\n    &&/usr/local/python3.5.2/bin/pip3 install -r requirements.txt\n\n# 设置工作目录(默认目录)\nWORKDIR /app/torweb\n\n# EXPOSE默认不暴露端口，只有加-P参数才会将该端口随机绑定一个宿主机可用端口\n# EXPOSE 8888\n\n# CMD相当于启动命令\nCMD [\"/usr/local/python3.5.2/bin/python3\", \"app.py\"]\n\n# EXPOSE 方式，使用docker ps会发现绑定到宿主机随机可用端口\n# docker run -d -P --link db:db jmpews/base:test1\n# -p特定端口映射\n# docker run -d -p 8888:8888 --link db:db jmpews/base:test1\n```\n\n### MySQL部署\n直接使用`daocloud.io/library/mysql:5.7.14`镜像。\n\n启动MySQL作为一个容器。\n\n```\n# -e MYSQL_ROOT_PASSWORD 环境变量,启动Container必须设置的数据库密码\n# --name 容器的名字\ndocker run --name torweb-mysql -e MYSQL_ROOT_PASSWORD=root -d daocloud.io/library/mysql:5.7.14\n```\n\n###连接Web、MySQL两个容器\n通过`--link`连接容器，现在属于从属关系，现在torweb层服务父容器可以通过隧道调用MySQL服务，MYSQL子容器通过注入环境变量来传递配置参数给torweb层父容器。\n\n通过`docker run -ti --link torweb-mysql:db jmpews/base:test1 /bin/bash -c env`，可以发现注入了很多`DB_`的环境变量(`DB_`即为db别名的大写)，所以在程序中需要通过这些环境变量连接数据库。\n![](http://oaxgrbqi8.bkt.clouddn.com/14703344757862.jpg)\n\n刚才已经启动MySQL服务。\n\n```\n# torweb-mysql为容器name，db为容器别名\n# 启动会执行Dockerfile里CMD对应的命令\ndocker run -d -p 8888:8888 --link torweb-mysql:db jmpews/base:test1\n\n```\n\n###通过`Docker-Compose`更简洁快速部署\n这样我们需要先启动MySQL服务，再启动Web服务，过程繁琐，Docker官方推荐使用`docker-compose`，进行统一部署。\n\n在目录下建立`docker-compose.yml`，然后使用`docker-compose up`配置。\n\n具体配置目录如下。\n![](http://oaxgrbqi8.bkt.clouddn.com/14703354062153.jpg)\n\n具体配置文件内容如下。\n\n```\n# docker-compose.yml\ntorweb:\n	# docker build目录\n  build: ./web\n  links:\n    - db:db\n  ports:\n    - 8888:8888\n  # 每次启动执行命令\n  command: /usr/local/python3.5.2/bin/python3 app.py\n\ndb:\n	# docker的基础镜像\n  image: daocloud.io/library/mysql:5.7.14\n  expose:\n    - \"3306\"\n  environment:\n    MYSQL_ROOT_PASSWORD: root\n```\n\n\n\n','2016-11-10 01:23:36',0),(253,'开发工具栈','develop-tools',113,'### flake8\n对python代码进行编码规范检查，对应的vim插件`vim-flake8`,`syntastic`\n\n### Vagrant\n类似于VPS，开始时打包开发部署环境\n\nbox镜像: http://www.vagrantbox.es/\n\n```\n#添加box\nvagrant box add boxname ~/box/precise64.box\n\n#实例化一个box\nvagrant init boxname\n\n#打包一个配置好的box\nvagrant package\n```\n\n### hug\n\nAPI开发更简洁\n\n```\n```\n','2016-11-10 01:23:36',0),(254,'开发环境快速配置','develop-config',113,'### 服务器安全配置\n\n查看 **[服务器安全配置.md]**\n\n### Ubuntu基本配置\n\nssh-public-key免密码登陆\n\n```\n复制本地~/.ssh/id_rsa.pub到服务器的~/.ssh/authorized_keys\n```\n\n切换为xfce桌面\n```\nsudo apt-get remove unity && sudo apt-get autoremove\nsudo apt-get install -y xfce4 xfce4-goodies\n```\n\n生成语言编码\n```\nsudo locale-gen zh_CN.UTF-8\nsudo locale-gen zh_CN.UTF-8 en_US.UTF-8\n```\n\n修改源为阿里的源\n\n```\nvim /etc/apt/sourses.list\ndeb http://mirrors.aliyun.com/ubuntu/ trusty main restricted universe multiverse\ndeb http://mirrors.aliyun.com/ubuntu/ trusty-security main restricted universe multiverse\ndeb http://mirrors.aliyun.com/ubuntu/ trusty-updates main restricted universe multiverse\ndeb http://mirrors.aliyun.com/ubuntu/ trusty-proposed main restricted universe multiverse\ndeb http://mirrors.aliyun.com/ubuntu/ trusty-backports main restricted universe multiverse\ndeb-src http://mirrors.aliyun.com/ubuntu/ trusty main restricted universe multiverse\ndeb-src http://mirrors.aliyun.com/ubuntu/ trusty-security main restricted universe multiverse\ndeb-src http://mirrors.aliyun.com/ubuntu/ trusty-updates main restricted universe multiverse\ndeb-src http://mirrors.aliyun.com/ubuntu/ trusty-proposed main restricted universe multiverse\ndeb-src http://mirrors.aliyun.com/ubuntu/ trusty-backports main restricted universe multiverse\n```\n\n安装基本依赖\n\n```\napt-get install build-essential libssl-dev libevent-dev libjpeg-dev libxml2-dev libxslt-dev\napt-get install libssl-dev zlib1g-dev libbz2-dev libreadline-dev libsqlite3-dev\n```\n### 基本工具配置\n\n```\napt-get install git vim htop\n\n# oh-my-zsh\napt-get install zsh\nsh -c \"$(curl -fsSL https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh)\"\ncp zsh/jmp2zsh.zsh-theme ~/.oh-my-zsh/themes/\n```\n\n### mysql5.7 安装\n\n```\n#!/usr/bin/env bash\n\n# This is assumed to be run as root or with sudo\n\nexport DEBIAN_FRONTEND=noninteractive\n\n# Import MySQL 5.7 Key\n# gpg: key 5072E1F5: public key \"MySQL Release Engineering <mysql-build@oss.oracle.com>\" imported\napt-key adv --keyserver ha.pool.sks-keyservers.net --recv-keys 5072E1F5\necho \"deb http://repo.mysql.com/apt/ubuntu/ trusty mysql-5.7\" | tee -a /etc/apt/sources.list.d/mysql.list\n\napt-get update\n\n# Install MySQL\n\nMYSQL_PASS=\"qwaszx\"\n\ndebconf-set-selections <<< \"mysql-community-server mysql-community-server/data-dir select \'\'\"\ndebconf-set-selections <<< \"mysql-community-server mysql-community-server/root-pass password $MYSQL_PASS\"\ndebconf-set-selections <<< \"mysql-community-server mysql-community-server/re-root-pass password $MYSQL_PASS\"\napt-get install -y mysql-server\n```\n\n### pyenv环境配置\n```\nsudo apt-get install libc6-dev gcc make build-essential libssl-dev zlib1g-dev libbz2-dev libreadline-dev libsqlite3-dev wget curl llvm\ngit clone git://github.com/yyuu/pyenv.git ~/.pyenv\necho \'export PYENV_ROOT=\"$HOME/.pyenv\"\' >> ~/.bashrc\necho \'export PATH=\"$PYENV_ROOT/bin:$PATH\"\' >> ~/.bashrc\necho \'eval \"$(pyenv init -)\"\' >> ~/.bashrc\nexec $SHELL -l\npyenv install 2.7.11 -v\n```\n\n### Pip源配置\n`vim ~/.pip/pip.conf`\n\n```\n[global]\nindex-url = http://mirrors.aliyun.com/pypi/simple/\n[install]\ntrusted-host = mirrors.aliyun.com\n```\n\n### vitualenv配置\n\n```\n# wget --no-check-certificate https://www.python.org/ftp/python/3.5.2/Python-3.5.2.tgz\nwget --no-check-certificate https://www.python.org/ftp/python/2.7.12/Python-2.7.12.tgz\n# ./configure --prefix=/usr/local/python3.5.2\n./configure --prefix=/usr/local/python2.7.12\nsudo make & sudo make install\n# 创建环境\nvirtualenv -p /usr/local/python2.7.12/bin/python python2.7.12\n\n```\n### nginx 安装\n\n```\n# http://nginx.org/en/linux_packages.html\n```\n\n### docker 安装\n\n```\n# https://docs.docker.com/engine/installation/linux/ubuntulinux/\n```\n\n### go配置\n\n```\nwget https://storage.googleapis.com/golang/go1.6.2.linux-amd64.tar.gz\ntar xvzf go1.6.2.linux-amd64.tar.gz -C /usr/local --strip-components=0\n# 添加环境变量\nexport GOROOT=\"/usr/local/go\"\nexport GOPATH=\"$HOME/gogo\"\nexport PATH=\"$PATH:$GOROOT/bin:$GOPATH/bin\"\n```\n','2016-11-10 01:23:36',0),(255,'异步在Tornado中的实现','async-coroutine-callback',102,'对异步I/O而言，当遇到I/O需要等待时，就注册一个事件告诉系统，当数据准备好了，就调用这个函数就行，然后就立刻返回，继续执行其他，然后当事件循环机制发现数据可读啦，就调用回调函数。所以一般来说实现异步函数需要**事件循环机制**、**回调函数**。\n\n## 几个注意的点\n* 无论是回调还是协程，都必须在过程中使用异步函数。\n* 通过future来代表处理结果，简单来说用来代表执行结果，包含判断是否执行完毕、是否还在运行、是否有结果等方法。异步函数通过`set_result()`与`future`联系起来\n\n## 基于回调函数实现\n1. `fetch`返回`future`\n2. `fetch_impl`，非阻塞socket连接(注册`ioloop`，等待数据可读)\n3. 有数据可以读取(response或error)，如果有response则调用回调函数即`handle_response()`，设置`future`的结果：`future.set_result(response)`，\n4. `future.set_result(response)`调用所有_callbacks这里即`handle_future()`\n5. `handle_future()`注册真正的回调函数处理结果，下次调用\n\n```\nimport ioloop\ndef handle_request(response):\n    if response.error:\n        print \"Error:\", response.error\n    else:\n        print response.body\n    ioloop.IOLoop.instance().stop()\n\nhttp_client = httpclient.AsyncHTTPClient()\nhttp_client.fetch(\"http://www.google.com/\", handle_request)\nioloop.IOLoop.instance().start()\n```\n\n## `@tornado.gen.coroutine`配合yield实现异步\n和回调某些方面类似的，但使用协程可以通过`send(result)`，将数据回传给`response`。\n\n1. `def get(self)`因为yield的存在变为生成器函数。等待`next(get)`启动生成器，\n2. 由`@tornado.gen.coroutine`装饰函数`def get(self)`，首先会调用`next()`启动生成器，接受yield右边表达式结果作为返回值，即`fetch`返回的`future`。调用`Runner(result, future, yielded)`给`future`增加done_callback函数，即`send(value)`，返回生成器函数。\n\n采用同步的编码方式，实现异步。\n\n\n```\n    class GenAsyncHandler(RequestHandler):\n        @gen.coroutine\n        def get(self):\n            http_client = AsyncHTTPClient()\n            # 挂起等待send(result)被调用\n            response = yield http_client.fetch(\'http://example.com\')\n            do_something_with_response(response)\n            self.render(\'template.html\')\n```\n\n### 下面是具体的代码分析\n\n```\n# gen.py\n# @gen.coroutine\ndef _make_coroutine_wrapper(func, replace_callback):\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n        future = TracebackFuture()\n\n        if replace_callback and \'callback\' in kwargs:\n            callback = kwargs.pop(\'callback\')\n            IOLoop.current().add_future(\n                future, lambda future: callback(future.result()))\n\n        try:\n            # result是包含yield的那个函数生成器\n            result = func(*args, **kwargs)\n        except (Return, StopIteration) as e:\n            result = getattr(e, \'value\', None)\n        except Exception:\n            future.set_exc_info(sys.exc_info())\n            return future\n        else:\n            if isinstance(result, types.GeneratorType):\n                try:\n                    orig_stack_contexts = stack_context._state.contexts\n                    #返回异步函数的(这里为fetch)的future，通过该future将异步函数和yiled联系起来。重要！\n                    \n                    yielded = next(result)\n                    if stack_context._state.contexts is not orig_stack_contexts:\n                        yielded = TracebackFuture()\n                        yielded.set_exception(\n                            stack_context.StackContextInconsistentError(\n                                \'stack_context inconsistency (probably caused \'\n                                \'by yield within a \"with StackContext\" block)\'))\n                except (StopIteration, Return) as e:\n                # 生成器函数执行完毕\n                    future.set_result(getattr(e, \'value\', None))\n                except Exception:\n                    future.set_exc_info(sys.exc_info())\n                else:\n                    # result:函数生成器\n                    # future:get函数的future\n                    # yielded:fetch函数的future\n                    Runner(result, future, yielded)\n                try:\n                    return future\n                finally:\n                    future = None\n        future.set_result(result)\n        #　返回future\n        return future\n    ＃　返回修饰后的函数\n    return wrapper\n```\n\n```\n# gen.py\nclass Runner(object):\n    def handle_yield(self, yielded):\n        ...\n        ＃　跳过其他处理code\n        try:\n            self.future = convert_yielded(yielded)\n        except BadYieldError:\n            self.future = TracebackFuture()\n            self.future.set_exc_info(sys.exc_info())\n    \n        if not self.future.done() or self.future is moment:\n            # 注册回调函数，当fetch调用set_result()，调用run()\n            self.io_loop.add_future(\n                self.future, lambda f: self.run())\n            return False\n        return True\n    \n    def run(self):\n            if self.running or self.finished:\n                return\n            try:\n                self.running = True\n                while True:\n                    future = self.future\n                    if not future.done():\n                    #执行run时generator返回的那个future必须已经有结果，否则就没必要传回到generator中了\n                        return\n                    self.future = None\n                    try:\n                        orig_stack_contexts = stack_context._state.contexts\n                        exc_info = None\n    \n                        try:\n                            value = future.result()\n                        except Exception:\n                            self.had_exception = True\n                            exc_info = sys.exc_info()\n    \n                        if exc_info is not None:\n                            yielded = self.gen.throw(*exc_info)\n                            exc_info = None\n                        else:\n                            # send(value)将结果回传给response\n                            yielded = self.gen.send(value)\n    \n                        if stack_context._state.contexts is not orig_stack_contexts:\n                            self.gen.throw(\n                                stack_context.StackContextInconsistentError(\n                                    \'stack_context inconsistency (probably caused \'\n                                    \'by yield within a \"with StackContext\" block)\'))\n                    except (StopIteration, Return) as e:\n                        #generator执行完毕并成功的处理\n                    except Exception:\n                        #generator执行过程中异常的处理\n                    if not self.handle_yield(yielded):\n                        #这里generator还没有执行完毕，yielded是generator迭代过一次之后返回的新yielded。如果yieled还没有被解析出结果就通过handle_yield给yieled设置完成时的重启run的回调,否则yielded已经有结果，就再次运行run，所以run中才会有一个循环\n                        return\n            finally:\n                self.running = False\n```\n附：\n\n```\nclass MainHandler(tornado.web.RequestHandler):\n	@gen.coroutine\n	def get(self):\n		data=yiled self.get_data()\n		self.wirte(data)\n		self.finish()\n		\n	def get_data(self):\n		# 异步函数需要返回future\n		future=Future()\n		s=socket.socket(socket.AF_INET,socket.SOCK_STREAM)\n		s.connect((localhost,8888))\n		s.send(\'hello\\n\')\n		def handle_data(sock,event):\n			io_loop=ioloop.IOLoop.current()\n			io_loop.remove_handler(sock)\n			data=sock.recv(1024)\n			future.set_result(data)\n			\n		io_loop=ioloop.IOLoop.current()\n		io_loop.add_handlers(s,handle_data,io_loop.READ)\n		return future\n\nif __name__==\"__main__\":\n	app=tornado.web.application(\n		handlers=[\n			(r\'/\',MainHandler)\n		]\n	)\n	app.listen(8000)\n	tornado.ioloop.IOLoop.instance().start()\n```\n','2016-11-10 01:23:36',0),(256,'搭建docker-registry的开发环境(在非docker镜像下跑registry服务)','dev-docker-registry-distribution',98,'## 简介\n\n因为最近需要搭建私有的docker-registry, 官方建议使用 `registry:2.5` 镜像搭建私有registry, 但是这需要在服务器跑docker, 打算直接跑 `distribution` 应用.\n\n## 具体实践\n\n```\n# 也可以wget最近的release版本\ngit pull https://github.com/docker/distribution.git\n\n# 把源码放到$GOPATH/src/github.com/下 因为registry中引用包都是\'github.com/distribution/*\'\nmv distribution $GOPATH/src/github.com/\n\n# 生成版本信息\ncd distribution/version/\n./version.sh>>version.go\n\n# 编译registry\ncd distribution/cmd/registry/\ngo build\n\n# 设置存储位置, 运行registry服务\nexport REGISTRY_STORAGE_FILESYSTEM_ROOTDIRECTORY=/somewhere\n./registry --version\n\n./registry serve ./config-example.yml\n```\n\n## 参考文档\n\ndistribution的dockerfile : https://github.com/docker/distribution/blob/master/Dockerfile\ndistribution的dev开发环境搭建 : https://github.com/docker/distribution/blob/master/BUILDING.md\n\n','2016-11-10 01:23:36',0),(257,'使用Harbor搭建私有Docker Registry服务','docker-harbor',98,'## 简介\n\ndocker提供registry的镜像但是没有比较完善的用户管理镜像管理的功能，harbor是vm开源的对于私有Registry解决方案。\n\n## 安装\n参考 https://github.com/vmware/harbor/blob/master/docs/installation_guide.md\n\nharbar通过多个docker-compose管理多个container.\n\n```\ncd /harbor/Deploy\n./prepare\n```\n\n这里有一种离线的方式install. 可以具体具体文档。\n\n### 1. 修改基础镜像源\n\n替换所有docker hub的镜像为DaoCloud镜像, 例如:\n\n```\n# FROM mysql:5.6\nFROM daocloud.io/library/mysql:5.6\n```\n\n### 2. 修改镜像源\n修改Dockerfile.ui,Dockerfile.job,添加源修改\n\n```\n+RUN cp /etc/apt/sources.list /etc/apt/sources.list.bak\n+RUN echo \"deb http://mirrors.163.com/debian/ jessie main non-free contrib\" > /etc/apt/sources.list\n+RUN echo \"deb http://mirrors.163.com/debian/ jessie-updates main non-free contrib\" >> /etc/apt/sources.list\n+RUN echo \"deb http://mirrors.163.com/debian/ jessie-backports main non-free contrib\" >> /etc/apt/sources.list\n+RUN echo \"deb-src http://mirrors.163.com/debian/ jessie main non-free contrib\" >> /etc/apt/sources.list\n+RUN echo \"deb-src http://mirrors.163.com/debian/ jessie-updates main non-free contrib\" >> /etc/apt/sources.list\n+RUN echo \"deb-src http://mirrors.163.com/debian/ jessie-backports main non-free contrib\" >> /etc/apt/sources.list\n+RUN echo \"deb http://mirrors.163.com/debian-security/ jessie/updates main non-free contrib\" >> /etc/apt/sources.list\n+RUN echo \"deb-src http://mirrors.163.com/debian-security/ jessie/updates main non-free contrib\" >> /etc/apt/sources.list\n```\n\n启动服务 `docker-compose up`\n\n## 实践\n\n```\n# 登陆验证,增加insecure-registry选项\nvim /etc/default/docekr\nDOCKER_OPTS=\"$DOCKER_OPTS --insecure-registry=10.0.247.186\"\nservice docker restart\n\n# 登陆\ndocker login 10.0.247.186\n\n# 上传镜像, 这里需要了解镜像的命名规则\ndocker tag daocloud.io/library/nginx:1.9 10.0.247.186/library/nginx:1.9\ndocker images\ndocker push 10.0.247.186/library/nginx:1.9\n```\n','2016-11-10 01:23:36',0),(258,'数据库问题笔记','db-issue',117,'## Mysql遇到表元数据锁等待-\"Waiting for table metadata lock\"\n\n`show processlist`看不到任何对表的操作，只显示sleep，但是可以在`information_schema.innodb_trx`看到.\n\n`select * from information_schema.innodb_trx\\G`,中的`trx_mysql_thread_id`对`应show processlist`中的Id\n\n**在事务没有完成之前，Table上的锁不会释放，其他语句获取不到metadata的独占锁。**\n\n## mysql在创建数据库的时编码问题\n```\nCREATE DATABASE torweb\n  DEFAULT CHARACTER SET utf8\n    DEFAULT COLLATE utf8_general_ci;\n```\n\n## mysql远程数据库复制\n```\nmysqldump sxuhelp -h 112.126.76.80 --opt -uroot -pqwaszx|mysql sxuhelp -uroot -pqwaszx\n```\n\n## 创建用户并赋予权限\n```\n//创建用户\nuse mysql\ncreate user \'jmpews\'@\'localhost\' identified by \'qwaszx\'\nflush privileges\n//赋予用户buzz数据库所有权限(% 表示既可以远程也可以本地)\ngrant all privileges on buzz.* to \'jmpews\'@\'%\' identified by \'qwaszx\'\n\n```\n\n## 导出文件(csv)\n```\nSELECT username,email INTO OUTFILE \'/tmp/result.csv\'\nFIELDS TERMINATED BY \'\\t\'\nOPTIONALLY ENCLOSED BY \'\"\'\nLINES TERMINATED BY \'\\n\'\nFROM auth_user;\n```\n\n## `show tables`的另一种写法\n```\nselect table_name from information_schema.tables where table_schema = \'sebug\' limit 10;\n```\n\n## 正则和联合的使用\n```\nselect email, nickname, phone_number from auth_user join accounts_profile on auth_user.id = accounts_profile.user_id where phone_number regexp \'^1[0-9]{10}\' into outfile \'/tmp/sebug_phone.csv\'\nFIELDS TERMINATED BY \'\\t\'\nOPTIONALLY ENCLOSED BY \'\"\'\nLINES TERMINATED BY \'\\n\';\n```\n\n## 用户远程连接\n```\n# 允许root用户远程连接test数据库\ngrant all privileges on test.* to \'root\'@\'%\' identified by \'qwaszx\' with grant option;\n# 查看授权连接详情;\nselect user, host, authentication_string from user;\n```\n','2016-11-10 01:23:36',0),(259,'服务器安全配置','server-security-configration',118,'## 修改默认端口\n```\nvim /etc/ssh/sshd_config\n---\nPort 2333\nPermitRootLogin No\n---\nservice sshd restart\n```\n## 添加新用户并加入sudo权限\n```\nuseradd -s /bin/bash -d /home/jmpews -m jmpews\npasswd jmpews\nchmod u+w /etc/sudoers\nvim /etc/sudoers\n---\njmpews ALL=(ALL) ALL\n---\nchmod u-w /etc/sudoers\n```\n## iptables的安全配置\n```\nvi /etc/iptables.firewall.rules\n---\n*filter\n\n# Allows all loopback (lo0) traffic and drop all traffic to 127/8 that doesn\'t use lo0\n-A INPUT -i lo -j ACCEPT\n-A INPUT ! -i lo -d 127.0.0.0/8 -j REJECT\n\n# Accepts all established inbound connections\n-A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT\n\n# Allows all outbound traffic\n# You could modify this to only allow certain traffic\n-A OUTPUT -j ACCEPT\n\n# Allows HTTP and HTTPS connections from anywhere (the normal ports for websites)\n-A INPUT -p tcp --dport 80 -j ACCEPT\n-A INPUT -p tcp --dport 443 -j ACCEPT\n\n# Allows SSH connections\n# The --dport number is the same as in /etc/ssh/sshd_config\n-A INPUT -p tcp -m state --state NEW --dport 2333 -j ACCEPT\n\n# Now you should read up on iptables rules and consider whether ssh access\n# for everyone is really desired. Most likely you will only allow access from certain IPs.\n\n# Allow ping\n#  note that blocking other types of icmp packets is considered a bad idea by some\n#  remove -m icmp --icmp-type 8 from this line to allow all kinds of icmp:\n#  https://security.stackexchange.com/questions/22711\n-A INPUT -p icmp -m icmp --icmp-type 8 -j ACCEPT\n\n# log iptables denied calls (access via \'dmesg\' command)\n-A INPUT -m limit --limit 5/min -j LOG --log-prefix \"iptables denied: \" --log-level 7\n\n# Reject all other inbound - default deny unless explicitly allowed policy:\n-A INPUT -j REJECT\n-A FORWARD -j REJECT\n\nCOMMIT\n---\niptables-restore < /etc/iptables.firewall.rules\n```\n','2016-11-10 01:23:36',0),(260,'服务器端开发笔记','python-server-develop',118,'## 1. socket关闭的流程\n[socket关闭](http://www.2cto.com/net/201309/243585.html)\n[TIME_WAIT详细解释](http://www.firefoxbug.com/index.php/archives/2795/)\n[TIME_WAIT详解](http://segmentfault.com/a/1190000003509876)\n\n主动发起关闭的才会存在TIME_WAIT\n\nTIME_WAIT状态会持续2MSL的时间才会转换到CLOSE状态，一般是1-4分钟。\n\n当一端收到一个FIN，内核让read返回0来通知应用层另一端已经终止了向本端的数据传送\n\n## 2. 处理服务器端TIME_WAIT\n[TIME_WAIT参数](http://www.91python.com/archives/435)\n\n## 3. 内核参数的调整\n发现系统存在大量TIME_WAIT状态的连接，通过调整内核参数解决，`vi /etc/sysctl.conf`\n\n```\nnet.ipv4.tcp_syncookies = 1\nnet.ipv4.tcp_tw_reuse = 1\nnet.ipv4.tcp_tw_recycle = 1\nnet.ipv4.tcp_fin_timeout = 30\n```\n\n然后执行 `/sbin/sysctl -p`让参数生效。\n\n```\nnet.ipv4.tcp_syncookies = 1 表示开启SYN Cookies。当出现SYN等待队列溢出时，启用cookies来处理，可防范少量SYN攻击，默认为0，表示关闭；\nnet.ipv4.tcp_tw_reuse = 1 表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭；\nnet.ipv4.tcp_tw_recycle = 1 表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭。\nnet.ipv4.tcp_fin_timeout 修改系統默认的 TIMEOUT 时间.tcp_tw_recycle = 1\n```\n\n## 4. socket参数的调整\n\n[socket参数详解](http://blog.chinaunix.net/uid-24517549-id-4044883.html)\n\n```\nsock.setsockopt(socket.SOL_SOCKET,socket.SO_REUSEADDR,1)\nsock.setsockopt(socket.SOL_SOCKET, socket.SO_LINGER, struct.pack(\'ii\', 1, 0))\n```\n\n## 5. 文件描述符相关(select关于限制1024)\n[解释文件描述相关知识](http://blog.csdn.net/cywosp/article/details/38965239)\n\n系统为每一个进程维护了一个文件描述符表，程序刚刚启动的时候，该表的值都是从0开始的，所以在不同的进程中你会看到相同的文件描述符，这种情况下相同文件描述符有可能指向同一个文件，也有可能指向不同的文件。0是标准输入，1是标准输出，2是标准错误。如果此时去打开一个新的文件，它的文件描述符会是3。\n\n需要查看由内核维护的3个数据结构\n\n1. 进程级的文件描述符表\n2. 系统级的打开文件描述符表\n3. 文件系统的i-node表\n','2016-11-10 01:23:36',0),(261,'栈溢出漏洞之一','stackoverflow_1',99,'### 简介\n\n最近在学习安全研究, @张博 推荐 https://sploitfun.wordpress.com/2015/05/08/classic-stack-based-buffer-overflow/ 这个文章, 然后就做了一下复现, 但是发现和文章中有很大不同, 做一下记录.\n\n本来这是一个很简明的栈溢出漏洞, 覆盖$esp的地址, 也就是返回地址, 让我们自己控制返回地址.\n\n### Start\n\n```\n//vuln.c\n#include <stdio.h>\n#include <string.h>\n\nint main(int argc, char* argv[]) {\n        /* [1] */ char buf[256];\n        /* [2] */ strcpy(buf,argv[1]);\n        /* [3] */ printf(\"Input:%s\\n\",buf);\n        return 0;\n}\n```\n\n编译环境:\n\n![](assets/stackoverflow_1-fdd18.png)\n\n### 反汇编 `main` 函数\n\n![](assets/stackoverflow_1-135f9.png)\n\n画了一个运行栈状态\n\n![](assets/stackoverflow_1-83e43.png)\n\n```\ngdb-peda$ disassemble\nDump of assembler code for function main:\n   0x0804843b <+0>:	  lea    ecx,[esp+0x4] // argc address\n   0x0804843f <+4>:	  and    esp,0xfffffff0 // stack align\n   0x08048442 <+7>:  	push   DWORD PTR [ecx-0x4] // return address\n   0x08048445 <+10>:	push   ebp\n   0x08048446 <+11>:	mov    ebp,esp\n   0x08048448 <+13>:	push   ecx // save ecx\n   0x08048449 <+14>:	sub    esp,0x104\n   0x0804844f <+20>:	mov    eax,ecx\n   0x08048451 <+22>:	mov    eax,DWORD PTR [eax+0x4] // argv address\n   0x08048454 <+25>:	add    eax,0x4\n   0x08048457 <+28>:	mov    eax,DWORD PTR [eax] // arg[1]\n   0x08048459 <+30>:	sub    esp,0x8\n   0x0804845c <+33>:	push   eax\n   0x0804845d <+34>:	lea    eax,[ebp-0x108] // buf address\n   0x08048463 <+40>:	push   eax\n   0x08048464 <+41>:	call   0x8048310 <strcpy@plt>\n   0x08048469 <+46>:	add    esp,0x10\n   0x0804846c <+49>:	sub    esp,0x8\n   0x0804846f <+52>:	lea    eax,[ebp-0x108]\n   0x08048475 <+58>:	push   eax\n   0x08048476 <+59>:	push   0x8048510\n   0x0804847b <+64>:	call   0x8048300 <printf@plt>\n   0x08048480 <+69>:	add    esp,0x10\n   0x08048483 <+72>:	mov    eax,0x0\n   0x08048488 <+77>:	mov    ecx,DWORD PTR [ebp-0x4] // restore ecx\n   0x0804848b <+80>:	leave  \n   0x0804848c <+81>:	lea    esp,[ecx-0x4] // !!! set esp again, keep ecx is right!\n   0x0804848f <+84>:	ret    \nEnd of assembler dump.\n```\n\n这里有几点需要说明的.\n\n**对于第二个状态:**\n\n<+7> 是进行内存栈对齐\n\n**对于第三个状态:**\n\n`[ecx-4]` 指向的就是 `Return Address`\n\n`ecx` 入栈是为了之后恢复 `ecx`, 因为必须先知道 `ecx`, 才能通过 `[ecx-4]` 取得返回地址.\n\n`arg[1]` 是如何压入栈的? 从 <+20> 开始, `[eax+0x4]` 也就是 `[esp+0x8]` 也就是 `arg`,从 <+25> 开始, `[eax]` 也就是 `[eax+0x4]` 也就是 `*(arg+1)` 也就是 `arg[1]`\n\n所以**正常思路应该是覆盖区间 `[%ecx, $ebp-0x108]` 为 `\'A\'`, 也就是控制 `Return Address`. **\n\n### 坑?\n在 <+77> 恢复了 `ecx` 的值\n\n** 重点在 <+81> 这里, 使用 `ecx-0x4` 恢复 `%esp` 的值, 而不是使用 `leave` 恢复 `%esp` **\n\n所以 **如果我们想要继续正常思路, 我们必须保持 `ecx` 是不变的 **\n\n### 那么如何覆盖 `Return Address` ?\n#### 方法一:\n\n采用正常思路, 然后保持 `ecx` 不变, 覆盖其他\n\n#### 方法二:\n\n重新设置 `ecx`, 控制 `ecx-0x4` 为我们想要的 `%esp`, 使该 `%esp` 指向的地址是我们的 目的地址. (也就是说多了一步.)\n','2016-11-10 01:23:36',0),(262,'深入理解计算机操作系统-程序的机器级表示','scpp3',119,'### 知识点:\n\n**3.4.2 数据传送指令**\n\n栈相关知识:\n\n1. 栈向下增长\n2. %ebp 栈底 %esp栈顶\n\n**push指令**\n\n```\npush %eax\n\n// 等价命令, 考虑好大端,小端\nsubl %4, %esp\nmovl %eax, (%esp)\n```\n**pop指令**\n\n```\npop %eax\n\n//等价命令\nmovl (%esp), %eax\naddl %4, %esp\n\n```\n\n**3.6.6 条件传送指令**\n\n传统是采用: **控制** 的条件转移\n\n现代处理器: **数据** 的条件转移\n\n现代处理器 采用流水线获得高性能(重叠连续指令的步骤)\n\n注意: 并不是所有情况都可以采用数据条件转移\n\n1. xp ? *xp : 0 (间接引用空指针)\n2. xp ? (global_count++, xp) : 1 (修改了全局变量)\n3. 存在大量计算\n\n\n## 3.7 过程\n\n**3.7.1 栈帧结构**\n\n%ebp 帧指针 (大多数信息访问是相对于帧指针)\n\n%esp 栈指针 (栈指针是会改变的)\n\n栈的结构向下增长\n\n如何开始函数调用?\n\n1. 存放下一个调用需要的形参\n2. 保存返回地址 (call 的作用)\n3. 修改%ebp, %esp (在新的函数需要在一开始执行的)\n4. 在新%ebp的基础上存放局部变量和临时变量\n5. 处理调用\n6. leave 恢复%ebp 和 %esp\n7. ret 返回保存的地址继续执行\n\n**3.7.2 转移控制**\n\ncall 的作用: 将返回地址入栈\n\n**leave 指令**\n\n```\nleave\n\n// 等价命令\nmovl %ebp, %esp\npopl %ebp\n```\n','2016-11-10 01:23:36',0),(263,'如何用C为Python写扩展','write-extensions-for-python',107,'## 头文件\n`#include \"Python.h\"`\n\n## 定义你的函数\n* `PyArg_ParseTuple`，将`Pyobject* `转化为c语言对象\n\n```\nstatic PyObject *\nspam_system(PyObject *self,PyObject *args)\n{\n    const char *command;\n    int sts;\n    if(!PyArg_ParseTuple(args,\"s\",&command))\n        return NULL;\n    sts=system(command);\n    if(sts<0)\n    {\n        PyErr_SetString(SpamError,\"System command failed\");   \n        return NULL;\n    }\n    return PyLong_FromLong(sts);\n}\n```\n\n## 编写方法表(method table)\n* `METH_VARARGS`: Python-level parameters to be passed in as a tuple acceptable for parsing via **PyArg_ParseTuple()**\n* `METH_VARARGS`: 应该传入Python对象，然后使用`PyArg_ParseTuple()`转化为C语言使用数据\n\n```\nstatic PyMethodDef SpamMethods[]={\n    {\"system\",spam_system,METH_VARARGS,\"Execute a shell command.\"},\n    {NULL,NULL,0,NULL}\n};\n```\n\n## 定义就模块结构体\n\n```\nstatic struct PyModuleDef spammodule = {\n    PyModuleDef_HEAD_INIT,\n    \"spam\", /* name of module */\n    NULL,\n    -1,\n    SpamMethods\n};\n```\n\n## 初始化模块\n如果有自己定义的异常应该同样初始化\n\n\n```\nPyMODINIT_FUNC\nPyInit_spam(void)\n{\n    PyObject *m;\n    m = PyModule_Create(&spammodule);\n    if(m==NULL)\n        return NULL;\n    SpamError = PyErr_NewException(\"spam.error\",NULL,NULL);\n    Py_INCREF(SpamError);\n    PyModule_AddObject(m,\"error\",SpamError);\n    return m;\n}\n```\n\n## 安装模块\n需要安装setuptools\n\n```\nfrom distutils.core import setup,Extension\n\nmoduleone=Extension(\'spam\',sources=[\'spammodule.c\'])\n\nsetup(name=\'spam\',\n    version=\'1.0\',\n    description=\'This is spam\',\n    ext_modules=[moduleone]\n)\n```\n\n## 完整代码\n### spammodule.c\n\n```\n#include \"Python.h\"\n\nstatic PyObject *SpamError;\n\nstatic PyObject *\nspam_system(PyObject *self,PyObject *args)\n{\n    const char *command;\n    int sts;\n    if(!PyArg_ParseTuple(args,\"s\",&command))\n        return NULL;\n    sts=system(command);\n    if(sts<0)\n    {\n        PyErr_SetString(SpamError,\"System command failed\");   \n        return NULL;\n    }\n    return PyLong_FromLong(sts);\n}\n\n\nstatic PyMethodDef SpamMethods[]={\n    {\"system\",spam_system,METH_VARARGS,\"Execute a shell command.\"},\n    {NULL,NULL,0,NULL}\n};\n\nstatic struct PyModuleDef spammodule = {\n    PyModuleDef_HEAD_INIT,\n    \"spam\",\n    NULL,\n    -1,\n    SpamMethods\n};\n\nPyMODINIT_FUNC\nPyInit_spam(void)\n{\n    PyObject *m;\n    m = PyModule_Create(&spammodule);\n    if(m==NULL)\n        return NULL;\n    SpamError = PyErr_NewException(\"spam.error\",NULL,NULL);\n    Py_INCREF(SpamError);\n    PyModule_AddObject(m,\"error\",SpamError);\n    return m;\n}\n```\n### setup.py\n\n```\nfrom distutils.core import setup,Extension\n\nmoduleone=Extension(\'spam\',sources=[\'spammodule.c\'])\n\nsetup(name=\'spam\',\n    version=\'1.0\',\n    description=\'This is spam\',\n    ext_modules=[moduleone]\n)\n```\n\n\n','2016-11-10 01:23:36',0),(264,'采用C开发基于事件循环的高性能Server','minihttpd',120,'## Summary:\n快速提供web服务(pure c)，采用epoll。https://github.com/jmpews/minihttpd\n\n### 主要特点\n1. 每一个socket分配一个节点，保存socket的请求相关信息\n2. 处理发送缓冲区问题，当发送缓冲区满，记录当前发送长度。\n3. 处理了epoll的ET模式并发处理。\n4. 实现了一个简单的路由功能\n\n\n### 几个遇到的Trick的地方:\n#### 1.正确关闭socket\n不要使用`close()`，服务端会产生大量`TIME_WAIT`，客户端接受不到发送缓冲区数据。\n\nclose是直接关闭读和写，摧毁socket，不能再使用该socket，服务端收不到ack等数据。\n\n采用`shutdown(client_fd,FD_WR)`，先将缓冲区数据发送完毕，接受ACK，发送FIN，告诉客户端，不再写入数据，等待客户端关闭连接，服务端读取到0字节数据，进而关闭socket连接。\n\n#### 2.处理epoll的ET模式\n\nET模式，在于减少事件的频繁响应，只有当socket的状态change的时候，才会发出响应，所以`listen_fd`接受到accept请求，并不知道具体有几个并发socket请求，所以需要while(accept())直到EAGAIN的errno(读取也是类似).\n\nPS：一个很类似并发的情况就是在一个html文件下面，引入多个本地js，这些js在加载的时候是并发去请求的。\n\n###  几个代码实现细节:\n#### 1. 通用类型链表实现\n路由匹配等可以使用\n\n```\ntypedef struct node\n{\n    ElemType *data;\n    struct node * next;\n}ListNode;\n\n\ntypedef int (*FindElemFunc)(ElemType *,ElemType *key);\n\nint list_append(ListNode *,ElemType *);  //追加元素节点\nElemType *list_get_by_func(ListNode *,FindElemFunc,ElemType *);  //查找元素\nListNode *new_list_node();    //新建元素节点\n\n/* 新节点加在head之后 */\nint list_append(ListNode *head,ElemType *elem)\n{\n    ListNode *node;\n    node=new_list_node();\n    node->data=elem;\n    node->next=head->next;\n    head->next=node;\n    return 0;\n}\n\n/* 通过自定义函数查找节点 */\nElemType *list_get_by_func(ListNode *head,FindElemFunc func,void *key)\n{\n    ListNode *tmp=head->next;\n    if(tmp==NULL)\n        return NULL;\n    do{\n        if(func(tmp->data,key))\n        {\n            return tmp->data;\n        }\n    }while(tmp=tmp->next);\n    return NULL;\n}\n\n/* 新建链表节点 */\nListNode *new_list_node(){\n    ListNode *tmp;\n    tmp=(ListNode *)malloc(sizeof(ListNode));\n    tmp->data=NULL;\n    tmp->next=NULL;\n    return tmp;\n}\n```\n\n\n#### 2. socket节点的实现\n\n建立一个链表，对于到来的请求，分配一个结构体。\n\n```\n\n/* 请求结构体 */\ntypedef struct {\n    char *read_cache;       //缓存读取内容\n    int read_cache_len;     //缓存的内容长度\n    char *header_dump;      //缓存请求头\n    int header_dump_len;    //请求头的长度\n    char method;            //请求方法\n    char *request_path;     //请求路径\n    long body_len;          //请求的body长度\n}Req;\n\n/* 响应结构体 */\ntypedef struct {\n    long response_cache_len;    //响应内容长度\n    char *response_path;        //响应文件路径\n}Resp;\n\n/* socket连接节点 */\ntypedef struct sn{\n    int client_fd;          //socket连接描述符\n    char IO_STATUS;         //socket状态\n    Req request;            //socket对应的请求\n    Resp response;          //socket对应的响应\n    struct sn *next;\n}SocketNode;\n\n/* new socket节点 */\nSocketNode *new_socket_node() {\n    SocketNode *tmp = (SocketNode *) malloc(sizeof(SocketNode));\n    memset(tmp, 0, sizeof(SocketNode));\n    tmp->request.read_cache=NULL;\n    tmp->request.header_dump=NULL;\n    return tmp;\n}\n\n/* 查找socket描述符节点 */\nSocketNode *find_socket_node(SocketNode *head,INT_32 client_fd) {\n    SocketNode *tmp = head;\n    if (head == NULL) {\n        PRINT_ERROR(\"Socket-Head-Node is None\");\n        exit(1);\n    }\n    do{\n        if (tmp->client_fd == client_fd)\n            return tmp;\n    }while(tmp=tmp->next);\n    return NULL;\n\n}\n\n/* 添加节点到Header-Node与其他Node之间 */\nvoid add_socket_node(SocketNode *head,SocketNode *client) {\n    client->next = head->next;\n    head->next = client;\n}\n\n/* 根据socket描述符释放节点 */\nvoid free_socket_node(SocketNode *head,INT_32 client_fd) {\n    SocketNode *tmp = head;\n    SocketNode *k=NULL;\n    //空链表\n    if (tmp->next == NULL) {\n        printf(\"! free_socket_node ERROR\\n\");\n        exit(1);\n    }\n    if (head->client_fd==client_fd) {\n        head=head->next;\n        free_buf(k->request.read_cache);\n        free_buf(k->request.header_dump);\n        free_buf(k->request.request_path);\n        free_buf(k->response.response_path);\n        free_buf(k);\n        close(client_fd);\n        return;\n    }\n    while((tmp->next)!=NULL){\n        if (tmp->next->client_fd == client_fd)\n            break;\n        tmp=tmp->next;\n    }\n\n    k = tmp->next;\n    //没找到node\n    if (k == NULL) {\n        PRINT_ERROR(\"socket-node not found for client_fd\");\n        close(client_fd);\n        exit(1);\n    }\n\n    tmp->next = k->next;\n    printf(\"FREE:ID-%d,PATH-%s\\n\",client_fd,k->request.request_path);\n    free_buf(k->request.read_cache);\n    free_buf(k->request.header_dump);\n    free_buf(k->request.request_path);\n    free_buf(k->response.response_path);\n    free_buf(k);\n\n    close(client_fd);\n    TIP printf(\"> SOCKET[%d] ready close.\\n\", client_fd);\n}\n```\n\n#### 3.`read_line` 读一行实现\n函数设计尽量模块独立，最好不要在`read_line`中引用其他结构体、函数等。\n\n```\nINT_32 read_line(INT_32 sock, char *buf,int BUF_SIZE,int *len) {\n    char c=\'\\0\' ;\n    INT_32 r=0,t=0;\n    *len=0;\n    //buf[BUF_SIZE-1] must be \'\\0\'\n    while ((t < BUF_SIZE - 1) && (c != \'\\n\')) {\n        r = recv(sock, &c, 1, 0);\n        if (r > 0) {\n            // 判断下一个符号是否是\\r，如果是则表明为\\r\\n结束符\n            if (c == \'\\r\') {\n                // MSG_PEEK:从缓冲区copy数据，并不删除数据，如果符合再次读取数据\n                r = recv(sock, &c, 1, MSG_PEEK);\n                if (r > 0 && c == \'\\n\')\n                    recv(sock, &c, 1, 0);\n                else\n                    c = \'\\n\';\n            }\n            buf[t] = c;\n            t++;\n        }\n        else\n            break;\n    }\n\n    buf[t++]=\'\\0\';\n    *len=t;\n\n    if (r < 0) {\n        // 缓冲区为空,读取失败\n        if (errno == EAGAIN) {\n            return IO_EAGAIN;\n        }\n        else {\n            PRINT_ERROR(\"get_line\");\n            return IO_ERROR;\n        }\n    }\n    else if(r>0)\n            return IO_LINE_DONE;\n    return IO_ERROR;\n}\n```\n#### 4. `read_line_more` 读取一行无论多少数据\n返回malloc的返回的地址，注意释放\n\n```\n//读取一行无论数据有多长\nint read_line_more(int client_fd, char **malloc_buffer, int *len) {\n    int r;\n    int n = 0;\n    int t;\n    char *malloc_buf=NULL;\n    int BUF_SIZE=1024;\n    char buf[BUF_SIZE];\n\n    memset(buf, 0, BUF_SIZE);\n    *len=0;\n\n    r = read_line(client_fd, buf, BUF_SIZE, &t);\n\n    /*\n     * 读取流程:\n     * 读取一行(buf_size=1024)\n     * 拷贝到buf\n     * >进行状态判断\n     * 1. 最后字符!=\'\\n\',且读取状态为IO_LINE_DONE\n     *      重新读取\n     * 2. 读取错误IO_EAGAIN || IO_ERROR\n     *      返回buf+状态码\n     * 3. 最后字符为\'\\n\'\n     *      读取完毕，返回返回buf+状态码\n     */\n   while(1){\n        if(!malloc_buf)\n            malloc_buf = (char *) malloc(sizeof(char) * t);\n        else\n            malloc_buf = (char *) realloc(malloc_buf, (n + t) * sizeof(char));\n        memcpy(malloc_buf + n, buf, t);\n        n += t;\n        if(buf[t-1-1]!=\'\\n\' && r == IO_LINE_DONE ) {\n           r=read_line(client_fd, buf, BUF_SIZE, &t);\n        }\n        else if(buf[t-1-1]==\'\\n\' && r == IO_LINE_DONE)\n        {\n            *len=n;\n            *malloc_buffer=malloc_buf;\n            return r;\n        }\n        else if(r == IO_ERROR || r== IO_EAGAIN)\n        {\n            *len=n;\n            *malloc_buffer=malloc_buf;\n            return r;\n        }\n\n   }\n}\n```\n#### 5. 请求处理流程\n每次设置不同的状态码，根据不同的状态码，进入不同函数处理。\n\n发现设计模式真的重要，之前一直在纠结整个处理流程应该怎么处理，然后琢磨出应该用状态码来表明步骤。过了一段时间，再一想，这特么不就是状态机么？！\n\n在处理流程的过程中,case并没有接continue;(PS:如果while+switch+continue会不会更好)\n\n```\nint handle_request(int client_fd){\n    int r;\n    SocketNode *client_sock;\n    client_sock=find_socket_node(SocketHead,client_fd);\n    switch (client_sock->IO_STATUS) {\n        case R_HEADER_INIT:\n            printf(\"\\0\");\n        case R_HEADER_START:\n        {\n            r=request_header_start(client_fd);\n            if (r==IO_EAGAIN) {\n                if (client_sock->request.method==M_ERROR)\n                    return IO_ERROR;\n                return IO_EAGAIN;\n            }\n            else if(r==IO_ERROR)\n                return IO_ERROR;\n        }\n        case R_HEADER_BODY:\n        {\n            r=request_header_body(client_fd);\n            if (r==IO_EAGAIN) {\n                if (client_sock->request.method==M_ERROR)\n                    return IO_ERROR;\n                return IO_EAGAIN;\n            }\n            else if(r==IO_ERROR)\n                return IO_ERROR;\n        }\n        case R_BODY:\n        {\n            r=request_body(client_fd);\n            if (r==IO_EAGAIN||(client_sock->request.method==M_ERROR)) {\n                return IO_EAGAIN;\n            }\n            else if(r==IO_ERROR)\n                return IO_ERROR;\n        }\n        default:\n            break;\n    }\n    return IO_DONE;\n}\n```\n### 5. 路由实现\n\n```\ntypedef struct urlroute{\n    char route[64];\n    char *(*func)(SocketNode *);\n} URL_ROUTE;\nListNode *head_route;\n\n// 返回一个函数指针,该函数返回接受SocketNode * 参数,返回char *\ntypedef char *(*RouteFunc)(SocketNode *);\n\n// 路由处理函数\nchar *route_func1(SocketNode *tmp){\n    char *str;\n    char *s=\"route.1:hello world\\n\\0\";\n    str=(char *)malloc(1024*sizeof(char));\n    strcpy(str,s);\n    str[strlen(s)]=\'\\0\';\n    return str;\n}\n\nchar *route_func2(SocketNode *tmp){\n    char *str;\n    char *s=\"route.2:hello world\\n\\0\";\n    str=(char *)malloc(1024*sizeof(char));\n    strcpy(str,s);\n    str[strlen(s)]=\'\\0\';\n    return str;\n}\nchar *route_func3(SocketNode *tmp){\n    return tmp->request.header_dump;\n}\n\n//配合任意类型的链表，返回ElemType *，然后对返回，进行强制类型转换。\nint find_route(ElemType *data,void *key){\n    if(!strcasecmp((char *)key, ((URL_ROUTE *)data)->route)){\n        printf(\"匹配到route:%s\",(char *)key);\n        return 1;\n    }\n    return 0;\n}\n\n//new\nURL_ROUTE *new_route_node(char *route_str,RouteFunc func){\n    URL_ROUTE *tmp=(URL_ROUTE *)malloc(sizeof(URL_ROUTE));\n    strcpy(tmp->route,route_str);\n    tmp->func=func;\n    return tmp;\n}\n\n//注册路由\nvoid init_route(){\n    head_route=NewElemNode();\n    ListAppend(head_route, new_route_node(\"/route1\", route_func1));\n    ListAppend(head_route, new_route_node(\"/route2\", route_func2));\n    ListAppend(head_route, new_route_node(\"/echo\", route_func3));\n}\n\n//对于传入的route_key(请求路径)匹配路由表，调用处理函数，返回`char *`\nchar *handle_route(SocketNode *client_sock,char *route_key){\n    char *resp;\n    ElemType *data;\n    data=GetElem(head_route, find_route, route_key);\n    if(data)\n    {\n        resp=((URL_ROUTE *)data)->func(client_sock);\n        return resp;\n    }\n    else{\n        return NULL;\n    }\n}\n\n```\n### 6. 处理响应文件(发送缓冲区EAGAIN处理)\n返回已发送的长度\n\n```\nINT_32 send_file(INT_32 client_fd,char *file_path,long *len) {\n    int buffer_size=1024;\n    FILE *fd;\n    long file_length = 0;\n    char buf[buffer_size];\n    int t=0,r = 0;\n\n    fd = fopen(file_path, \"r\");\n    if (fd == NULL) {\n        perror(\"! send_file/fopen error\\n\");\n        exit(1);\n    }\n\n    //内容长度，暂时不用，协议自动计算\n    fseek(fd, 0, SEEK_END);\n    file_length = ftell(fd);\n    rewind(fd);\n\n    //设置文件当前指针,为上次没有读完的\n    if (*len)\n        fseek(fd, *len, SEEK_SET);\n    else\n        send_headers(client_fd);\n    while (1) {\n        memset(buf, 0, buffer_size);\n        t = fread(buf, sizeof(char), buffer_size, fd);\n        r = send(client_fd, buf, t, 0);\n        if (r < 0) {\n            if (errno == EAGAIN) {\n                fclose(fd);\n                return IO_EAGAIN;\n            }\n            else {\n                printf(\"! Send Error:\");\n                fclose(fd);\n                return IO_ERROR;\n            }\n        }\n        *len+=r;\n        if ((*len+2)>=file_length||t<=(buffer_size-2)){\n            fclose(fd);\n            return IO_DONE;\n        }\n\n    }\n}\n\n```\n\nEpoll的参考资料:\n\n1. http://vizee.org/blog/epoll-et-note/\n2. http://www.ccvita.com/515.html\n3. http://blog.lucode.net/linux/epoll-tutorial.html\n\ntypedef  void ElemType;\n','2016-11-10 01:23:36',0),(265,'用图解释异步、非阻塞实质','understand-noblock-async',120,'## Summary\n1.服务端对于请求的处理，必须要形成『环』\n2.非阻塞是为避免I/O等待，同时开启多个『环』，提高并发量\n3.异步是为了避免『环』被超时阻塞\n\n## Example\n### IO等待事件：\n例如：发出connect请求，到收到响应之间的这段等待时间，不仅取决于服务器网络，同时也也取决于客户端网络\n\n### 异步sleep\n在tornado中实现了异步的sleep：设置好超时，加入IOLoop循环中，yield切换协程，然后IOLoop不断循环检测是否超时，当检测到超时，触发yield，回到当时上下文。\n\n### 异步SQL\n执行SQL不等结果出来，直接加进IOLoop，等待回调触发\n\n![](assets/understand-noblock-async-3b5f7.png)\n','2016-11-10 01:23:36',0);
/*!40000 ALTER TABLE `blogpost` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `blogpostcategory`
--

DROP TABLE IF EXISTS `blogpostcategory`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `blogpostcategory` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `name` varchar(255) NOT NULL,
  `str` varchar(255) NOT NULL,
  PRIMARY KEY (`id`),
  UNIQUE KEY `blogpostcategory_str` (`str`)
) ENGINE=InnoDB AUTO_INCREMENT=121 DEFAULT CHARSET=utf8;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `blogpostcategory`
--

LOCK TABLES `blogpostcategory` WRITE;
/*!40000 ALTER TABLE `blogpostcategory` DISABLE KEYS */;
INSERT INTO `blogpostcategory` VALUES (97,'django','django'),(98,'docker','docker'),(99,'pwn','pwn'),(100,'gdb','gdb'),(101,'go','go'),(102,'tornado','tornado'),(103,'greenlet','greenlet'),(104,'linux','linux'),(105,'nginx','nginx'),(106,'php','php'),(107,'python','python'),(108,'react','react'),(109,'redis','redis'),(110,'SICP','SICP'),(111,'socketpool','socketpool'),(112,'linux/shell','linux/shell'),(113,'未分类','未分类'),(114,'协议栈','协议栈'),(115,'zmap','zmap'),(116,'前端','前端'),(117,'数据库','数据库'),(118,'服务器','服务器'),(119,'深入理解计算机操作系统','深入理解计算机操作系统'),(120,'模式框架','模式框架');
/*!40000 ALTER TABLE `blogpostcategory` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `blogpostlabel`
--

DROP TABLE IF EXISTS `blogpostlabel`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `blogpostlabel` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `name` varchar(255) NOT NULL,
  `post_id` int(11) NOT NULL,
  `is_del` tinyint(1) NOT NULL,
  PRIMARY KEY (`id`),
  KEY `blogpostlabel_post_id` (`post_id`),
  CONSTRAINT `blogpostlabel_ibfk_1` FOREIGN KEY (`post_id`) REFERENCES `blogpost` (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=406 DEFAULT CHARSET=utf8;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `blogpostlabel`
--

LOCK TABLES `blogpostlabel` WRITE;
/*!40000 ALTER TABLE `blogpostlabel` DISABLE KEYS */;
INSERT INTO `blogpostlabel` VALUES (325,'python',213,0),(326,' django',213,0),(327,'python',214,0),(328,'restful',214,0),(329,'django',214,0),(330,'django',215,0),(331,' python',215,0),(332,'docker',216,0),(333,'gdb',217,0),(334,' stack',217,0),(335,'gdb',218,0),(336,'go',219,0),(337,'tornado',220,0),(338,'协程',221,0),(339,'coroutine',221,0),(340,'greenlet',221,0),(341,'vpn',222,0),(342,'juniper',223,0),(343,'vpn',223,0),(344,'linux',224,0),(345,'nginx',225,0),(346,'vpn',226,0),(347,'php',227,0),(348,'python',228,0),(349,' 元类',228,0),(350,'python',229,0),(351,'mock',229,0),(352,'引用计数',230,0),(353,'python',231,0),(354,'redis',231,0),(355,'爬虫',231,0),(356,'python',232,0),(357,'js',233,0),(358,'react',233,0),(359,'python',234,0),(360,'redis',234,0),(361,'代理扫描',235,0),(362,'递归',236,0),(363,'迭代',236,0),(364,'socketpool',237,0),(365,'连接池',237,0),(366,'ssh',238,0),(367,'proxy',239,0),(368,'syn',240,0),(369,'TCP/IP',241,0),(370,'tornado',242,0),(371,'tornado',243,0),(372,'tornado',244,0),(373,'异步',244,0),(374,' yield',244,0),(375,'tornado',245,0),(376,'Tornado',246,0),(377,' Websocket',246,0),(378,'tornado',247,0),(379,'tornado',248,0),(380,'zmap',249,0),(381,'python',250,0),(382,'js',251,0),(383,'docker',252,0),(384,'笔记',253,0),(385,'develop',254,0),(386,'python',255,0),(387,'协程',255,0),(388,'异步',255,0),(389,'coroutine',255,0),(390,'asynchronous',255,0),(391,'docker',256,0),(392,' registry',256,0),(393,' distribution',256,0),(394,'docker harbor',257,0),(395,'mysql',258,0),(396,'linux',259,0),(397,'python',260,0),(398,'stackoverflow',261,0),(399,' pwn',261,0),(400,'c',262,0),(401,'python',263,0),(402,'epoll',264,0),(403,'select',264,0),(404,'异步',265,0),(405,'非阻塞',265,0);
/*!40000 ALTER TABLE `blogpostlabel` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `chatmessage`
--

DROP TABLE IF EXISTS `chatmessage`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `chatmessage` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `sender_id` int(11) NOT NULL,
  `receiver_id` int(11) NOT NULL,
  `content` longtext NOT NULL,
  `is_read` tinyint(1) NOT NULL,
  `time` datetime NOT NULL,
  PRIMARY KEY (`id`),
  KEY `chatmessage_sender_id` (`sender_id`),
  KEY `chatmessage_receiver_id` (`receiver_id`),
  CONSTRAINT `chatmessage_ibfk_1` FOREIGN KEY (`sender_id`) REFERENCES `user` (`id`),
  CONSTRAINT `chatmessage_ibfk_2` FOREIGN KEY (`receiver_id`) REFERENCES `user` (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=3 DEFAULT CHARSET=utf8;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `chatmessage`
--

LOCK TABLES `chatmessage` WRITE;
/*!40000 ALTER TABLE `chatmessage` DISABLE KEYS */;
INSERT INTO `chatmessage` VALUES (1,1,2,'self>other',0,'2016-10-26 13:39:18'),(2,2,1,'other>self',0,'2016-10-26 13:39:18');
/*!40000 ALTER TABLE `chatmessage` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `collectpost`
--

DROP TABLE IF EXISTS `collectpost`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `collectpost` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `post_id` int(11) NOT NULL,
  `user_id` int(11) NOT NULL,
  `collect_time` datetime NOT NULL,
  PRIMARY KEY (`id`),
  KEY `collectpost_post_id` (`post_id`),
  KEY `collectpost_user_id` (`user_id`),
  CONSTRAINT `collectpost_ibfk_1` FOREIGN KEY (`post_id`) REFERENCES `post` (`id`),
  CONSTRAINT `collectpost_ibfk_2` FOREIGN KEY (`user_id`) REFERENCES `user` (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `collectpost`
--

LOCK TABLES `collectpost` WRITE;
/*!40000 ALTER TABLE `collectpost` DISABLE KEYS */;
/*!40000 ALTER TABLE `collectpost` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `follower`
--

DROP TABLE IF EXISTS `follower`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `follower` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `user_id` int(11) NOT NULL,
  `follower_id` int(11) NOT NULL,
  `follow_time` datetime NOT NULL,
  PRIMARY KEY (`id`),
  KEY `follower_user_id` (`user_id`),
  KEY `follower_follower_id` (`follower_id`),
  CONSTRAINT `follower_ibfk_1` FOREIGN KEY (`user_id`) REFERENCES `user` (`id`),
  CONSTRAINT `follower_ibfk_2` FOREIGN KEY (`follower_id`) REFERENCES `user` (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `follower`
--

LOCK TABLES `follower` WRITE;
/*!40000 ALTER TABLE `follower` DISABLE KEYS */;
INSERT INTO `follower` VALUES (1,1,2,'2016-10-26 13:39:18');
/*!40000 ALTER TABLE `follower` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `imagerepository`
--

DROP TABLE IF EXISTS `imagerepository`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `imagerepository` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `user_id` int(11) DEFAULT NULL,
  `action` varchar(16) DEFAULT NULL,
  `name` varchar(72) NOT NULL,
  `description` longtext NOT NULL,
  `post_count` int(11) NOT NULL,
  `collect_count` int(11) NOT NULL,
  `create_time` datetime NOT NULL,
  `latest_time` datetime DEFAULT NULL,
  `latest_digest` varchar(88) DEFAULT NULL,
  `latest_tag` varchar(72) DEFAULT NULL,
  `is_delete` tinyint(1) NOT NULL,
  PRIMARY KEY (`id`),
  KEY `imagerepository_user_id` (`user_id`),
  CONSTRAINT `imagerepository_ibfk_1` FOREIGN KEY (`user_id`) REFERENCES `user` (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=27 DEFAULT CHARSET=utf8;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `imagerepository`
--

LOCK TABLES `imagerepository` WRITE;
/*!40000 ALTER TABLE `imagerepository` DISABLE KEYS */;
INSERT INTO `imagerepository` VALUES (25,1,NULL,'admin/registry','none',0,0,'2016-11-09 19:58:24','2016-11-09 19:58:24','sha256:8cc735b5dab8cf042d0705b4b44ee351bcbd94a760bbf0781e5334182538a6d6','2.5x',0),(26,3,NULL,'chujm/registry','none',0,0,'2016-11-09 19:58:24','2016-11-09 19:58:24','sha256:8cc735b5dab8cf042d0705b4b44ee351bcbd94a760bbf0781e5334182538a6d6','2.5x',0);
/*!40000 ALTER TABLE `imagerepository` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `imagetag`
--

DROP TABLE IF EXISTS `imagetag`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `imagetag` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `repository_id` int(11) NOT NULL,
  `name` varchar(72) NOT NULL,
  `digest` varchar(88) NOT NULL,
  `is_delete` tinyint(1) NOT NULL,
  `create_time` datetime NOT NULL,
  PRIMARY KEY (`id`),
  KEY `imagetag_repository_id` (`repository_id`),
  CONSTRAINT `imagetag_ibfk_1` FOREIGN KEY (`repository_id`) REFERENCES `imagerepository` (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=23 DEFAULT CHARSET=utf8;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `imagetag`
--

LOCK TABLES `imagetag` WRITE;
/*!40000 ALTER TABLE `imagetag` DISABLE KEYS */;
INSERT INTO `imagetag` VALUES (21,25,'2.5x','sha256:8cc735b5dab8cf042d0705b4b44ee351bcbd94a760bbf0781e5334182538a6d6',0,'2016-11-09 19:58:24'),(22,26,'2.5x','sha256:8cc735b5dab8cf042d0705b4b44ee351bcbd94a760bbf0781e5334182538a6d6',0,'2016-11-09 19:58:24');
/*!40000 ALTER TABLE `imagetag` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `notification`
--

DROP TABLE IF EXISTS `notification`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `notification` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `user_id` int(11) NOT NULL,
  `opt` int(11) NOT NULL,
  `msg` varchar(71) NOT NULL,
  `extra_user_id` int(11) DEFAULT NULL,
  `extra_post_id` int(11) DEFAULT NULL,
  `extra_post_reply_id` int(11) DEFAULT NULL,
  `create_time` datetime NOT NULL,
  `is_read` tinyint(1) NOT NULL,
  PRIMARY KEY (`id`),
  KEY `notification_user_id` (`user_id`),
  KEY `notification_extra_user_id` (`extra_user_id`),
  KEY `notification_extra_post_id` (`extra_post_id`),
  KEY `notification_extra_post_reply_id` (`extra_post_reply_id`),
  CONSTRAINT `notification_ibfk_1` FOREIGN KEY (`user_id`) REFERENCES `user` (`id`),
  CONSTRAINT `notification_ibfk_2` FOREIGN KEY (`extra_user_id`) REFERENCES `user` (`id`),
  CONSTRAINT `notification_ibfk_3` FOREIGN KEY (`extra_post_id`) REFERENCES `post` (`id`),
  CONSTRAINT `notification_ibfk_4` FOREIGN KEY (`extra_post_reply_id`) REFERENCES `postreply` (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=10 DEFAULT CHARSET=utf8;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `notification`
--

LOCK TABLES `notification` WRITE;
/*!40000 ALTER TABLE `notification` DISABLE KEYS */;
INSERT INTO `notification` VALUES (1,2,1,'发表新文章',1,2,NULL,'2016-10-26 14:49:36',0),(2,2,1,'发表新文章',1,3,NULL,'2016-10-26 14:52:15',0),(3,2,1,'发表新文章',1,3,NULL,'2016-10-26 14:55:40',0),(4,2,1,'发表新文章',1,4,NULL,'2016-10-26 15:00:56',0),(5,2,1,'发表新文章',1,5,NULL,'2016-10-26 15:13:42',0),(6,2,1,'发表新文章',1,6,NULL,'2016-11-08 15:07:26',0),(7,2,1,'发表新文章',1,6,NULL,'2016-11-08 15:15:38',0),(8,2,1,'发表新文章',1,1,NULL,'2016-11-08 15:15:51',0),(9,2,1,'发表新文章',1,1,NULL,'2016-11-09 18:51:43',0);
/*!40000 ALTER TABLE `notification` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `post`
--

DROP TABLE IF EXISTS `post`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `post` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `topic_id` int(11) DEFAULT NULL,
  `image_id` int(11) DEFAULT NULL,
  `title` varchar(255) NOT NULL,
  `content` longtext NOT NULL,
  `user_id` int(11) NOT NULL,
  `create_time` datetime NOT NULL,
  `latest_reply_user_id` int(11) DEFAULT NULL,
  `latest_reply_time` datetime DEFAULT NULL,
  `visit_count` int(11) NOT NULL,
  `reply_count` int(11) NOT NULL,
  `collect_count` int(11) NOT NULL,
  `top` tinyint(1) NOT NULL,
  `essence` tinyint(1) NOT NULL,
  `is_delete` tinyint(1) NOT NULL,
  PRIMARY KEY (`id`),
  KEY `post_topic_id` (`topic_id`),
  KEY `post_image_id` (`image_id`),
  KEY `post_user_id` (`user_id`),
  KEY `post_latest_reply_user_id` (`latest_reply_user_id`),
  CONSTRAINT `post_ibfk_1` FOREIGN KEY (`topic_id`) REFERENCES `posttopic` (`id`),
  CONSTRAINT `post_ibfk_2` FOREIGN KEY (`image_id`) REFERENCES `imagetag` (`id`),
  CONSTRAINT `post_ibfk_3` FOREIGN KEY (`user_id`) REFERENCES `user` (`id`),
  CONSTRAINT `post_ibfk_4` FOREIGN KEY (`latest_reply_user_id`) REFERENCES `user` (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=7 DEFAULT CHARSET=utf8;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `post`
--

LOCK TABLES `post` WRITE;
/*!40000 ALTER TABLE `post` DISABLE KEYS */;
INSERT INTO `post` VALUES (1,4,NULL,'Docker-Reigstry使用指南','# jmp-registry\n\n---\n## 关于Docker-Registry分支\n\ndocker分支是建立在[torweb-master](http://github.com/jmpews/torweb)之上的私有Registry.\n\n主要是与现有的账户系统进行融合. 提供自定义授权的token-auth机制, 以及对Image的列表和检索.\n\n关于Docker-Reigsty的搭建过程详见[docs/docker-registry-install.md](docs/docker-registry-install.md)\n\n---\n## TODO...\n\n1. 将`Post` 和 `Image` 联系起来, 用户可以为其Push的 `Image` 添加一篇 `Post` 来介绍该 `Image`\n\n2. 对 `Image` 删除操作(通过Registry的API(v2)发起del请求, 接受 `Image` 删除完成广播, 删除Image的DB记录)\n\n3. 对于Pull操作的记录\n\n---\n## 如何测试该私有Registry\n### 1. 设置信任该Registry\n\n由于暂时没有做https相关处理. 需要将该Registry设置为信任的Registry.\n\n#### * OSX-Docker客户端\n在 `Perferences... -> Advanced -> Insecure registryies` 添加 `110.110.10.149`\n\n#### * Linux\n> 1. Open the /etc/default/docker file or /etc/sysconfig/docker for editing.Depending on your operating system, your Engine daemon start options.\n> 2. Edit (or add) the DOCKER_OPTS line and add the --insecure-registry flag.This flag takes the URL of your registry, for example. `DOCKER_OPTS=\"--insecure-registry myregistrydomain.com:5000\"`\n> 3. Close and save the configuration file.Restart your Docker daemon\n> The command you use to restart the daemon depends on your operating system. For example, on Ubuntu, this is usually the service docker stop and service docker start command.\n\n这里把 `DOCKER_OPTS=\"--insecure-registry myregistrydomain.com:5000\"` 改为 `DOCKER_OPTS=\"--insecure-registry 110.110.10.149\"` 进行上述操作\n\n### 2. Push 镜像\n\n```\n# 登陆Registry, 使用torweb的用户进行验证\n# 目前提供测试账户admin: admin; test:test\ndocker login 110.110.10.149\n\n# 给需要push的image打tag\ndocker tag image_id 110.110.10.149/jmpews/nginx:1.9\n\n# push打上tag的image\ndocker push 110.110.10.149/jmpews/nginx:1.9\n```\n\n### 3. Pull 镜像\n```\n# 无需授权验证直接pull\n# 镜像列表\n# http://110.110.10.149/registryauth\ndocker pull 110.110.10.149/jmpews/nginx:1.9\n```\n\n---\n## 大致原理以及架构\n\n### 0. token-auth部分\n\n参考连接:\n\n> https://docs.docker.com/registry/spec/auth/token/\n\n在 `registry.yaml` 的配置文件注册token-auth服务器的地址, Registry 将用户的push和pull操作的信息, 发送给token-auth的服务器, 服务器需要返回一个token, 以表明是否有权限进行操作\n\n### 1. 如果更新Images的DB(notification)\n\n参考连接:\n\n> https://docs.docker.com/registry/notifications/\n\n在 `registry.yaml` 的配置文件注册 notification 的 endpoints, Registry 自动会将事件信息广播注册的 endpoints\n\n### 2. 如何检索Image\n\n采用上述 1 的方式, 直接检索DB即可\n\n---\n## torweb介绍\n\n> http://github.com/jmpews/torweb',1,'2016-10-26 13:39:18',NULL,NULL,11,0,0,0,0,0),(2,4,NULL,'Redis基础镜像','# Redis\n\nRedis是一个开源，基于内存的高性能key-Value数据库，它支持存储的value类型很丰富，包括string(字符串)、list(链表)、set(集合)、zset(sortedset--有序集合)和hash（哈希类型）。\n\n# 说明\n容器启动后，会默认生成一个随机密码，你可以通过查看容器日志获得密码，比如\n\n```\n========================================================================\nYou can now connect to this Redis server using:\n\n    redis-cli -a iuiouljwi9tjw5638u65lkj6356 -h <host> -p <port>\n\nPlease remember to change the above password as soon as possible!\n========================================================================\n```\n\n在上面的例子中，iuiouljwi9tjw5638u65lkj6356 就是随机密码。\n\n如果你想设置一个特定的密码，你可以设置环境变量 REDIS_PASS 为您需要的密码。\n\n如果你想启动Redis并忽略密码登录，你可以设置环境变量 REDIS_PASS 为 **None**。\n\n# 配置Redis\n\n如果你想设置Redis的配置，你可以把配置加REDIS_前缀作为一个环境变量传入容器中，例如您想设置tcp-keepalive为60，可以设置环境变量`REDIS_TCP_KEEPALIVE=60`',1,'2016-10-26 14:49:36',NULL,NULL,5,0,0,0,0,0),(3,4,NULL,'Nginx 基础镜像','# Nginx\n\n> 此镜像从 [Docker Hub](https://registry.hub.docker.com/_/nginx/) 同步并由 DaoCloud 提供中文文档支持，用来帮助国内开发者更方便的使用 Docker 镜像。\n> \n> 该镜像源维护在 [Github](https://github.com/docker-library/official-images/blob/master/library/nginx)。\n\n## 什么是 Nginx？\n\nNginx 是一款轻量级的 Web 服务器、反向代理服务器、及电子邮件（IMAP/POP3）代理服务器，并在一个 BSD-like 协议下发行。由俄罗斯的程序设计师 Igor Sysoev 所开发，供俄国大型的入口网站及搜索引擎 Rambler（俄文：Рамблер）使用。其特点是占有内存少，并发能力强，事实上 Nginx 的并发能力确实在同类型的网页服务器中表现较好，中国大陆使用 Nginx 网站用户有：新浪、网易、腾讯等。\n\n> 来自[百度百科](http://baike.baidu.com/view/926025.htm)\n\n## 如何使用这个镜像？\n\n> 因所有镜像均位于境外服务器，为了确保所有示例能正常运行，DaoCloud 提供了一套境内镜像源，并与官方源保持同步。\n\n### 托管静态网页内容\n\ndocker run --name some-nginx -v /some/content:/usr/share/nginx/html:ro -d daocloud.io/nginx\n\n另外一种比上面绑定 volume 更推荐的做法是用`Dockerfile`生成包含网页内容的新镜像，如下所示：\n\n`FROM daocloud.io/nginx COPY static-html-directory /usr/share/nginx/html`\n\n把上面的`Dockerfile`和您的网页内容（static-html-directory）放在同一目录下，然后运行命令生成新镜像：\n\n`docker build -t some-content-nginx .`\n\n最后启动容器：\n\n`docker run --name some-nginx -d some-content-nginx`\n    \n### 暴露端口\n\n`docker run --name some-nginx -d -p 8080:80 some-content-nginx`\n\n这样启动，您就可以通过 `http://localhost:8080` 或者 `http://宿主 IP:8080` 访问 Nginx 了。\n\n### 进阶配置\n\n`docker run --name some-nginx -v /some/nginx.conf:/etc/nginx/nginx.conf:ro -d daocloud.io/nginx`\n\n> 了解详细的 Nginx 配置文件语法，请参考：[官方文档](http://nginx.org/en/docs/)。\n\n为了确保 Nginx 容器能够持续运行，请务必在您自定义的 Nginx 配置文件中包含`deamon off`配置项。 \n\n下面的命令从一个正在运行的 Nginx 容器中复制出配置文件：\n\n`docker cp some-nginx:/etc/nginx/nginx.conf /some/nginx.conf`\n\n\n您也可以通过推荐的`Dockerfile`方式来生成一个包含自定义配置文件的镜像，如下所示：\n\n`FROM daocloud.io/nginx COPY nginx.conf /etc/nginx/nginx.conf`\n\n再用下面的命令构建镜像：\n\n`docker build -t some-custom-nginx`\n\n\n最后启动容器：\n\n`docker run --name some-nginx -d some-custom-nginx`\n\n## 支持的Docker版本\n\n这个镜像在 Docker 1.7.0 上提供最佳的官方支持，对于其他老版本的 Docker（1.0 之后）也能提供基本的兼容。\n\n## 该翻译的许可证\n\n本作品采用[署名-非商业性使用-禁止演绎](http://creativecommons.org/licenses/by-nc-nd/4.0/)进行许可。',1,'2016-10-26 14:52:15',NULL,NULL,7,0,0,0,0,0),(4,4,NULL,'Mongo 基础镜像','# MongoDB\n\nMongoDB 是一个高性能、开源、无 Schema 的 NoSQL 数据库管理系统，常被用于高流量网站，在线游戏网站和搜索引擎的大规模数据管理和分类。它支持的数据结构非常松散，是类似 json 的 bson 格式，因此可以存储比较复杂的数据类型。\n\n本镜像源自于 Docker Hub 镜像 **[tutum/mongodb](https://registry.hub.docker.com/u/tutum/mongodb/)**。\n\n## 版本\n\n当前版本 MongoDB 3.0\n\n## 说明\n\n该容器会给您部署一个 MongoDB。您可以使用如下命令登陆\n\n`user$ mongo --host 映射的地址 --port 映射的端口号`\n\n如果你想启动 MongoDB 并需要密码登录，你可以设置环境变量 `AUTH` 为 `yes`（默认为 `no`）。\n\n容器启动后会自动创建一个具有所有权限的 `admin` 用户，并自动生成随机密码。如果你想为 `admin` 用户设置一个特定的密码，你可以将环境变量 `MONGODB_PASS` 设置为您需要的密码。\n\n你也可以通过查看容器日志获得密码，比如\n\n```\n========================================================================\nPlease remember to change the above password as soon as possible!\n\nmongo admin -u admin -p 67u6kjiy6ll --host host --port port\n\n========================================================================\n```\n在上面的例子中，`67u6kjiy6ll` 就是 `admin` 用户的密码。',1,'2016-10-26 15:00:56',NULL,NULL,2,0,0,0,0,0),(5,1,NULL,'test','<p>Please Write Here.</p>\n<p>&nbsp;</p>\n<p><code>import requests</code></p>\n<p><code>resp = requests.get(\'http://baidu.com\')</code></p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>',1,'2016-10-26 15:13:42',NULL,NULL,3,0,0,0,0,0),(6,2,NULL,'asdf','直接粘贴markdown即可',1,'2016-11-08 15:07:26',NULL,NULL,13,0,0,0,0,1);
/*!40000 ALTER TABLE `post` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `post_bak`
--

DROP TABLE IF EXISTS `post_bak`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `post_bak` (
  `id` int(11) NOT NULL DEFAULT '0',
  `topic_id` int(11) NOT NULL,
  `image_id` int(11) DEFAULT NULL,
  `title` varchar(255) NOT NULL,
  `content` longtext NOT NULL,
  `user_id` int(11) NOT NULL,
  `create_time` datetime NOT NULL,
  `latest_reply_user_id` int(11) DEFAULT NULL,
  `latest_reply_time` datetime DEFAULT NULL,
  `visit_count` int(11) NOT NULL,
  `reply_count` int(11) NOT NULL,
  `collect_count` int(11) NOT NULL,
  `top` tinyint(1) NOT NULL,
  `essence` tinyint(1) NOT NULL
) ENGINE=InnoDB DEFAULT CHARSET=utf8;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `post_bak`
--

LOCK TABLES `post_bak` WRITE;
/*!40000 ALTER TABLE `post_bak` DISABLE KEYS */;
INSERT INTO `post_bak` VALUES (1,4,NULL,'Docker-Reigstry使用指南','\n        # jmp-registry\n\n---\n## 关于Docker-Registry分支\n\ndocker分支是建立在[torweb-master](http://github.com/jmpews/torweb)之上的私有Registry.\n\n主要是与现有的账户系统进行融合. 提供自定义授权的token-auth机制, 以及对Image的列表和检索.\n\n关于Docker-Reigsty的搭建过程详见[docs/docker-registry-install.md](docs/docker-registry-install.md)\n\n---\n## TODO...\n\n1. 将`Post` 和 `Image` 联系起来, 用户可以为其Push的 `Image` 添加一篇 `Post` 来介绍该 `Image`\n\n2. 对 `Image` 删除操作(通过Registry的API(v2)发起del请求, 接受 `Image` 删除完成广播, 删除Image的DB记录)\n\n3. 对于Pull操作的记录\n\n---\n## 如何测试该私有Registry\n### 1. 设置信任该Registry\n\n由于暂时没有做https相关处理. 需要将该Registry设置为信任的Registry.\n\n#### * OSX-Docker客户端\n在 `Perferences... -> Advanced -> Insecure registryies` 添加 `110.110.10.149`\n\n#### * Linux\n> 1. Open the /etc/default/docker file or /etc/sysconfig/docker for editing.Depending on your operating system, your Engine daemon start options.\n> 2. Edit (or add) the DOCKER_OPTS line and add the --insecure-registry flag.This flag takes the URL of your registry, for example. `DOCKER_OPTS=\"--insecure-registry myregistrydomain.com:5000\"`\n> 3. Close and save the configuration file.Restart your Docker daemon\n> The command you use to restart the daemon depends on your operating system. For example, on Ubuntu, this is usually the service docker stop and service docker start command.\n\n这里把 `DOCKER_OPTS=\"--insecure-registry myregistrydomain.com:5000\"` 改为 `DOCKER_OPTS=\"--insecure-registry 110.110.10.149\"` 进行上述操作\n\n### 2. Push 镜像\n\n```\n# 登陆Registry, 使用torweb的用户进行验证\n# 目前提供测试账户admin: admin; test:test\ndocker login 110.110.10.149\n\n# 给需要push的image打tag\ndocker tag image_id 110.110.10.149/jmpews/nginx:1.9\n\n# push打上tag的image\ndocker push 110.110.10.149/jmpews/nginx:1.9\n```\n\n### 3. Pull 镜像\n```\n# 无需授权验证直接pull\n# 镜像列表\n# http://110.110.10.149/registryauth\ndocker pull 110.110.10.149/jmpews/nginx:1.9\n```\n\n---\n## 大致原理以及架构\n\n### 0. token-auth部分\n\n参考连接:\n\n> https://docs.docker.com/registry/spec/auth/token/\n\n在 `registry.yaml` 的配置文件注册token-auth服务器的地址, Registry 将用户的push和pull操作的信息, 发送给token-auth的服务器, 服务器需要返回一个token, 以表明是否有权限进行操作\n\n### 1. 如果更新Images的DB(notification)\n\n参考连接:\n\n> https://docs.docker.com/registry/notifications/\n\n在 `registry.yaml` 的配置文件注册 notification 的 endpoints, Registry 自动会将事件信息广播注册的 endpoints\n\n### 2. 如何检索Image\n\n采用上述 1 的方式, 直接检索DB即可\n\n---\n## torweb介绍\n\n> http://github.com/jmpews/torweb\n\n        ',1,'2016-10-26 13:39:18',NULL,NULL,6,0,0,0,0),(2,4,NULL,'Redis基础镜像','# Redis\n\nRedis是一个开源，基于内存的高性能key-Value数据库，它支持存储的value类型很丰富，包括string(字符串)、list(链表)、set(集合)、zset(sortedset--有序集合)和hash（哈希类型）。\n\n# 说明\n容器启动后，会默认生成一个随机密码，你可以通过查看容器日志获得密码，比如\n\n```\n========================================================================\nYou can now connect to this Redis server using:\n\n    redis-cli -a iuiouljwi9tjw5638u65lkj6356 -h <host> -p <port>\n\nPlease remember to change the above password as soon as possible!\n========================================================================\n```\n\n在上面的例子中，iuiouljwi9tjw5638u65lkj6356 就是随机密码。\n\n如果你想设置一个特定的密码，你可以设置环境变量 REDIS_PASS 为您需要的密码。\n\n如果你想启动Redis并忽略密码登录，你可以设置环境变量 REDIS_PASS 为 **None**。\n\n# 配置Redis\n\n如果你想设置Redis的配置，你可以把配置加REDIS_前缀作为一个环境变量传入容器中，例如您想设置tcp-keepalive为60，可以设置环境变量`REDIS_TCP_KEEPALIVE=60`',1,'2016-10-26 14:49:36',NULL,NULL,4,0,0,0,0),(3,4,NULL,'Nginx 基础镜像','# Nginx\n\n> 此镜像从 [Docker Hub](https://registry.hub.docker.com/_/nginx/) 同步并由 DaoCloud 提供中文文档支持，用来帮助国内开发者更方便的使用 Docker 镜像。\n> \n> 该镜像源维护在 [Github](https://github.com/docker-library/official-images/blob/master/library/nginx)。\n\n## 什么是 Nginx？\n\nNginx 是一款轻量级的 Web 服务器、反向代理服务器、及电子邮件（IMAP/POP3）代理服务器，并在一个 BSD-like 协议下发行。由俄罗斯的程序设计师 Igor Sysoev 所开发，供俄国大型的入口网站及搜索引擎 Rambler（俄文：Рамблер）使用。其特点是占有内存少，并发能力强，事实上 Nginx 的并发能力确实在同类型的网页服务器中表现较好，中国大陆使用 Nginx 网站用户有：新浪、网易、腾讯等。\n\n> 来自[百度百科](http://baike.baidu.com/view/926025.htm)\n\n## 如何使用这个镜像？\n\n> 因所有镜像均位于境外服务器，为了确保所有示例能正常运行，DaoCloud 提供了一套境内镜像源，并与官方源保持同步。\n\n### 托管静态网页内容\n\ndocker run --name some-nginx -v /some/content:/usr/share/nginx/html:ro -d daocloud.io/nginx\n\n另外一种比上面绑定 volume 更推荐的做法是用`Dockerfile`生成包含网页内容的新镜像，如下所示：\n\n`FROM daocloud.io/nginx COPY static-html-directory /usr/share/nginx/html`\n\n把上面的`Dockerfile`和您的网页内容（static-html-directory）放在同一目录下，然后运行命令生成新镜像：\n\n`docker build -t some-content-nginx .`\n\n最后启动容器：\n\n`docker run --name some-nginx -d some-content-nginx`\n    \n### 暴露端口\n\n`docker run --name some-nginx -d -p 8080:80 some-content-nginx`\n\n这样启动，您就可以通过 `http://localhost:8080` 或者 `http://宿主 IP:8080` 访问 Nginx 了。\n\n### 进阶配置\n\n`docker run --name some-nginx -v /some/nginx.conf:/etc/nginx/nginx.conf:ro -d daocloud.io/nginx`\n\n> 了解详细的 Nginx 配置文件语法，请参考：[官方文档](http://nginx.org/en/docs/)。\n\n为了确保 Nginx 容器能够持续运行，请务必在您自定义的 Nginx 配置文件中包含`deamon off`配置项。 \n\n下面的命令从一个正在运行的 Nginx 容器中复制出配置文件：\n\n`docker cp some-nginx:/etc/nginx/nginx.conf /some/nginx.conf`\n\n\n您也可以通过推荐的`Dockerfile`方式来生成一个包含自定义配置文件的镜像，如下所示：\n\n`FROM daocloud.io/nginx COPY nginx.conf /etc/nginx/nginx.conf`\n\n再用下面的命令构建镜像：\n\n`docker build -t some-custom-nginx`\n\n\n最后启动容器：\n\n`docker run --name some-nginx -d some-custom-nginx`\n\n## 支持的Docker版本\n\n这个镜像在 Docker 1.7.0 上提供最佳的官方支持，对于其他老版本的 Docker（1.0 之后）也能提供基本的兼容。\n\n## 该翻译的许可证\n\n本作品采用[署名-非商业性使用-禁止演绎](http://creativecommons.org/licenses/by-nc-nd/4.0/)进行许可。',1,'2016-10-26 14:52:15',NULL,NULL,5,0,0,0,0),(4,4,NULL,'Mongo 基础镜像','# MongoDB\n\nMongoDB 是一个高性能、开源、无 Schema 的 NoSQL 数据库管理系统，常被用于高流量网站，在线游戏网站和搜索引擎的大规模数据管理和分类。它支持的数据结构非常松散，是类似 json 的 bson 格式，因此可以存储比较复杂的数据类型。\n\n本镜像源自于 Docker Hub 镜像 **[tutum/mongodb](https://registry.hub.docker.com/u/tutum/mongodb/)**。\n\n## 版本\n\n当前版本 MongoDB 3.0\n\n## 说明\n\n该容器会给您部署一个 MongoDB。您可以使用如下命令登陆\n\n`user$ mongo --host 映射的地址 --port 映射的端口号`\n\n如果你想启动 MongoDB 并需要密码登录，你可以设置环境变量 `AUTH` 为 `yes`（默认为 `no`）。\n\n容器启动后会自动创建一个具有所有权限的 `admin` 用户，并自动生成随机密码。如果你想为 `admin` 用户设置一个特定的密码，你可以将环境变量 `MONGODB_PASS` 设置为您需要的密码。\n\n你也可以通过查看容器日志获得密码，比如\n\n```\n========================================================================\nPlease remember to change the above password as soon as possible!\n\nmongo admin -u admin -p 67u6kjiy6ll --host host --port port\n\n========================================================================\n```\n在上面的例子中，`67u6kjiy6ll` 就是 `admin` 用户的密码。',1,'2016-10-26 15:00:56',NULL,NULL,2,0,0,0,0),(5,1,NULL,'test','<p>Please Write Here.</p>\n<p>&nbsp;</p>\n<p><code>import requests</code></p>\n<p><code>resp = requests.get(\'http://baidu.com\')</code></p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>',1,'2016-10-26 15:13:42',NULL,NULL,3,0,0,0,0);
/*!40000 ALTER TABLE `post_bak` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `postcategory`
--

DROP TABLE IF EXISTS `postcategory`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `postcategory` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `name` varchar(255) NOT NULL,
  `str` varchar(255) NOT NULL,
  PRIMARY KEY (`id`),
  UNIQUE KEY `postcategory_str` (`str`)
) ENGINE=InnoDB AUTO_INCREMENT=3 DEFAULT CHARSET=utf8;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `postcategory`
--

LOCK TABLES `postcategory` WRITE;
/*!40000 ALTER TABLE `postcategory` DISABLE KEYS */;
INSERT INTO `postcategory` VALUES (1,'漏洞环境','vulenv'),(2,'安全工具','tools');
/*!40000 ALTER TABLE `postcategory` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `postreply`
--

DROP TABLE IF EXISTS `postreply`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `postreply` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `post_id` int(11) NOT NULL,
  `user_id` int(11) NOT NULL,
  `content` longtext NOT NULL,
  `create_time` datetime NOT NULL,
  `like_count` int(11) NOT NULL,
  PRIMARY KEY (`id`),
  KEY `postreply_post_id` (`post_id`),
  KEY `postreply_user_id` (`user_id`),
  CONSTRAINT `postreply_ibfk_1` FOREIGN KEY (`post_id`) REFERENCES `post` (`id`),
  CONSTRAINT `postreply_ibfk_2` FOREIGN KEY (`user_id`) REFERENCES `user` (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `postreply`
--

LOCK TABLES `postreply` WRITE;
/*!40000 ALTER TABLE `postreply` DISABLE KEYS */;
/*!40000 ALTER TABLE `postreply` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `posttopic`
--

DROP TABLE IF EXISTS `posttopic`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `posttopic` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `category_id` int(11) DEFAULT NULL,
  `name` varchar(255) NOT NULL,
  `str` varchar(255) NOT NULL,
  `hot` tinyint(1) NOT NULL,
  PRIMARY KEY (`id`),
  UNIQUE KEY `posttopic_str` (`str`),
  KEY `posttopic_category_id` (`category_id`),
  CONSTRAINT `posttopic_ibfk_1` FOREIGN KEY (`category_id`) REFERENCES `postcategory` (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=6 DEFAULT CHARSET=utf8;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `posttopic`
--

LOCK TABLES `posttopic` WRITE;
/*!40000 ALTER TABLE `posttopic` DISABLE KEYS */;
INSERT INTO `posttopic` VALUES (1,1,'web漏洞','web-vulenv',0),(2,1,'php漏洞','php-vulenv',0),(3,2,'kali','kali-tools',0),(4,NULL,'通知','notice',0),(5,NULL,'讨论','discussion',0);
/*!40000 ALTER TABLE `posttopic` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `profile`
--

DROP TABLE IF EXISTS `profile`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `profile` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `user_id` int(11) NOT NULL,
  `nickname` varchar(16) NOT NULL,
  `weibo` varchar(64) NOT NULL,
  `website` varchar(64) NOT NULL,
  `reg_time` datetime NOT NULL,
  `last_login_time` datetime NOT NULL,
  PRIMARY KEY (`id`),
  KEY `profile_user_id` (`user_id`),
  CONSTRAINT `profile_ibfk_1` FOREIGN KEY (`user_id`) REFERENCES `user` (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=4 DEFAULT CHARSET=utf8;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `profile`
--

LOCK TABLES `profile` WRITE;
/*!40000 ALTER TABLE `profile` DISABLE KEYS */;
INSERT INTO `profile` VALUES (1,1,'','','','2016-10-26 13:39:18','2016-10-26 13:39:18'),(2,2,'','','','2016-10-26 13:39:18','2016-10-26 13:39:18'),(3,3,'','','','2016-11-09 19:48:28','2016-11-09 19:48:28');
/*!40000 ALTER TABLE `profile` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `registryimage`
--

DROP TABLE IF EXISTS `registryimage`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `registryimage` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `user_id` int(11) DEFAULT NULL,
  `action` varchar(16) DEFAULT NULL,
  `repository` varchar(72) NOT NULL,
  `tag` varchar(72) NOT NULL,
  `digest` varchar(88) NOT NULL,
  `create_time` datetime NOT NULL,
  PRIMARY KEY (`id`),
  KEY `registryimage_user_id` (`user_id`),
  CONSTRAINT `registryimage_ibfk_1` FOREIGN KEY (`user_id`) REFERENCES `user` (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `registryimage`
--

LOCK TABLES `registryimage` WRITE;
/*!40000 ALTER TABLE `registryimage` DISABLE KEYS */;
INSERT INTO `registryimage` VALUES (1,1,NULL,'jmpews/test','2.5.0','sha256:8cc735b5dab8cf042d0705b4b44ee351bcbd94a760bbf0781e5334182538a6d6','2016-10-26 13:40:06');
/*!40000 ALTER TABLE `registryimage` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `user`
--

DROP TABLE IF EXISTS `user`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `user` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `username` varchar(16) NOT NULL,
  `nickname` varchar(16) DEFAULT NULL,
  `email` varchar(32) NOT NULL,
  `avatar` varchar(20) DEFAULT NULL,
  `theme` varchar(16) DEFAULT NULL,
  `role` int(11) NOT NULL,
  `password` varchar(32) NOT NULL,
  `salt` varchar(64) NOT NULL,
  `key` varchar(64) NOT NULL,
  `level` int(11) NOT NULL,
  `reg_time` datetime NOT NULL,
  `key_time` bigint(20) NOT NULL,
  PRIMARY KEY (`id`),
  UNIQUE KEY `user_username` (`username`),
  KEY `user_key` (`key`)
) ENGINE=InnoDB AUTO_INCREMENT=4 DEFAULT CHARSET=utf8;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `user`
--

LOCK TABLES `user` WRITE;
/*!40000 ALTER TABLE `user` DISABLE KEYS */;
INSERT INTO `user` VALUES (1,'admin','','admin@jmp.com','default_doubi.png',NULL,1,'38d840dd1c4b9cc91fd309072df85724','bWfmY4zYmedcUI41','V4AhFC549BOmVuu9r3YiVObVoZ6C8OOu',1,'2016-10-26 13:39:18',1477460357),(2,'test','','test@jmp.com','default_doubi.png',NULL,1,'0a6f3effdb614442fb9d951a4d632a3f','ZZNknZ9mnKxxNNgL','QpdeIeTzWVrLFJFjycvHyM98yNY6r252',1,'2016-10-26 13:39:18',1477460357),(3,'chujm','','chujm@knownsec.com','default_doubi.png',NULL,1,'43e344e0a0a38024da8836e6b337083e','iqF9ro4iLCeBLxJ7','7QPjRcjkkUaRZJshJV2DWEWPcfe0ZqOQ',1,'2016-11-09 19:48:28',1478692108);
/*!40000 ALTER TABLE `user` ENABLE KEYS */;
UNLOCK TABLES;
/*!40103 SET TIME_ZONE=@OLD_TIME_ZONE */;

/*!40101 SET SQL_MODE=@OLD_SQL_MODE */;
/*!40014 SET FOREIGN_KEY_CHECKS=@OLD_FOREIGN_KEY_CHECKS */;
/*!40014 SET UNIQUE_CHECKS=@OLD_UNIQUE_CHECKS */;
/*!40101 SET CHARACTER_SET_CLIENT=@OLD_CHARACTER_SET_CLIENT */;
/*!40101 SET CHARACTER_SET_RESULTS=@OLD_CHARACTER_SET_RESULTS */;
/*!40101 SET COLLATION_CONNECTION=@OLD_COLLATION_CONNECTION */;
/*!40111 SET SQL_NOTES=@OLD_SQL_NOTES */;

-- Dump completed on 2016-11-10  1:34:21
